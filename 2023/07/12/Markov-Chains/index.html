<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="I am a second PhD student at Renmin University of China. My research interests include federated learning, high dimensional data, machine learning, and optimization. I am currently working on latent graph learning in Prof.Renjie Liao&#39;s group." />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Discrete Markov Chains |  Welcome to XueYu&#39;s Blog
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

<link rel="alternate" href="/atom.xml" title="Welcome to XueYu's Blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-Markov-Chains"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Discrete Markov Chains
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2023/07/12/Markov-Chains/" class="article-date">
  <time datetime="2023-07-12T10:00:00.000Z" itemprop="datePublished">2023-07-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Random-Process/">Random Process</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">3.4k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">21 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="markov-chains-definitions-and-representations">Markov Chains:
Definitions and Representations</h1>
<p>A stochastic process <span class="math inline">\(X = \{ x(t): t\in
T\}\)</span> is a collection of random variables.</p>
<p>There are two elements:</p>
<ul>
<li>Time <span class="math inline">\(t\)</span>:
<ul>
<li>discrete time (<span class="math inline">\(T\)</span> is a countably
infinite set; under this case, we call 'Markov chain')</li>
<li>continuous time (under this case, we call 'Markov process')</li>
</ul></li>
<li>Space <span class="math inline">\(\Omega\)</span>:
<ul>
<li>discrete space (<span class="math inline">\(X_{t}\)</span> comes
from a countably infinite set)</li>
<li>continuous space.</li>
</ul></li>
</ul>
<p>Markov chain is a <strong>discrete-time</strong> process for which
the future behaviour, given the past and the present, only depends on
the present and not on the past.</p>
<p>Markov process is the <strong>continuous-time</strong> version of a
Markov chain.</p>
<blockquote>
<p>Definition 1.[Markov chain] A discrete time stochastic process $ X_0,
X_1, X_2, <span class="math inline">\(. . . is a Markov chain
if\)</span>$ P(X_{t} = a_t | X_{t-1} = a_{t-1}, X_{t-2} = a_{t-2}, ...,
X_0 = a_0) = P(X_{t} = a_t | X_{t-1} = a_{t-1}) = P_{a_{t-1}, a_{t}}
$$</p>
</blockquote>
<p>Remark 1: This is time-homogeneous markov chain, for <span class="math inline">\(\forall t\)</span>, for <span class="math inline">\(\forall a_{t-1}, a_{t} \in \Omega\)</span>, the
transition probability <span class="math inline">\(P_{a_{t-1}, a_{t}
}\)</span> is the same.</p>
<p>Remark 2: In DDPM, it is not a time-homogeneous chain, as the
transition probability at t is obtained by a network(t).</p>
<p>The state <span class="math inline">\(X_{t}\)</span> depends on the
previous state <span class="math inline">\(X_{t-1}\)</span> but is
independent of the particular history <span class="math inline">\(X_{t-2}, X_{t-3},...\)</span>. This is called the
<strong>Markov property</strong> or <strong>memoryless
property</strong>.</p>
<p>The Markov property does not imply that <span class="math inline">\(X_{t}\)</span> is independent of the random
variables <span class="math inline">\(X_{0}\)</span>, <span class="math inline">\(X_{1}\)</span>,..., <span class="math inline">\(X_{t-2}\)</span>; it just implies that <strong>any
dependency of <span class="math inline">\(X_{t}\)</span> on the past is
captured in the value of <span class="math inline">\(X_{t-1}\)</span></strong>.</p>
<p>The Markov chain is <strong>uniquely</strong> defined by the one-step
transition probability matrix P: <span class="math display">\[
P =
\begin{pmatrix}
P_{0,0} &amp; P_{0, 1} &amp; \cdots &amp; P_{0, j} &amp; \cdots\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots&amp; \vdots\\
P_{i,0} &amp; P_{i, 1} &amp; \cdots &amp; P_{i, j} &amp; \cdots\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots&amp; \vdots\\
\end{pmatrix}
\]</span> where <span class="math inline">\(P_{i,j}\)</span> is the
probability of transition from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span>. <span class="math inline">\(P_{i,j} =
P(X_{t} = j| X_{t-1} = i), i,j \in \Omega\)</span>. For <span class="math inline">\(i\)</span>, <span class="math inline">\(\sum_{j
\geq 0} P_{i,j} = 1\)</span>.</p>
<h1 id="classification-of-states">Classification of States</h1>
<p>For simplicity, we assume that the state space <span class="math inline">\(\Omega\)</span> is finite. ## Communicating
class</p>
<blockquote>
<p>Definition 2. [Communicating class] A state <span class="math inline">\(j\)</span> is reachable from state <span class="math inline">\(i\)</span> if there exists a positive integer
<span class="math inline">\(n\)</span> such that <span class="math inline">\(P_{i,j}^{(n)} &gt; 0\)</span>. We write <span class="math inline">\(i \rightarrow j\)</span>. If <span class="math inline">\(j\)</span> is reachable from <span class="math inline">\(i\)</span>, and <span class="math inline">\(i\)</span> is reachable from <span class="math inline">\(j\)</span>, then the states <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are said to
<strong>communicate</strong>, denoted by <span class="math inline">\(i
\leftrightarrow j\)</span>. A communicating class <span class="math inline">\(C\)</span> is a <strong>maximal</strong> set of
states that communicate with each other. <strong>No state in <span class="math inline">\(C\)</span> communicates with any state not in
<span class="math inline">\(C\)</span>.</strong></p>
</blockquote>
<h2 id="irreducible">Irreducible</h2>
<blockquote>
<p>Definition 3: A Markov chain is <strong>irreducible</strong> if all
states belong to <strong>one</strong> communicating class.</p>
</blockquote>
<p>This means that <strong>any state can be reached from any other
state</strong>. For <span class="math inline">\(\forall i, j \in
\Omega\)</span>, <span class="math inline">\(P_{i,j} &gt;
0\)</span>.</p>
<blockquote>
<p>Lemma 1. A finite Markov chain is irreducible if and only if its
graph representation is a strongly connected graph.</p>
</blockquote>
<h3 id="transient-vs-recurrent-states">Transient vs Recurrent
states</h3>
<p>Let <span class="math inline">\(r_{i,j}^{t}\)</span> denote the
probability that the chain, starting at state <span class="math inline">\(i\)</span>, <strong>the first time</strong>
transition to state <span class="math inline">\(j\)</span> occurs at
time <span class="math inline">\(t\)</span>. That is, <span class="math display">\[
r_{i,j}^{t} = P(X_{t} = j, X_{s} \neq j, \forall 1 \leq s \leq t-1 |
X_{0} = i)
\]</span></p>
<blockquote>
<p>Definition 4. A state is <strong>recurrent</strong> if <span class="math inline">\(\sum_{t \geq 1} r_{i,i}^{t} = 1\)</span> and it is
<strong>transient</strong> if <span class="math inline">\(\sum_{t \geq
1} r_{i,i}^{t} &lt; 1\)</span>. A Markov chain is recurrent if every
state in the chain is recurrent.</p>
</blockquote>
<ul>
<li><p>If state i is recurrent then, once the chain visits that state,
it will (with probability 1) eventually return to that state. Hence the
chain will visit state <span class="math inline">\(i\)</span> over and
over again, <strong>infinitely</strong> often.</p></li>
<li><p>A transient state has the property that a Markov chain starting
at this state returns to this state only <strong>finitely
often</strong>, with probability 1.</p></li>
<li><p>If one state in a communicating class is transient (respectively,
recurrent) then all states in that class are transient (respectively,
recurrent).</p></li>
</ul>
<blockquote>
<p>Definition 5. An irreducible Markov chain is called recurrent if at
least one (equivalently, every) state in this chain is recurrent. An
irreducible Markov chain is called transient if at least one
(equivalently, every) state in this chain is transient.</p>
</blockquote>
<p>Let <span class="math inline">\(\mu_{i} = \sum_{t \geq 1} t \cdot
r_{i,i}^{t}\)</span> denote the expected time to return to state <span class="math inline">\(i\)</span> when starting at state <span class="math inline">\(i\)</span>.</p>
<blockquote>
<p>Definition 6. A state <span class="math inline">\(i\)</span> is
<strong>positive recurrent</strong> if <span class="math inline">\(\mu_{i} &lt; \infty\)</span> and <strong>null
recurrent</strong> if <span class="math inline">\(\mu_{i} =
\infty\)</span>.</p>
</blockquote>
<p>Here we give an example of a Markov chain that has null recurrent
states. Consider the following markov chain whose states are the
positive integers.</p>
<figure>
<img src="/2023/07/12/Markov-Chains/image.png" alt="Fig. 1. An example of a Markov chain that has null recurrent states">
<figcaption aria-hidden="true">Fig. 1. An example of a Markov chain that
has null recurrent states</figcaption>
</figure>
<p>Starting at state 1, the probability of not having returned to state
1 within the first <span class="math inline">\(t\)</span> steps is <span class="math display">\[
\prod_{j=1}^{t} \frac{j}{j+1} = \frac{1}{t+1}.
\]</span> The probability of never returning to state 1 from state 1 is
0, and state 1 is recurrent. Thus, the probability of the first time
transition to state <span class="math inline">\(1\)</span> occurs at
time <span class="math inline">\(t\)</span> is <span class="math display">\[
r_{1,1}^{t} = \frac{1}{t} \cdot \frac{1}{t+1} = \frac{1}{t(t+1)}.
\]</span> The expected number of steps until the first return to state 1
when starting at state 1 is <span class="math display">\[
\mu_{1} = \sum_{t = 1}^{\infty} t \cdot r_{1,1}^{t} = \sum_{t =
1}^{\infty} \frac{1}{t+1} = \infty.
\]</span> State 1 is recurrent but null recurrent.</p>
<blockquote>
<p>Lemma 2. In a finite Markov chain: 1. at least one state is
recurrent; and 2. all recurrent states are positive recurrent.</p>
</blockquote>
<p>Thus, all states of a finite, irreducible Markov chain are positive
recurrent.</p>
<h3 id="periodic-vs-aperiodic-states">Periodic vs Aperiodic states</h3>
<blockquote>
<p>Definition 7. A state <span class="math inline">\(j\)</span> in a
discrete time Markov chain is <strong>periodic</strong> if there exists
an integer <span class="math inline">\(k&gt;1\)</span> such that <span class="math inline">\(P(X_{t+s}= j | X_t = j) = 0\)</span> unless <span class="math inline">\(s\)</span> is divisible by <span class="math inline">\(k\)</span>. A discrete time Markov chain is
periodic if any state in the chain is periodic. A state or chain that is
not periodic is <strong>aperiodic</strong>.</p>
</blockquote>
<p>A state <span class="math inline">\(i\)</span> is periodic means that
for <span class="math inline">\(s = k, 2k, 3k,...\)</span>, <span class="math inline">\(P(X_{t+s}= j | X_t = j) &gt; 0\)</span>.</p>
<p><strong>NB: k &gt; 1</strong></p>
<h3 id="ergodic">Ergodic</h3>
<blockquote>
<p>Definition 8. An <strong>aperiodic</strong>, <strong>positive
recurrent</strong> state is an <strong>ergodic</strong> state. A Markov
chain is ergodic if all its states are ergodic.</p>
</blockquote>
<blockquote>
<p>Corollary 1. Any finite, irreducible, and aperiodic Markov chain is
an ergodic chain.</p>
</blockquote>
<h3 id="stationary-distribution">Stationary distribution</h3>
<p>Consider the two-state “broken printer” Markov chain:</p>
<figure>
<img src="/2023/07/12/Markov-Chains/2023-07-22-11-00-52.png" alt="Transition diagram for the two-state broken printer chain">
<figcaption aria-hidden="true">Transition diagram for the two-state
broken printer chain</figcaption>
</figure>
<p>There are two state (0 and 1) in this Markov chain, and assume that
the initial distribution is <span class="math display">\[
P(X_0 = 0) = \frac{\beta}{\alpha+\beta}, \qquad P(X_0 = 1) =
\frac{\alpha}{\alpha+\beta}.
\]</span> Then, according to the transition probability matrix <span class="math inline">\(P\)</span>, after one step, the distribution is
<span class="math display">\[
\begin{align*}
P(X_1 = 0) &amp;= P(X_0 = 0)P(X_1 = 0 | X_0 = 0) + P(X_0 = 1)P(X_1 = 0 |
X_0 = 1) \\
&amp;= \frac{\beta}{\alpha+\beta} \cdot (1-\alpha) +
\frac{\alpha}{\alpha+\beta} \cdot \beta = \frac{\beta}{\alpha+\beta}, \\
P(X_1 = 1) &amp;= P(X_0 = 0)P(X_1 = 1 | X_0 = 0) + P(X_0 = 1)P(X_1 = 1 |
X_0 = 1) \\
&amp;= \frac{\beta}{\alpha+\beta} \cdot \alpha +
\frac{\alpha}{\alpha+\beta} \cdot (1-\beta) =
\frac{\alpha}{\alpha+\beta}.
\end{align*}
\]</span> Apparently, the distribution of <span class="math inline">\(X_1\)</span> is the same as the initial
distribution. Similarly, we can prove that the distribution of <span class="math inline">\(X_t\)</span> is the same as the initial
distribution for any <span class="math inline">\(t\)</span>. Here, <span class="math inline">\(\pi = (\frac{\beta}{\alpha+\beta},
\frac{\alpha}{\alpha+\beta})\)</span> is called <strong>stationary
distribution</strong>.</p>
<blockquote>
<p>Definition 9. A probability distribution <span class="math inline">\(\pi = (\pi_i)\)</span>, <span class="math inline">\(\sum_{i \in \Omega} \pi_i = 1\)</span>(<strong>row
vector</strong>) on the state space <span class="math inline">\(\Omega\)</span> is called a <strong>stationary
distribution</strong> (or an equilibrium distribution) for the Markov
chain with transition probability matrix <span class="math inline">\(P\)</span> if <span class="math inline">\(\pi =
\pi P\)</span>, equivalently, <span class="math inline">\(\pi_j =
\sum_{i \in \Omega}\pi_i P_{i,j}\)</span> for all <span class="math inline">\(j \in \Omega\)</span>.</p>
</blockquote>
<ul>
<li><p>One interpretation of the stationary distribution: if we started
off a <strong>thousand</strong> Markov chains, choosing each starting
position to be state <span class="math inline">\(i\)</span> with
probability <span class="math inline">\(\pi_i\)</span>, then(roughly)
<strong><span class="math inline">\(1000 \pi_j\)</span></strong> of them
would be in state <span class="math inline">\(j\)</span> at any time in
the future – but not necessarily the same ones each time.</p></li>
<li><p>If a chain ever reaches a stationary distribution then it
maintains that distribution for all future time, and thus a stationary
distribution represents a steady state or an equilibrium in the chain’s
behavior.</p></li>
</ul>
<h4 id="finding-a-stationary-distribution">Finding a stationary
distribution</h4>
<p>Consider the following no-claims discount Markov chain with state
space <span class="math inline">\(\Omega = \{1,2,3\}\)</span> and
transition matrix <span class="math display">\[
P =
\begin{pmatrix}
\frac{1}{4} &amp; \frac{3}{4} &amp; 0\\
\frac{1}{4} &amp; 0 &amp; \frac{3}{4}\\
0 &amp; \frac{1}{4} &amp; \frac{3}{4}
\end{pmatrix}
\]</span></p>
<ul>
<li><p>Step 1: Assume $= {_1, _2, _3} $ is a stationary distribution.
According to the definition 9 of stationary distribution, we need to
solve the following equations: <span class="math display">\[
\begin{align*}
\pi_1 &amp;= \frac{1}{4}\pi_1 + \frac{1}{4}\pi_2, \\
\pi_2 &amp;= \frac{3}{4}\pi_1 + \frac{1}{4}\pi_3, \\
\pi_3 &amp;= \frac{3}{4}\pi_2 + \frac{3}{4}\pi_3.
\end{align*}
\]</span> Adding the normalising condition <span class="math inline">\(\pi_1 + \pi_2 + \pi_3 = 1\)</span>, we get four
equations in three unknown parameters.</p></li>
<li><p>Step 2: Choose one of the parameters, say <span class="math inline">\(\pi_1\)</span>, and solve for the other two
parameters in terms of <span class="math inline">\(\pi_1\)</span>. We
get <span class="math display">\[
\pi_1 = \frac{1}{4}\pi_1 + \frac{1}{4}\pi_2 \Rightarrow \pi_2 = 3\pi_1,
\qquad \pi_3 = 3\pi_2 = 9\pi_1.
\]</span></p></li>
<li><p>Step 3: Combining with the normalising condition, we get <span class="math display">\[
\pi_1 + 3\pi_1 + 9\pi_1 = 1 \Rightarrow \pi_1 = \frac{1}{13}, \qquad
\pi_2 = \frac{3}{13}, \qquad \pi_3 = \frac{9}{13}.
\]</span> Finally, we get the stationary distribution <span class="math inline">\(\pi = (\frac{1}{13}, \frac{3}{13},
\frac{9}{13})\)</span>.</p></li>
</ul>
<h4 id="existence-and-uniqueness">Existence and uniqueness</h4>
<p>Given a Markov chaine, how can we know whether it has a stationary
distribution? If it has, is it unique? At this part, we will answer
these questions.</p>
<p>Some notations: - Hitting time to hit the state <span class="math inline">\(j\)</span>: <span class="math inline">\(H_{j} =
\min \{ t \in \{0, 1, 2,...\}: X_t = j\}\)</span>. Note that here we
include time <span class="math inline">\(t = 0\)</span>.</p>
<ul>
<li>Hitting probability to hit the state <span class="math inline">\(j\)</span> staring from state <span class="math inline">\(i\)</span>: <span class="math inline">\(h_{i,j} =
P(X_t = j, \text{for some} \ t \geq 0 | X_0 = i) = P(H_{j} &lt; \infty |
X_0 = i) = \sum_{t \geq 0} r_{i,j}^{t}\)</span>.</li>
</ul>
<p>Note that this is different from <span class="math inline">\(r_{i,j}^{t}\)</span>, which denotes the
probability that the chain, starting at state <span class="math inline">\(i\)</span>, the <strong>first</strong> time
transition to state <span class="math inline">\(j\)</span>
<strong>occurs at time <span class="math inline">\(t\)</span></strong>.</p>
<p>We also have <span class="math display">\[
h_{i,j} =
\begin{cases}
\sum_{k \in \Omega}P_{i,k}h_{k,j} &amp; , &amp; \text{if} \quad j \ne i,
\\
1 &amp; , &amp; \text{if} \quad  j = i.
\end{cases}
\]</span> - Expected hitting time: <span class="math inline">\(\eta_{i,j} = E(H_{j} | X_0 = i) = \sum_{t \geq 0}
t \cdot r_{i,j}^{t}\)</span>. The expected time until we hit state <span class="math inline">\(j\)</span> starting from state <span class="math inline">\(i\)</span>. We also have <span class="math display">\[
\eta_{i,j} =
\begin{cases}
1 + \sum_{k \in \Omega}P_{i,k}\eta_{k,j} &amp; , &amp; if j \ne i, \\
0 &amp; , &amp; if j = i.
\end{cases}
\]</span> (For the first case, we add 1 because we need to consider the
first step from state <span class="math inline">\(i\)</span> to state
<span class="math inline">\(k\)</span>.)</p>
<ul>
<li>Return time: <span class="math inline">\(M_i = \min \{ t \in \{1,
2,...\}: X_t = i\}\)</span>. It is different from <span class="math inline">\(H_{i}\)</span>, as we exclude time <span class="math inline">\(t = 0\)</span>. It is the first time that the
chain returns to state <span class="math inline">\(i\)</span> after
<span class="math inline">\(t = 0\)</span>.</li>
<li>Return probability: <span class="math inline">\(m_{i} = P(X_t = i  \
\text{for some} \ n \geq 1 | X_0 = i) = P(M_i &lt; \infty | X_0 = i) =
\sum_{t&gt;1}r_{i,i}^{t}.\)</span></li>
<li>Expected return time: <span class="math inline">\(\mu_{i} = E(M_i |
X_0 = i) = \sum_{t \geq 1} t \cdot r_{i,i}^{t}\)</span>. The expected
time until we return to state <span class="math inline">\(i\)</span>
starting from state <span class="math inline">\(i\)</span>. <span class="math display">\[
m_{i} = \sum_{j \in \Omega} P_{i,j}h_{j,i},  \qquad \mu_{i} = 1 +
\sum_{j \in \Omega} P_{i,j}\eta_{j,i}.
\]</span></li>
</ul>
<table style="width:24%;">
<colgroup>
<col style="width: 23%">
</colgroup>
<tbody>
<tr>
<td>&gt; Theorem 1. Consider an irreducible Markov chain (<strong>finite
or infinite</strong>), &gt; (1) if it is <strong>positive
recurrent</strong>, <span class="math inline">\(\exists\)</span> an
unique stationary distribution <span class="math inline">\(\pi\)</span>,
such that <span class="math inline">\(\pi_i =
\frac{1}{\mu_{i}}\)</span>. &gt; (2) if it is <strong>null
recurrent</strong> or <strong>transient</strong>, no stationary
distribution exists.</td>
</tr>
<tr>
<td>Remark: If the chain is <strong>finite</strong> irreducible, it must
be positive recurrent, thus it has an unique stationary
distribution.</td>
</tr>
<tr>
<td>Remark: If the Markov chain is not irreducible, we can decompose the
state space into several communicating classes. Then, we can consider
each communicating class separately. - If none of the classes are
positive recurrent, then no stationary distribution exists. - If exactly
one of the classes is positive recurrent (and therefore closed), then
there exists a unique stationary distribution, supported only on that
closed class. - If more the one of the classes are positive recurrent,
then many stationary distributions will exist.</td>
</tr>
<tr>
<td>Now, we give the proof of Theorem 1. We first prove that if a Markov
chain is irreducible and positive recurrent, then there
<strong>exists</strong> a stationary distribution. Next, we will prove
the stationary distribution is <strong>unique</strong>. Since the second
part with the null recurrent or transitive Markov chains is less
important and more complicated, we will omit it. If you are interested
in it, you can refer to the book <a target="_blank" rel="noopener" href="https://www.statslab.cam.ac.uk/~james/Markov/">Markov Chains</a>
by James Norris.</td>
</tr>
<tr>
<td>Proof. (1) Suppose that <span class="math inline">\((X_0, X_1
...)\)</span> a recurrent Markov chain, which can be positive recurrent
or null recurrent. Then we can desigh a stationary distribution as
follows. (If we can desigh a stationary distribution, then it must be
existed.)</td>
</tr>
<tr>
<td>Let <span class="math inline">\(\nu_i\)</span> be the expected
number of visits to <span class="math inline">\(i\)</span> before we
return back to <span class="math inline">\(k\)</span>, <span class="math display">\[
\begin{align*}
\nu_i &amp;= \mathbb{E}(\# \text{visits to $i$ before returning to } k |
X_0 = k) \\
&amp;= \mathbb{E}\sum_{t=1}^{M_k} P(X_t = i | X_0 = k) \\
&amp;= \mathbb{E}\sum_{t = 0}^{M_k - 1} P(X_t = i | X_0 = k)
\end{align*}
\]</span> The last equation holds because of $ P(X_0 = i | X_0 = k) = 0$
and $ P(X_{M_k} = i | X_0 = k) = 0$.</td>
</tr>
<tr>
<td>If we want design a stationary distribution, it must statisfy <span class="math inline">\(\pi P = \pi\)</span> and <span class="math inline">\(\sum_{i \in \Omega}\pi_i = 1\)</span>.</td>
</tr>
<tr>
<td>(a) We first prove that <span class="math inline">\(\nu P =
\nu\)</span>. <span class="math display">\[
\begin{align*}
\sum_{i \in \Omega} \nu_i P_{i,j} &amp;= \mathbb{E}\sum_{i \in \Omega}
\sum_{t = 0}^{M_k - 1} P(X_t = i, X_{t+1} = j | X_0 = k) \\
&amp;= \mathbb{E}\sum_{t = 0}^{M_k - 1}  \sum_{i \in \Omega}  P(X_t = i,
X_{t+1} = j | X_0 = k) \\
&amp;=  \mathbb{E} \sum_{t = 0}^{M_k - 1} P(X_{t+1} = j | X_0 = k) \\
&amp;= \mathbb{E} \sum_{t = 1}^{M_k } P(X_{t} = j | X_0 = k) \\
&amp;= \mathbb{E} \sum_{t = 0}^{M_k - 1} \nu_i \\
&amp;= \nu_j.
\end{align*}
\]</span> (b) Next, what we need to do is to normalize <span class="math inline">\(\nu\)</span> to get a stationary distribution. We
have <span class="math display">\[
\sum_{i \in \Omega} \nu_i = \sum_{i \in \Omega} \mathbb{E} \sum_{t =
0}^{M_k - 1} P(X_t = i | X_0 = k) =\mathbb{E} \sum_{t = 0}^{M_k -
1}  \sum_{i \in \Omega}  P(X_t = i | X_0 = k) = E(M_k | X_0 = i) =
\mu_k.
\]</span> Thus, we can define <span class="math inline">\(\pi_i =
\nu_i/\mu_k\)</span>, <span class="math inline">\(\pi = \{\pi_i, i \in
\Omega\}\)</span> is one of the stationary distribution.</td>
</tr>
<tr>
<td>(2) Next, we prove that if a Markov chain is irreducible and
positive recurrent, then the stationary distribution is
<strong>unique</strong> and is given by <span class="math inline">\(\pi_j = \frac{1}{\mu_j}\)</span>.</td>
</tr>
<tr>
<td>Given a stationary distribution <span class="math inline">\(\pi\)</span>, if we prove that for all <span class="math inline">\(i\)</span>, <span class="math inline">\(\pi_j ==
\frac{1}{\mu_j}\)</span>, then we prove that the stationary distribution
is unique.</td>
</tr>
<tr>
<td>Remember that the expected hitting time: <span class="math display">\[
\eta_{i,j} = 1 + \sum_{k \in \Omega}P_{i,k}\eta_{k,j},  j \ne i  \qquad
(eq:1)
\]</span> We multiply both sides of (eq:1) by <span class="math inline">\(\pi_i\)</span> and sum over <span class="math inline">\(i (i \ne j)\)</span> to get <span class="math display">\[
\sum_{i \ne j} \pi_i \eta_{i,j} = \sum_{i \ne j} \pi_i + \sum_{i \ne j}
\sum_{k \in \Omega} \pi_i P_{i,k}\eta_{k,j}
\]</span> Since <span class="math inline">\(\eta_{j,j} = 0\)</span>, we
can rewrite the above equation as <span class="math display">\[
\sum_{i \in \Omega} \pi_i \eta_{i,j} = \sum_{i \ne j} \pi_i + \sum_{i
\ne j} \sum_{k \in \Omega} \pi_i P_{i,k}\eta_{k,j}. \qquad (eq:2)
\]</span></td>
</tr>
<tr>
<td>(The above equality lacks <span class="math inline">\(j\)</span>,
and we also want to design <span class="math inline">\(\pi_j =
1/\mu_j\)</span>.) Remember that the expected return time: <span class="math display">\[ \mu_{j} = 1 + \sum_{i \in \Omega}
P_{j,i}\eta_{i,j}. \qquad (eq:3) \]</span> We multiply both sides of
(eq:2) by <span class="math inline">\(\pi_j\)</span> to get <span class="math display">\[
\pi_j \mu_{j} =\pi_j +  \sum_{k \in \Omega} \pi_j P_{j,k}\eta_{k,j}
\qquad (eq:4)
\]</span> Adding (eq:2) and (eq:4), we get <span class="math display">\[
\begin{align*}
\sum_{i \in \Omega} \pi_i \eta_{i,j} + \pi_j \mu_{j} &amp;= \sum_{i \in
\Omega} \pi_i + \sum_{i \in \Omega} \sum_{k \in \Omega} \pi_i
P_{i,k}\eta_{k,j} \\
&amp;= 1 + \sum_{k \in \Omega} \sum_{i \in \Omega}  \pi_i
P_{i,k}\eta_{k,j} \\
&amp;= 1 +  \sum_{k \in \Omega} \pi_k \eta_{k,j}  \qquad (\text{since}
\sum_{i \in \Omega} \pi_i P_{i,k} = \pi_k) \\
\end{align*}
\]</span> <strong>Since the Markov chain is irreducible and positive
recurrent, that means all states belong to a communication class and the
expected return time of each state is finite. Thus, the space <span class="math inline">\(\Omega\)</span> is a finite dimensional
space.</strong> We can substract <span class="math inline">\(\sum_{k \in
\Omega} \pi_k \eta_{k,j}\)</span> and $_{i } <em>i </em>{i,j} $ (equal)
from both sides of the above equation to get <span class="math display">\[
\pi_j \mu_{j}=1,
\]</span> which means <span class="math inline">\(\pi_j =
1/\mu_j\)</span>. Similarly, we can prove that <span class="math inline">\(\pi_i = 1/\mu_i\)</span> for all <span class="math inline">\(i \in \Omega\)</span>.</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Theorem 2 (Limit theorem) Consider an irreducible, aperiodic Markov
chain (maybe infinite), we have <span class="math inline">\(\lim\limits_{t \to \infty} P_{i,j}^{t} =
\frac{1}{\mu_{j}}\)</span>. Spectially, (1) Suppose the Markov chain is
positive recurrent. Then <span class="math inline">\(\lim\limits_{t \to
\infty} P_{i,j}^{t} = \pi_j = \frac{1}{\mu_{j}}\)</span>. (2) Suppose
the Markov chain is null recurrent or transient. Then there is no limite
probability.</p>
</blockquote>
<ul>
<li>Three conditions for convergence to an equilibrium probability
distribution: irreducibility, aperiodicity, and positive recurrence. The
limit probability <span class="math display">\[
P =
\begin{pmatrix}
\pi_1 &amp; \pi_2 &amp; \cdots &amp; \pi_N\\
\pi_1 &amp; \pi_2 &amp; \cdots &amp; \pi_N\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
\pi_1 &amp; \pi_2 &amp; \cdots &amp; \pi_N\\
\end{pmatrix}
\]</span> where each row is identical.</li>
</ul>
<table style="width:7%;">
<colgroup>
<col style="width: 6%">
</colgroup>
<tbody>
<tr>
<td>Define <span class="math inline">\(V_{i,j}^{t} = |\{ n &lt; t | X_n
= j\}|\)</span>. <span class="math inline">\(V_{i,j}^{t}\)</span> is the
number of visits to state <span class="math inline">\(j\)</span> before
time <span class="math inline">\(t\)</span> starting from state <span class="math inline">\(i\)</span>. Then we can interpret <span class="math inline">\(V_{i,j}^{t}/t\)</span> as the proportion of time
up to time <span class="math inline">\(t\)</span> spent in state <span class="math inline">\(j\)</span>.</td>
</tr>
<tr>
<td>&gt; Theorem 3 [Ergodic theorem] Consider an irreducible Markov
chain, we have <span class="math inline">\(\lim\limits_{t \to \infty}
V_{i,j}^{t}/t = \frac{1}{\mu_{j}}\)</span> <strong>almost
surely</strong>. Spectially, &gt; (1) Suppose the Markov chain is
positive recurrent. Then <span class="math inline">\(\lim\limits_{t \to
\infty}  V_{i,j}^{t}/t = \pi_j = \frac{1}{\mu_{j}}\)</span>
<strong>almost surely</strong>. &gt; (2) Suppose the Markov chain is
null recurrent or transient. Then $ V_{i,j}^{t}/t $ <strong>almost
surely</strong> for all <span class="math inline">\(j\)</span>.</td>
</tr>
<tr>
<td><strong>almost surely</strong> means that the convergence
probability of the event is 1.</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Theorem 4[Detailed balance condition]. Consider a finite,
irreducible, and ergodic Markov chain with transition matrix <span class="math inline">\(P\)</span>. If there are nonnegative numbers <span class="math inline">\(\bar{\pi} = (\pi_0, \pi_1, ..., \pi_n)\)</span>
such that <span class="math inline">\(\sum_{i=0}^{n} \pi_i = 1\)</span>
and if, for any pair of states <span class="math inline">\(i,
j\)</span>, <span class="math display">\[
\pi_i P_{i,j} = \pi_{j} P_{j,i},
\]</span> then <span class="math inline">\(\bar{\pi}\)</span> is the
stationary distribution corresponding to <span class="math inline">\(P\)</span>.</p>
</blockquote>
<p>Proof. <span class="math display">\[
\sum_{i} \pi_i P_{i,j} = \sum_{i}\pi_{j} P_{j,i} = \pi_{j}
\]</span> Thus, <span class="math inline">\(\bar{\pi} =
\bar{\pi}P\)</span>. Since this is a finite, irreducible, and ergodic
Markov chain, <span class="math inline">\(\bar{\pi}\)</span> must be the
unique stationary distribution of the Markov chain.</p>
<p>Remark: Theorem 2 is a sufficient but not necessary condition.</p>
<h2 id="reference">Reference</h2>
<ul>
<li>Mitzenmacher, M., &amp; Upfal, E. (2005). Probability and Computing.
Cambridge University Press.</li>
<li><a target="_blank" rel="noopener" href="https://mpaldridge.github.io/math2750/S09-recurrence-transience.html">Recurrence
and transience</a></li>
<li><a target="_blank" rel="noopener" href="https://mpaldridge.github.io/math2750/S07-classes.html">Class
structure</a></li>
<li><a target="_blank" rel="noopener" href="https://mpaldridge.github.io/math2750/S10-stationary-distributions.html">Stationary
distributions</a></li>
<li>Stirzaker, David. <a target="_blank" rel="noopener" href="https://www.ctanujit.org/uploads/2/5/3/9/25393293/_elementary_probability.pdf">Elementary
Probability</a></li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://xueyu-ubc.github.io/2023/07/12/Markov-Chains/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Markov-Chains/" rel="tag">Markov Chains</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2023/07/15/Metropolis-Hastings/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Metropolis-Hastings
          
        </div>
      </a>
    
    
      <a href="/2021/02/27/GD/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Gradient Descent, Stochastic Gradient Descent, Variance Reduction</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "",
    app_key: "",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021-2024
        <i class="ri-heart-fill heart_icon"></i> Xue Yu
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Welcome to XueYu&#39;s Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2021/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i></p>
  <div class="reward-box">
    
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>
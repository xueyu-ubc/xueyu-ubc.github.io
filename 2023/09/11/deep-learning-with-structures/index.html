<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="I am a second PhD student at Renmin University of China. My research interests include federated learning, high dimensional data, machine learning, and optimization. I am currently working on latent graph learning in Prof.Renjie Liao&#39;s group." />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Deep Learning |  Welcome to XueYu&#39;s Blog
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

<link rel="alternate" href="/atom.xml" title="Welcome to XueYu's Blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>

</html>
<script src="/js/hexo_resize_image.js"></script>
<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-deep-learning-with-structures"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Deep Learning
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2023/09/11/deep-learning-with-structures/" class="article-date">
  <time datetime="2023-09-11T05:30:00.000Z" itemprop="datePublished">2023-09-11</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Graph/">Graph</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">4.1k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">25 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="brief-intro-to-deep-learning">Brief Intro to Deep Learning</h2>
<p>Deep learning: - Data: large datasets, e.g., ImageNet, etc.; - Model:
deep neural networks, e.g., ResNet-152, etc.; - Learning algorithm:
backpropagation, i.e., stochastic gradient descent (SGD).</p>
<p>In recurrent neural networks (RNNs): <strong>same</strong> neural
network gets reused many times. <span class="math display">\[
h^t = F(x^t, h^{t-1}, W).
\]</span></p>
<p>Back propagation: - Loss is always a scalar value; - For the backward
propogation, the gradient is in the form: <span class="math inline">\(J^T v\)</span>, where <span class="math inline">\(v\)</span> is a vector, and <span class="math inline">\(J\)</span> is a Jacobian matrix, <span class="math inline">\(T\)</span> means transpose; - For the forward
propogation, the gradient is in the form: <span class="math inline">\(J
v\)</span>. - In BF process, the shape of a Jacobian matrix is <span class="math inline">\(m \times n\)</span>, where <span class="math inline">\(m\)</span> is the dimension of output, and <span class="math inline">\(n\)</span> is the dimension of input.</p>
<p>Consider Vector-by-Matrix Gradients:</p>
<p>Case 1: <span class="math inline">\(\bm{z} =
\mathbf{W}\bm{x}\)</span>, where <span class="math inline">\(\bm x \in
\mathbb{R}^{n \times 1}\)</span>, <span class="math inline">\(\mathbf{W}
\in \mathbb{R}^{m \times n}\)</span>, <span class="math inline">\(\bm z
\in \mathbb{R}^{m \times 1}\)</span>. <span class="math display">\[
\begin{aligned}
\frac{\partial \bm{z}}{\partial \bm{x}} &amp;= \mathbf{W}, \\
\end{aligned}
\]</span></p>
<p>Case 2： <span class="math inline">\(\bm{z} = \bm{x}
\mathbf{W}\)</span>, where <span class="math inline">\(\bm x \in
\mathbb{R}^{1 \times m}\)</span>, <span class="math inline">\(\mathbf{W}
\in \mathbb{R}^{m \times n}\)</span>, <span class="math inline">\(\bm z
\in \mathbb{R}^{1 \times n}\)</span>. <span class="math display">\[
\begin{aligned}
\frac{\partial \bm{z}}{\partial \bm{x}} &amp;= \mathbf{W}^T, \\
\end{aligned}
\]</span></p>
<p>Case 3: <span class="math inline">\(\bm z = \bm x\)</span>, then
<span class="math inline">\(\frac{\partial \bm z}{\partial \bm x} =
\mathbf{I}\)</span>.</p>
<p>Case 4: <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{m
\times n}\)</span>, then <span class="math inline">\(\frac{\partial
scalar}{\partial \mathbf{X}}  \in \mathbb{R}^{m \times n}\)</span>, just
as the same as the shape of <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>Case 5: <span class="math inline">\(\mathbf{Z} =
\mathbf{X}\mathbf{W}\)</span>, where <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{m \times n}\)</span>,
<span class="math inline">\(\mathbf{W} \in \mathbb{R}^{n \times
w}\)</span>. Assume <span class="math inline">\(\frac{\partial
Loss}{\partial \mathbf{Z}} = \mathbf{\delta} \in \mathbb{R}^{m \times
w}\)</span>. <span class="math display">\[
\begin{aligned}
\frac{\partial Loss}{\partial \mathbf{X}} &amp;= \mathbf{\delta}
\mathbf{W}^T, \\
\frac{\partial Loss}{\partial \mathbf{W}} &amp;= \mathbf{X}^T
\mathbf{\delta}.
\end{aligned}
\]</span></p>
<p><img src="/2023/09/11/deep-learning-with-structures/bp.jpg"></p>
<p>Here we consider the simple example: <span class="math display">\[
\begin{aligned}
\bm h_1 = \bm x \mathbf{W}_1,  \qquad (1 \times 4) = (1 \times 3) \times
(3 \times 4)\\
\hat{\bm y} = \bm h_1 \mathbf{W}_2, \qquad (1 \times 2) = (1 \times 4)
\times (4 \times 2)\\
L = \|\hat{\bm y}\|_2^2. \qquad (1 \times 1) = (1 \times 2) \times (2
\times 1)
\end{aligned}
\]</span> Then, for the backward propagation process, we have: <span class="math display">\[
\begin{aligned}
\frac{\partial L}{\partial \hat{\bm y}} &amp;= 2 \hat{\bm y}, \qquad (1
\times 2) = (1 \times 2) \\
\frac{\partial L}{\partial \mathbf{W}_2} &amp;=  (\frac{\partial
\hat{\bm y}}{\partial \mathbf{W}_2})^T \frac{\partial L}{\partial
\hat{\bm y}}= \bm h_1^T  \frac{\partial L}{\partial \hat{\bm y}} = 2 \bm
h_1^T \hat{\bm y}, \qquad (4 \times 2) = (4 \times 1) \times (1 \times
2)\\
\frac{\partial L}{\partial \bm h_1} &amp;=  \frac{\partial L}{\partial
\hat{\bm y}}\frac{\partial \hat{\bm y}}{\partial \bm h_1}=\frac{\partial
L}{\partial \hat{\bm y}} \mathbf{W}_2^T = 2 \hat{\bm y} \mathbf{W}_2^T
, \qquad (1 \times 4) = (1 \times 2) \times (2 \times 4)\\
\frac{\partial L}{\partial \mathbf{W}_1} &amp;=  (\frac{\partial \bm
h_1}{\partial \mathbf{W}_1})^T [\frac{\partial L}{\partial \hat{\bm
y}}\frac{\partial \hat{\bm y}}{\partial \bm h_1}] = \bm x^T
\frac{\partial L}{\partial \bm h_1} = 2 \bm x^T \hat{\bm y}
\mathbf{W}_2^T, \qquad (3 \times 4) = (3 \times 1) \times (1 \times 4)
\\
\frac{\partial L}{\partial \bm x} &amp;=  \frac{\partial L}{\partial
\hat{\bm y}}\frac{\partial \hat{\bm y}}{\partial \bm h_1} \frac{\partial
\bm h_1}{\partial \bm x} = 2\hat{\bm y} \mathbf{W}_2^T \mathbf{W}_1^T,
\qquad (1 \times 3) = (1 \times 2) \times (2 \times 4) \times (4 \times
3)
\end{aligned}
\]</span></p>
<p>We can get similar results if <span class="math inline">\(\bm x \in
\mathbb{R}^{3 \times 1}\)</span>.</p>
<h2 id="invariant-and-equivariant">Invariant and Equivariant:</h2>
<p><strong>Invariant</strong>: A mathematical object (or a class of
mathematical objects) remains unchanged after operations or
transformations of a certain type are applied to the objects <span class="math inline">\(F(g(x)) = F(x)\)</span>, e.g., max pooling;</p>
<ul>
<li>Symmetry Group: all transformations under which the object is
invariant</li>
</ul>
<p><strong>Equivariant</strong>: Applying a transformation and then
computing the function produces the same result as computing the
function and then applying the transformation <span class="math inline">\(F(g(x)) = g(F(x))\)</span>.</p>
<ul>
<li><p>Convolution is translation equivariant, i.e., Conv(Shift(X)) =
Shift(Conv(X))!</p></li>
<li><p>Global pooling gives you shift-invariance!</p></li>
</ul>
<h3 id="permutation-invariance">Permutation Invariance</h3>
<p>Birkhoff Polytope: <span class="math display">\[
B_n = \{P \in \mathbb{R}^{n \times n} | \forall i, j, P_{ij} \geq 0,
\sum_{i=1}^n P_{ij} = 1, \sum_{j=1}^n P_{ij} = 1\}
\]</span> This type of matrix is Doubly Stochastic Matrix.</p>
<p>Birkhoff–von Neumann Theorem: 1. Birkhoff Polytope is the convex hull
of permutation matrices 2. Permutation matrices = Vertices of Birkhoff
Polytope (S_n):</p>
<p><img src="/2023/09/11/deep-learning-with-structures/Birkhoff.png"></p>
<p>Assume <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{n
\times 3}\)</span>, permutation matrix <span class="math inline">\(\mathbf{P} \in \mathbb{R}^{n \times n}\)</span>.
<span class="math inline">\(\bm Y \in \mathbb{R}^{1 \times K}\)</span>
is the output probability of classes.</p>
<p>Permutation Invariance : <span class="math inline">\(\bm Y =
f(\mathbf{PX})\)</span>, <span class="math inline">\(\forall \mathbf{P}
\in S_n\)</span>.</p>
<p>Assume <span class="math inline">\(\mathbf{H} \in \mathbb{R}^{n
\times d}\)</span> is the representations, and <span class="math inline">\(\mathbf{H} = f(\mathbf{X})\)</span>, then,</p>
<p>Permutation Equivariance: <span class="math inline">\(\mathbf{PH} =
\mathbf{P}f(\mathbf{X}) = f(\mathbf{PX})\)</span>, where <span class="math inline">\(\mathbf{P} \in S_n\)</span> is a permutation
matrix.</p>
<ul>
<li>equivariant first, then move to invariant.</li>
</ul>
<p>Valid set funtions: the function is invariant to the order of the
input.</p>
<p>Theorem: A function <span class="math inline">\(f\)</span> operating
on a set <span class="math inline">\(X\)</span> having elements from a
countable <strong>universe</strong>. If <span class="math inline">\(f\)</span> is a valid set function, then there
exists a function <span class="math inline">\(g\)</span> such that <span class="math inline">\(f(X) = \rho(\sum_{x \in X} \phi(x))\)</span>.</p>
<p>Proof: For the mapping: <span class="math inline">\(f(X) \to
R\)</span>, the domain of <span class="math inline">\(f\)</span> is all
subsets in <span class="math inline">\(X\)</span>. For example: if <span class="math inline">\(X = \{a, b, c\}\)</span>, then the domain is a
<strong>power set</strong> <span class="math inline">\(\{\phi, a, b, c,
\{a, b\}, \{a, c\}, \{b, c\}, \{a, b, c\}\}\)</span>.</p>
<p>Sufficiency: summation is permutation invariant!</p>
<p>Necessity: find an unique representation of any set and then map
it:</p>
<p>why choose 4: base 3,4 ... are ok, but base 2 is not. Since base 2
cannot guarantee the uniqueness of the representation.</p>
<h2 id="deep-learning-for-sequences">Deep learning for Sequences</h2>
<p>Applications:</p>
<ul>
<li><p>Language Model: <span class="math inline">\(P(x^{t+1}| x^{t},
\cdots, x^1)\)</span>, where <span class="math inline">\(x^{t+1}\)</span> is the word we want to
predict.</p></li>
<li><p>Machine Translation.</p></li>
</ul>
<p>Key challenges:</p>
<ul>
<li>Variable length input and output;</li>
<li>Order change may be crucial for cognition;</li>
<li>complex statistical dependencies (e.g. long-range ones).</li>
</ul>
<h3 id="transformer">Transformer:</h3>
<p><img src="/2023/09/11/deep-learning-with-structures/transformer.png"> The
output representation of the final encoder is the input of each
decoder.</p>
<p><img src="/2023/09/11/deep-learning-with-structures/encoder_decoder.png">
The decoder includes self-attention and encoder-decoder attention. For
the self-attention, it uses <strong>masked multi-head
attention</strong>, why????</p>
<p><strong>How to encode the input sequence?</strong></p>
<p><strong>Input embedding:</strong> Construct the one-hot vector for
each word. N words, each word will be mapping to a D dimension vector.
Then, we can get a NxD matrix. D is the hyper-parameter.</p>
<ul>
<li><p>Will the input embedding manners affect the performance of the
model?</p>
<p>In general, we use the same vocabulary dictionary for the input
embedding.</p></li>
</ul>
<p><strong>positional encoding:</strong> <img src="/2023/09/11/deep-learning-with-structures/positional.png"> <span class="math display">\[
\begin{aligned}
PE(pos, 2i) &amp;= sin(pos/10000^{2i/d_{model}}) \\
PE(pos, 2i+1) &amp;= cos(pos/10000^{2i/d_{model}}) \\
\end{aligned}
\]</span></p>
<p>pos is the index of the word in the sentence. (0-30) <span class="math inline">\(2i\)</span> and <span class="math inline">\(2i+1\)</span> is the index of the column, d_model
is the number of columns, it is a hyper-parameter(120). For each
word(token), we encode it to a vector with dimension d_model according
to its position.</p>
<p>Here we use denominator <span class="math inline">\(10000^{2i/d_model}\)</span> to make sure the
positional encoding is different for different tokens. The sin and cos
are periodic functions, if we don't use the denominator, then the
positional encoding could be same for different tokens.</p>
<ul>
<li>If there are two different sentences with the same size, will the
positional encodings be the same?? yes.</li>
</ul>
<p><strong>Self attention:</strong> <span class="math inline">\(X \in
R^{tokes \times dim}\)</span>, <span class="math inline">\(W_Q \in
R^{dim \times dim}\)</span>, <span class="math inline">\(Q = XW_Q \in
R^{tokens \times dim}\)</span>.</p>
<p><span class="math inline">\(softmax(\frac{QK^T}{\sqrt{dim}}) \in
R^{tokens \times tokens}\)</span> is the <strong>attention
matrix</strong>, the dimension must be the same as the number of
tokens.</p>
<p>we apply softmax in individual row, then the output of softmax is
<span class="math inline">\(tokens \times tokens\)</span>.</p>
<p>The final output dimension is <span class="math inline">\(tokens
\times dim\)</span>.</p>
<ul>
<li><p>Why does it need to divide by <span class="math inline">\(\sqrt{dim}\)</span>?</p>
<p>To keep the variance of each entry <span class="math inline">\(QK^T[i,k]\)</span> to be 1. <strong>[approach to
1]</strong>. if we don't preserve the variance, then the gradient will
be larger and larger, and the model will be unstable.</p></li>
</ul>
<p><strong>Multi-head attention</strong> it can capture different
dependency of the input sequence. One choice is to input the same input
embedddings for each attention head, and then aggregate the output of
each attention head. Another choice is to split the input embeddings
into different parts, and then input different parts to different
attention heads. (The problem is not a convex problem, thus the weights
of each attention head may be different.)</p>
<p><strong>Layer normalization</strong> <img src="/2023/09/11/deep-learning-with-structures/layernorm.png"> it is
applied to each row of the output of multi-head attention. It is similar
to batch normalization, but it is applied to each row, not each column.
we want to learn <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\beta\)</span>, because we want to learn the
distribution of each row.</p>
<p><strong>Masked multi-head attention in decoder</strong> The decoder
must be autoregressive. We need to input the previous words to predict
the next word and prevent attending from future. For a attention matrix,
we can mask the upper triangle, then the values masked are zeros. But,
if we mask the upper triangle, the sum of each row is not equal to 1,
thus we need to adjust the attention matrix. Normally, the attention
matrix is: <span class="math display">\[
\begin{aligned}
A = softmax(\frac{QK^T}{\sqrt{dim}})
\end{aligned}
\]</span> The dimension of the attention matrix is <span class="math inline">\(outputtokens \times outputtokens\)</span>. If we
mask <span class="math inline">\(A_{ij}\)</span>, then the input of
softmax function will be: <span class="math display">\[
\begin{aligned}
A_{ij} = \frac{\exp \frac{ \sum_k Q_{ik}K_{jk} -
\infty}{\sqrt{dim}}}{\sum \exp()}
\end{aligned}
\]</span></p>
<p>Shifted right: we already generate one token, and we want to predict
the next token, then we always focus on the right part of the output
sequence.</p>
<p><strong>Cross attention</strong> it is used in the decoder. The input
of the decoder is the output of the encoder. The encoder-decoder
attention is similar to the self attention, but the query is the output
of the decoder, and the key and value are the output of the encoder.
Here the output of encoder is the embaddings, and the docoder can
generate the key and value from the embeddings. Cross attention can
capture the relationship between the input sentence and the output
sentence.</p>
<h2 id="graph-neural-networks-message-passing-models">Graph Neural
Networks Message Passing Models</h2>
<p>Graph: multi-edges, nodes have types, edges have types.</p>
<ul>
<li>connectivity: adjacency list <span class="math inline">\(G = (V,
E)\)</span> and adjacency matrix <span class="math inline">\(A\)</span>.
<span class="math inline">\(|V| = n, |E| = m\)</span>. <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span>.</li>
<li>features: node features <span class="math inline">\(X\)</span>, edge
features, graph features.</li>
</ul>
<p>if you want to permute a graph, then you need to
<strong>left</strong> multiply the permutation matrix to the adjacency
matrix (change rows) and also right multiply the transpose permutation
matrix to the adjacency matrix(change columns): <span class="math display">\[
\begin{aligned}
A' = PAP^T
\end{aligned}
\]</span></p>
<p>For a graph <span class="math inline">\(A_1\)</span>, if there exists
a permutation matrix <span class="math inline">\(P\)</span>, such that
<span class="math inline">\(A_2 = PA_1P^T\)</span>, then <span class="math inline">\(A_1\)</span> and <span class="math inline">\(A_2\)</span> are graph isomorphic.</p>
<p>For a graph <span class="math inline">\(A\)</span>, if there exists a
permutation matrix <span class="math inline">\(P\)</span>, such that
<span class="math inline">\(A = PAP^T\)</span>, then <span class="math inline">\(A\)</span> is graph automorphism.</p>
<p>Given graph data <span class="math inline">\((A, X)\)</span> and
<span class="math inline">\(f(A, X) \in \mathbb{R}^{n \times
d}\)</span>:</p>
<ul>
<li><p>invariance: <span class="math inline">\(f(PAP^T, PX)=f(A,
X)\)</span>, <span class="math inline">\(\forall P \in
S_n\)</span>.</p></li>
<li><p>equivariance: <span class="math inline">\(f(PAP^T, PX) = Pf(A,
X)\)</span>, <span class="math inline">\(\forall P \in
S_n\)</span>.</p></li>
</ul>
<p>Key challenges:</p>
<ul>
<li>unordered neighbors;</li>
<li>variable size of neighbors;</li>
<li>varying graph partitions.</li>
</ul>
<h3 id="message-passing-in-gnns">Message Passing in GNNs</h3>
<p>Feedforward networks: layers do not share message passing module.
[don't share weights]. Usually, we call it 'layers'.</p>
<p>Recurrent networks: layers share message passing module.[reuse
weights]. Usually, we call it 'steps' instead of 'layers'.</p>
<p>Even if we increase the number of nodes and edges, the model can
still work.</p>
<p><strong>ONLY USE ONE NETWORK FOR ALL NEIGHBORS</strong>, same across
edges. if we use different networks for each neighbor, changing the
number of nodes will affect the model. The model is not invariant to the
number of nodes.</p>
<p>For undirected graph, the message passing is symmetric, i.e., m_ij =
m_ji. It doesn't related to the order of nodes. For directed graph, m_ij
may not equal to m_ji.</p>
<p>We can also use transformers or gcn or LSTM to implement the message
passing. Be careful that LSTM is not permutation invariant.</p>
<p>Tips: parallel message passing: compute messages for all nodes/edges
and compute updates for all nodes in parallel. Use dense operators on
GPUs.</p>
<p>privacy and robust to attack in gnn.</p>
<p>we can also use transformers in encoding graph structure as an
attention mask.</p>
<h2 id="graph-convolutional-networks">Graph Convolutional Networks</h2>
<p>laplace operator is the eigenfuction, why?</p>
<p>For <strong>undirected</strong> graph, Graph Laplacian: <span class="math inline">\(L = D - A\)</span>, where <span class="math inline">\(D\)</span> is the degree matrix, <span class="math inline">\(A\)</span> is the adjacency matrix. Laplacian
matrix can compute the difference between the node and its neighbors. It
is symmetric, diagonally dominant, positive semi-definite(eigenvalues
are nonnegative), and the number of zero eigenvalues is the number of
connected components.</p>
<ul>
<li>Translation group;</li>
<li>Roto-translation group: SO(n): <span class="math inline">\(Q \in
\mathbb{R}^{n \times n}, Q^TQ = Q Q^T = I, det(Q) = 1.\)</span></li>
</ul>
<p><span class="math inline">\(g = (X, R_\theta), g' = (X',
R_{\theta'})\)</span></p>
<p><span class="math inline">\(g \cdot g' = g \cdot g' (x_0) =
g(R_{\theta'}x_0 + X') = R_{\theta}R_{\theta'}x_0 +
R_{\theta}X' + X = (R_{\theta'}X' + X, R_{\theta +
\theta'})\)</span></p>
<ul>
<li>Scale-translation group.</li>
<li>Affine group.</li>
</ul>
<p>cross-correlations: <span class="math inline">\(f \star g (x) = \int
f(x'-x)g(x')dx'\)</span>, in mathmetics, the order of
convolution is inverse to the order in DL.</p>
<h2 id="autoregressive-models">Autoregressive Models</h2>
<p>Autoregressive model： <span class="math display">\[
\begin{aligned}
P(x_1, \cdots, x_n) = \prod_{i=1}^n P(x_i|x_1, \cdots, x_{i-1}) =
\prod_{i=1}^n P(x_i|x_{&lt;i})
\end{aligned}
\]</span></p>
<p>For images, each <span class="math inline">\(x_i\)</span> is a pixel
value, e.g., {0,...,255}. n = height * width. Each term <span class="math inline">\(P(x_i|x_{&lt;i})\)</span> can be modeled by a
single CNN/RNN/....</p>
<p>Why do we consider the same model for each term? Otherwise, the
number of model is O(n).</p>
<p>PixelCNNs: conditioned on the pixels above and to the left of the
pixel being predicted. At each step, we will mask the pixels below and
right of the pixel being predicted. Then we use convolution on the
image, but it will yield high computation cost.</p>
<p>PixelRNNs: vectorize the image as a sequence of pixels, and then use
RNN to model the sequence.</p>
<p>Masked Filter: we mask the filter to make sure the convolution is
autoregressive. But it will yield blind spots.</p>
<p>blind spots: the model cannot see the pixels below and right of the
pixel being predicted.</p>
<p>resovle blind spots: use a stack of masked convolutions.</p>
<p>The cons of softmax: if the number of dimension is very large, then
the softmax will be very small. Thus we use the discretized mixture
logistic distribution: <span class="math display">\[
\begin{aligned}
P(x) = \sum_{k=1}^K \pi_k \sigma(\frac{x - \mu_k}{s_k})
\end{aligned}
\]</span> where <span class="math inline">\(\sigma\)</span> is the
sigmoid function, <span class="math inline">\(\pi_k\)</span> is the
weight of the <span class="math inline">\(k\)</span>-th component, <span class="math inline">\(\mu_k\)</span> is the mean of the <span class="math inline">\(k\)</span>-th component, <span class="math inline">\(s_k\)</span> is the scale of the <span class="math inline">\(k\)</span>-th component.</p>
<p>Due to the sequential nature of autoregressive sampling, it is
slow.</p>
<ul>
<li><p>will autoregressive model focus more on the nearby locations?
yes, because we use masked convolutions.</p></li>
<li><p>For directed graphs, we can generate the lower triangle of the
adjacency matrix, and then generate the upper triangle.</p></li>
</ul>
<h2 id="generative-adversarial-networks-gans">Generative Adversarial
Networks (GANs)</h2>
<p>Generative models: generate data from noise.</p>
<p>Min-max loss: <span class="math display">\[
\begin{aligned}
\min_{\theta} \max_{\phi}\mathbb{E}_{x \sim p_{data}(x)}[\log
D_{\phi}(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 -
D_{\phi}(G_{\theta}(z)))]
\end{aligned}
\]</span> where <span class="math inline">\(D\)</span> is the
discriminator, <span class="math inline">\(G\)</span> is the generator,
<span class="math inline">\(x\)</span> is the real data, <span class="math inline">\(z\)</span> is the noise, <span class="math inline">\(p_{data}\)</span> is the distribution of the real
data, <span class="math inline">\(p_z\)</span> is the distribution of
the noise.</p>
<p>The fake images are generated from noise (normal distribution), we
can not get the distribution of fake images. Why? Because the mapping
from noise to fake images is not invertible. Thus, we cannot get the
likelihood of the fake images.</p>
<p>GAN is also called likihood-free model. We cannot get the likelihood
of the fake images.</p>
<p>For GANs, we can get images through one forward pass, but for
autoregressive model, we need to generate images pixel in a sequential
manner.</p>
<p>The output of the discriminator is a scalar, the probability of the
input image being real. The output of the generator is an image.</p>
<p>Fix generator, the optimal discriminator is: <span class="math display">\[
\begin{aligned}
D_{\phi}^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_{G_{\theta}}(x)}
\end{aligned}
\]</span> where <span class="math inline">\(p_{G_{\theta}}(x)\)</span>
is the distribution of the fake images. When <span class="math inline">\(p_{G_{\theta}}(x) = p_{data}(x)\)</span>, then
<span class="math inline">\(D_{\phi}^*(x) = 0.5\)</span>. However, we
don't know the distribution of the fake images and the distribution of
the real images.</p>
<p>inner-loop is the discriminator, outer-loop is the generator. why?
focus more on the generator, because the discriminator is easy to train
??</p>
<h2 id="paper-graph-convolutional-autoencoders-with-co-learning-of-graph-structure-and-node-attributes">[paper]
Graph convolutional autoencoders with co-learning of graph structure and
node attributes</h2>
<p>In this paper, they design the special graph encoder and decoder for
the tasks undertaken by the graph autoencoders. The task of the encoder
is to embed the nodes into a new space, and then the latent
representation of each node is close to its neighbors[the encoder is a
low-pass filter]. The decoder restores the original space from the
embedded space by making the latent representation of each node away
from its neighbors[the decoder is a high-pass filter].</p>
<p>In this paper, they encode both the graph structure and the node
attributes in the latent space with an improved GCN, which is a
<strong>completely low-pass graph filter</strong>. Then, to reconstruct
the node attributes X , they design a new <strong>high-pass graph
decoder</strong>. At the same time, we use the inner product layer to
reconstruct the graph structure information. Last, the graph encoder and
two sub-decoders are jointly optimized in a unified framework in such a
way that each can be beneficial to the other and finally lead to a
better graph embedding.</p>
<h3 id="normalized-adjacency-matrix-and-laplacian-matrices">Normalized
adjacency matrix and Laplacian matrices</h3>
<p>1, The normalized adjacency matrix is defined as: <span class="math display">\[\hat{A} = D^{-1/2}A D^{-1/2},\]</span> where
<span class="math inline">\(A\)</span> is the adjacency matrix of graph
<span class="math inline">\(G\)</span>. <span class="math inline">\(D =
diag(d)\)</span>, <span class="math inline">\(d(i)\)</span> is the
degree of node <span class="math inline">\(i\)</span>.</p>
<p>2, The normalized Laplacian matrix is defined as: <span class="math display">\[L_s = I - \hat{A} = I - D^{-1/2}A
D^{-1/2}.\]</span> Note that <span class="math inline">\(L_s = I -
\hat{A} = D^{-1/2}(D - A) D^{-1/2} = D^{-1/2}L D^{-1/2}\)</span>, where
<span class="math inline">\(L = D - A\)</span> is the unnormalized
Laplacian matrix of graph <span class="math inline">\(G\)</span>.</p>
<p>For the largest eigenvalue <span class="math inline">\(\lambda^s\)</span> of <span class="math inline">\(A\)</span> and the maximum degree <span class="math inline">\(\Delta\)</span> of a node in a graph, we have $
d_{avg} ^s $. Normalizing the adjacency matrix can make its largest
eigenvalue 1.</p>
<p>3, Let <span class="math inline">\(\alpha_1 \geq \alpha_2 \geq ...
\geq \alpha_n\)</span> be the eigenvalues of <span class="math inline">\(\hat{A}\)</span>, <span class="math inline">\(\lambda^s_1 \leq \lambda^s_2 \leq ... \leq
\lambda^s_n\)</span> be the eigenvalues of <span class="math inline">\(L_s\)</span>, then <span class="math display">\[ 1
= \alpha_1 \geq ... \geq \alpha_n \geq -1, \quad 0=\lambda^s_1 \leq ...
\leq \lambda^s_n \leq 2.\]</span></p>
<h3 id="graph-convolutional-networks-1">Graph convolutional
networks</h3>
<p>GCN generalizes the convolutional neural networks on non-Euclidean
domains. It uses the first-order approximation of Chebyshev polynomials:
<span class="math display">\[
g_{\theta} \star x \approx \theta (I_N + D^{-1/2}AD^{-1/2})X.
\]</span> The spectral radius of <span class="math inline">\((I_N +
D^{-1/2}AD^{-1/2})\)</span> is 2, and repeated application of this
operator will cause numerical instabilities. To solve this problem, GCN
uses a renormalization trick by adding a self-loop to each node, which
is equivalent to adding the identity matrix <span class="math inline">\(I_N\)</span> to the adjacency matrix <span class="math inline">\(A\)</span>: <span class="math inline">\(\tilde{A}
= A + I\)</span>, the associated degree matrix <span class="math inline">\(\tilde{D} = D + I\)</span>. The new symmetrically
normalized matrix is <span class="math inline">\(\tilde{A}_{GCN} =
\tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}\)</span>. The one-layer GCN
is <span class="math display">\[
Z^{(m+1)} = \sigma(\tilde{A}_{GCN}Z^{(m)}W^{(m)}),
\]</span> where <span class="math inline">\(Z^{(m)}\)</span> is the
latent representation matrix learned by the <span class="math inline">\(m\)</span>-th layer, <span class="math inline">\(Z^{(0)} = X\)</span>.</p>
<h3 id="graph-signal-processing">Graph signal processing</h3>
<p>In graph signal processing , the eigenvalues and eigenvectors of the
graph Laplacian correspond to the frequencies and Fourier basis.</p>
<p>The graph laplacian is defined as <span class="math inline">\(L =
D-A\)</span>. By eigen-decomposition, <span class="math inline">\(L = U
\Lambda U^{-1}\)</span>, where <span class="math inline">\(\Lambda =
diag(\lambda_1, ..., \lambda_n)\)</span>, <span class="math inline">\(U
= (u_1, u_2, ..., u_n)\)</span>. The eigenvalues <span class="math inline">\(\lambda_i, i \in [n]\)</span> can be considered to
be frequencies, and the associated eigenvectors <span class="math inline">\(u_i, i \in [n]\)</span> can be considered to be a
Fourier basis.</p>
<p>A graph signal <span class="math inline">\(f\)</span> can be
decomposed into a linear combination of basis signals <span class="math inline">\(u_i\)</span>: <span class="math display">\[
f = Uc = \sum_{i=1}^n c_i u_i,
\]</span> where <span class="math inline">\(c = (c_1, ...,
c_n)^T\)</span>, <span class="math inline">\(c_i\)</span> is the
coefficient of <span class="math inline">\(u_i\)</span>, the magnitude
of <span class="math inline">\(c_i\)</span> represents the importance of
<span class="math inline">\(u_i\)</span> in <span class="math inline">\(f\)</span>.</p>
<p>The smoothness of the basis signal <span class="math inline">\(u_i\)</span> is measured by the corresponding
eigenvalue <span class="math inline">\(\lambda_i\)</span>. The smaller
the eigenvalue <span class="math inline">\(\lambda_i\)</span>, the
smoother the basis signal <span class="math inline">\(u_i\)</span>.
<span class="math display">\[
\sum_{e_{j,k} \in E} a_{j,k}[u_i(j) - u_i(k)]^2 = u_i^T L u_i =
\lambda_i u_i^T u_i = \lambda_i.
\]</span></p>
<p>The basic idea of graph filtering is to design a proper graph filter
to produce the required signals for the downstream tasks. A graph filter
is a function that takes a graph signal as input and <strong>outputs a
new signal</strong>. A linear graph filter can be represented as a
matrix <span class="math inline">\(G \in \mathbb{R}^{N \times
N}\)</span>, which is defined as <span class="math display">\[
G = U p(\Lambda) U^{-1},
\]</span> where <span class="math inline">\(p(\Lambda) =
diag(p(\lambda_1), ..., p(\lambda_n))\)</span>. <span class="math inline">\(p(\cdot)\)</span> is the frequency response
function.</p>
<p>The output signal can be written as <span class="math display">\[
y = Gf = U p(\Lambda) U^{-1} Uc = U p(\Lambda) c = \sum_{i=1}^n
p(\lambda_i) c_i u_i.
\]</span></p>
<p>Definition 1 (completely low-pass graph filter). A completely
low-pass graph filter is a graph filter whose frequency response
function <span class="math inline">\(p(\cdot): \mathbb{R} \to
\mathbb{R}^{+}\)</span> is a decreasing function with <span class="math inline">\(\lambda\)</span>.</p>
<ul>
<li>According to definition 1, the completely low-pass graph filter
obtains a smooth graph output signal <span class="math inline">\(y\)</span> that consists of mostly low-frequency
basis signals, and as a result, the latent representation of each node
is close to its neighbors.</li>
</ul>
<p>Definition 2 (completely high-pass graph filter). A completely
high-pass graph filter is a graph filter whose frequency response
function <span class="math inline">\(p(\cdot): \mathbb{R} \to
\mathbb{R}^{+}\)</span> is an increasing function with <span class="math inline">\(\lambda\)</span>.</p>
<p>According to definition 2, the completely high-pass graph filter
obtains an unsmooth graph output signal <span class="math inline">\(y\)</span> that consists of mostly high-frequency
basis signals, which makes the latent representation of each node far
away from its neighbors.</p>
<p>For GCN, the graph filter of GCN is <span class="math display">\[
\tilde{A}_{GCN} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} = I - L_s
= U (I - \Lambda^s) U^{-1}.
\]</span> The frequency response function of GCN is <span class="math inline">\(p(\lambda^s_i) = 1 - \lambda_i^s\)</span>. Since
the range of <span class="math inline">\(\lambda_i^s\)</span> is <span class="math inline">\([0, 2]\)</span>, the frequency response function
of GCN is a decreasing function with <span class="math inline">\(\lambda_i^s\)</span>. GCN is completely low-pass
graph filter when <span class="math inline">\(\lambda_i^s \in [0,
1]\)</span>, but not in <span class="math inline">\([1, 2]\)</span>.
When <span class="math inline">\(\lambda_i^s \in [1, 2]\)</span>, <span class="math inline">\(p(\lambda^s_i)\)</span> will take a negative value
that will introduce noise and undermine the performance. Thus, GCN is
not a completely low-pass graph filter.</p>
<h2 id="the-difference-between-adam-and-adamw">The difference between
Adam and AdamW</h2>
<p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/why-adamw-matters-736223f31b5d" class="uri">https://towardsdatascience.com/why-adamw-matters-736223f31b5d</a></p>
<h2 id="why-regularization-can-reduce-overfitting">Why regularization
can reduce overfitting?</h2>
<p><a target="_blank" rel="noopener" href="http://neuralnetworksanddeeplearning.com/chap3.html#regularization" class="uri">http://neuralnetworksanddeeplearning.com/chap3.html#regularization</a></p>
<h2 id="cosine-decay-schedule-with-warm-up-period">Cosine decay schedule
with warm up period</h2>
<p>Loshchilov and Hutter, SGDR: Stochastic Gradient Descent with Warm
Restarts. ICLR 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1608.03983" class="uri">https://arxiv.org/abs/1608.03983</a></p>
<p><a target="_blank" rel="noopener" href="https://scorrea92.medium.com/cosine-learning-rate-decay-e8b50aa455b" class="uri">https://scorrea92.medium.com/cosine-learning-rate-decay-e8b50aa455b</a></p>
<h2 id="reference">Reference</h2>
<p><a target="_blank" rel="noopener" href="https://lrjconan.github.io/UBC-EECE571F-DL-Structures/">EECE
571F (2023 Winter Term 1): Deep Learning with Structures</a></p>
<p>http://cs231n.stanford.edu/slides/2018/cs231n_2018_ds02.pdf</p>
<p><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-transformer/" class="uri">https://jalammar.github.io/illustrated-transformer/</a></p>
<p><a target="_blank" rel="noopener" href="https://uvagedl.github.io/">UvA - An Introduction to Group
Equivariant Deep Learning</a></p>
<p>Jie Wang, Jiye Liang, Kaixuan Yao, Jianqing Liang, Dianhui Wang,Graph
convolutional autoencoders with co-learning of graph structure and node
attributes,Pattern Recognition,Volume 121,2022,108215,ISSN 0031-3203, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.patcog.2021.108215" class="uri">https://doi.org/10.1016/j.patcog.2021.108215</a>.</p>
<p><a target="_blank" rel="noopener" href="https://people.orie.cornell.edu/dpw/orie6334/Fall2016/lecture7.pdf" class="uri">https://people.orie.cornell.edu/dpw/orie6334/Fall2016/lecture7.pdf</a></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://xueyu-ubc.github.io/2023/09/11/deep-learning-with-structures/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning-with-Structures/" rel="tag">Deep Learning with Structures</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2023/10/21/Monte-Carlo-Gradient-Estimation/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Monte Carlo Gradient Estimation in Machine Learning
          
        </div>
      </a>
    
    
      <a href="/2023/08/27/KS_test/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Kolmogorov-Smirnov statistic</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "",
    app_key: "",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021-2025
        <i class="ri-heart-fill heart_icon"></i> Xue Yu
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Welcome to XueYu&#39;s Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2021/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i></p>
  <div class="reward-box">
    
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>
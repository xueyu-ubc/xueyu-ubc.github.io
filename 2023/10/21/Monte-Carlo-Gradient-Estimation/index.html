<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="I am a second PhD student at Renmin University of China. My research interests include federated learning, high dimensional data, machine learning, and optimization. I am currently working on latent graph learning in Prof.Renjie Liao&#39;s group." />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Monte Carlo Gradient Estimation in Machine Learning |  Welcome to XueYu&#39;s Blog
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

<link rel="alternate" href="/atom.xml" title="Welcome to XueYu's Blog" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" />
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

</html>
<script src="/js/hexo_resize_image.js"></script>
<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-Monte-Carlo-Gradient-Estimation"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Monte Carlo Gradient Estimation in Machine Learning
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2023/10/21/Monte-Carlo-Gradient-Estimation/" class="article-date">
  <time datetime="2023-10-21T15:00:00.000Z" itemprop="datePublished">2023-10-21</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">7.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">44 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="monte-carlo-methods-and-stochastic-optimisation">Monte Carlo
Methods and Stochastic Optimisation</h1>
<p>The mean-value analysis problem: <span class="math display">\[
\mathcal{F}(\theta) := \int p(x; \theta) f(x; \phi) \text{d}x =
\mathbb{E}_{p(x; \theta)} f(x; \phi),  \enspace (1)
\]</span> where <span class="math inline">\(f(x; \phi)\)</span> is the
cost with parameters <span class="math inline">\(\phi\)</span>, <span class="math inline">\(p(x;\theta)\)</span> is the measure, a probability
distribution that is continuous in its domain and differentiable with
<span class="math inline">\(\theta\)</span>.</p>
<p>This objective is very common in variational inference, reinforcement
learning, etc.</p>
<p>To learn the distribution parameter <span class="math inline">\(\theta\)</span>, we need to consider the gradient:
<span class="math display">\[
\eta := \nabla_{\theta} \mathcal{F}(\theta) = \nabla_{\theta}
\mathbb{E}_{p(x; \theta)} f(x; \phi). \enspace  (2)
\]</span> <span class="math inline">\(\eta\)</span> is called the
sensitivity analysis of <span class="math inline">\(\mathcal{F}\)</span>.</p>
<p>Problems:</p>
<ul>
<li>not able to evaluate the expectation in closed form;</li>
<li><span class="math inline">\(x\)</span>: high-dimensional, <span class="math inline">\(\theta\)</span>: high-dimensional;</li>
<li>the cost funtion may not be differential or a black-box
function.</li>
</ul>
<h2 id="monte-carlo-estimators">Monte Carlo Estimators</h2>
<p>We can numerically evaluate the integral by first drawing
<strong>independent</strong> samples <span class="math inline">\(\hat{x}^{(1)}, ..., \hat{x}^{(N)}\)</span> from
the distribution <span class="math inline">\(p(x; \theta)\)</span>, and
then computing the averaged of the function evaluated at these samples:
<span class="math display">\[
\bar{\mathcal{F}}_N = \frac{1}{N} \sum_{n=1}^{N} f(\hat{x}^{(n)}),
\qquad \hat{x}^{(n)} \sim p(x; \theta), \quad n = 1,..., N.
\]</span> <span class="math inline">\(\bar{\mathcal{F}}_N\)</span> is a
random variable and is called Monte Carlo estimator of eq. (1).</p>
<p>Remark 1. As long as we can write an integral in the form of eq. (1)
(a product of a function and a distribution that we can easily sample
from), we can apply the Monte Carlo method.</p>
<h3 id="four-properties">Four Properties</h3>
<ul>
<li><p>Consistency. As <span class="math inline">\(N \to
\infty\)</span>, the estimator <span class="math inline">\(\bar{\mathcal{F}}_N \to \mathbb{E}_{p(x; \theta)}
f(x; \phi)\)</span>. This can be easily satisfied according to the
strong law of large number.</p></li>
<li><p>Unbiasedness. <span class="math display">\[
\mathbb{E}_{p(x; \theta)} [\bar{\mathcal{F}}_N] = \mathbb{E}_{p(x;
\theta)} [\frac{1}{N} \sum_{n=1}^{N} f(\hat{x}^{(n)})] = \frac{1}{N}
\sum_{n=1}^{N} \mathbb{E}_{p(x; \theta)} [f(\hat{x}^{(n)})] =
\mathbb{E}_{p(x; \theta)}[f(x)].
\]</span> (if we repeat the estimation process many times, the estimate
is centered on the the actual value of the integral on average)</p></li>
<li><p>Minimum variance. If we consider two <strong>unbiased</strong>
estimators using the same number of sampling <span class="math inline">\(N\)</span>, we will prefer the estimator that has
lower variance. [<strong>if MC estimator has the minimum
variance?</strong>]</p></li>
<li><p>Computational efficiency. for example: a computational cost
linear in the number of parameters, can be computed in
parallel.</p></li>
</ul>
<h3 id="the-central-role-of-gradient-estimation-eq.-2">The central role
of Gradient Estimation eq. (2)</h3>
<p>some examples in different areas.</p>
<h4 id="variational-inference">Variational Inference</h4>
<p>Variational inference is a general method for approximating complex
and unknown distributions by the closest distribution within a tractable
family. Consider a generic probabilistic model <span class="math inline">\(p(x|z)p(z)\)</span> that defines a generative
process in which observed data <span class="math inline">\(x\)</span> is
generated from a set of unobserved variables z using a data distribution
<span class="math inline">\(p(x|z)\)</span> and a prior distribution
<span class="math inline">\(p(z)\)</span>. The posterior distribution of
this generative process <span class="math inline">\(p(z|x)\)</span> is
unknown, and is approximated by a variational distribution <span class="math inline">\(q(z|x; \theta)\)</span> with variational
parameters <span class="math inline">\(\theta\)</span>. The objective is
<span class="math display">\[
\max_{\theta, \phi} \mathbb{E}_{q(z|x;\theta)} [\log p(x|z;\phi) - \log
\frac{q(z|x;\theta)}{p(z)}].
\]</span> Optimising the distribution <span class="math inline">\(q\)</span> requires the gradient of the objective
with respect to the variational parameters <span class="math inline">\(\theta\)</span>: <span class="math display">\[
\eta = \nabla_{\theta}\mathbb{E}_{q(z|x;\theta)} [\log p(x|z;\phi) -
\log \frac{q(z|x;\theta)}{p(z)}].
\]</span></p>
<h4 id="reinforcement-learning">Reinforcement Learning</h4>
<p>Model-free policy search is an area of reinforcement learning where
we learn a policy|a distribution over actions|that on average maximises
the accumulation of long-term rewards. Through interaction in an
environment, we can generate trajectories <span class="math inline">\(\tau = (s_1, a_1, s_2, a_2, ... , s_T , a_T
)\)</span> that consist of pairs of states st and actions at for time
period <span class="math inline">\(t = 1, ... , T\)</span>. A policy is
learnt by following the policy gradient:</p>
<p><span class="math display">\[
\eta = \nabla_{\theta} \mathbb{E}_{p(\tau;\theta)} [\sum_{t=0}^{T}
\gamma^t r(s_t,a_t)]
\]</span> The cost is the return over the trajectory, which is a
weighted sum of rewards obtained at each time step <span class="math inline">\(r(s_t, a_t)\)</span>, with the discount facthor
<span class="math inline">\(\gamma \in [0, 1]\)</span>. The measure is
the joint distribution over states and actions <span class="math inline">\(p(\tau;\theta) = \prod_{t=0}^{T-1} [p(s_{t+1}|s_t,
a_t)p(a_t|s_t; \theta)]p(a_T |s_T ; \theta)\)</span>.</p>
<h2 id="intuitive-analysis-of-gradient-estimators">Intuitive Analysis of
Gradient Estimators</h2>
<p>The gradients <span class="math inline">\(\nabla_{\theta}
\mathbb{E}_{p(x;\theta)}[f(x)]\)</span> can be computed in two ways:</p>
<ul>
<li><p>Derivatives of Measure. The gradient can be computed by
differentiation of the measure <span class="math inline">\(p(x;
\theta)\)</span>. Gradient estimators in this class include the score
function estimator and the measure-valued gradient.</p></li>
<li><p>Derivatives of Paths. The gradient can be computed by
differentiation of the cost <span class="math inline">\(f(x)\)</span>,
which encodes the pathway from parameters <span class="math inline">\(\theta\)</span>, through the random variable <span class="math inline">\(x\)</span>, to the cost value, such as the
pathwise gradient, harmonic gradient estimators and finite dfferences,
and Malliavin-weighted estimators.</p></li>
</ul>
<p>We focus on three classes of gradient estimators: the score function,
pathwise and measure-valued gradient estimators. <strong>All three
estimators satisfy two desirable properties: consistent and unbiased;
but they differ in their variance behaviour and in their computational
cost.</strong></p>
<h3 id="intuitive-comparision">Intuitive comparision</h3>
<p>Consider the stochastic gradient problem (2) that uses Gaussian
measures for three simple families of cost functions, quadratics,
exponentials and cosines: <span class="math display">\[
\eta = \nabla_{\theta} \int \mathcal{N}(x | \mu, \sigma^2) f(x; k)
\text{d}x; \quad \theta \in \{\mu, \sigma \}; \quad f \in \{ (x-k)^2,
\exp(-kx^2), \cos(kx)\}.
\]</span></p>
<p><img src="/2023/10/21/Monte-Carlo-Gradient-Estimation/figure2.png"></p>
<p><img src="/2023/10/21/Monte-Carlo-Gradient-Estimation/figure3.png"></p>
<p>The computational cost:</p>
<ul>
<li><p>Both of the score-function and pathwise estimators can be
computed using a single sample in the Monte Carlo estimator (N = 1),
even for multivariate distributions, making them computationally
cheap.</p></li>
<li><p>The measure-valued derivative estimator will require 2D
evaluations of the cost function for D dimensional parameters, and for
this the reason will typically not be preferred in high-dimensional
settings.</p></li>
<li><p>If the cost function is not differentiable, then the pathwise
gradient will not be applicable.</p></li>
</ul>
<p>Several criteria to be judged when choosing an unbiased gradient
estimator:</p>
<ul>
<li>computational cost;</li>
<li>implications on the use of differentiable and non-differentiable
cost functions;</li>
<li>the change in behaviour as the cost itself changes;</li>
<li>the availability of effective variance reduction techniques to
achieve low variance.</li>
</ul>
<h1 id="score-function-gradient-estimators-likelihood-ratio-method-reinforce-estimator">Score
Function Gradient Estimators (likelihood ratio method, REINFORCE
estimator)</h1>
<h2 id="score-function">Score function</h2>
<p>The score function is the derivative of the log-probability of the
distribution <span class="math inline">\(\nabla_{\theta} \log p(x;
\theta)\)</span> with respect to its parameters <span class="math inline">\(\theta\)</span>: <span class="math display">\[
\nabla_{\theta} \log p(x; \theta) = \frac{\nabla_{\theta} p(x;
\theta)}{p(x; \theta)}.
\]</span></p>
<p>properties: 1, Its expectation is zero: <span class="math display">\[\mathbb{E}_{p(x; \theta)} [\nabla_{\theta} \log
p(x; \theta)] = \int p(x; \theta) \frac{\nabla_{\theta} p(x;
\theta)}{p(x; \theta)} \text{d}x =  \nabla_{\theta} \int p(x; \theta)
\text{d}x = \nabla_{\theta} 1 = 0.\]</span></p>
<p>2, Its variance is the Fisher information matrix.</p>
<p>Using the score function, we can derive a general-purpose estimator
for the sensitivity analysis of eq. (2): <span class="math display">\[
\begin{aligned}
\eta &amp;= \nabla_{\theta} \mathbb{E}_{p(x; \theta)} [f(x)] \\
&amp;= \nabla_{\theta} \int p(x; \theta) f(x) \text{d}x \\
&amp;= \int f(x) \nabla_{\theta} p(x; \theta) \text{d}x \\
&amp;= \int p(x; \theta) f(x) \nabla_{\theta} \log p(x; \theta)
\text{d}x \\
&amp;= \mathbb{E}_{p(x; \theta)} [f(x) \nabla_{\theta} \log p(x;
\theta)].
\end{aligned}
\]</span> The form is what we need - a product of a distribution we can
sample from and a function we can evaluate. Then, use the Monte Carlo
estimator, we have <span class="math display">\[
\bar{\eta} = \frac{1}{N} \sum_{n=1}^{N} f(\hat{x}^{(n)}) \nabla_{\theta}
\log p(\hat{x}^{(n)}; \theta), \quad \hat{x}^{(n)} \sim p(x; \theta).
\]</span></p>
<p><strong>Notice that, in the third line, we have exchanged the order
of the integral and the derivative. We will discuss the validity of this
exchange later.</strong></p>
<h2 id="estimator-properties">Estimator Properties</h2>
<h3 id="unbiasedness">Unbiasedness</h3>
<p>When the interchange between differentiation and integration is
valid, we will obtain an <strong>unbiased</strong> estimator of the
gradient. Intuitively, since differentiation is a process of limits, the
validity of the interchange will relate to the conditions for which it
is possible to exchange limits and integrals, in such cases most often
relying on the use of the <strong>dominated convergence theorem or the
Leibniz integral rule</strong> (Flanders, 1973; Grimmett and Stirzaker,
2001). The interchange will be valid if the following conditions are
satisfied:</p>
<ol type="a">
<li><p>The measure <span class="math inline">\(p(x; \theta)\)</span> is
continuously differentiable with respect to <span class="math inline">\(\theta\)</span>;</p></li>
<li><p>The product <span class="math inline">\(f(x) p(x;
\theta)\)</span> is both integrable and differentiable for <span class="math inline">\(\theta\)</span>;</p></li>
<li><p>There exists an integrable function <span class="math inline">\(g(x)\)</span> such that <span class="math inline">\(\sup_{\theta} \|f(x) \nabla_{\theta} p(x; \theta)
\|_1 \leq g(x)\)</span> for <span class="math inline">\(\forall
x\)</span>.</p></li>
</ol>
<p>These assumptions usually hold in machine learning applications.</p>
<h3 id="abosolute-continuity">Abosolute Continuity</h3>
<ul>
<li><p>Example (Bounded support). Consider the score-function estimator
for a cost <span class="math inline">\(f(x) = x\)</span> and
distribution <span class="math inline">\(p(x; \theta) = \frac{1}{\theta}
1_{0 &lt; x &lt; \theta}\)</span>, which is differential in <span class="math inline">\(\theta\)</span> when <span class="math inline">\(x
\in (0, \theta)\)</span>; the score function is <span class="math inline">\(\nabla_{\theta} \log p(x; \theta) =
-\frac{1}{\theta}\)</span>. The true gradient is: <span class="math inline">\(\nabla_{\theta} \mathbb{E}_{p(x;\theta)} [x] =
\nabla_{\theta} (\frac{1}{\theta} \int_{0}^{\theta} \frac{x^2}{2}) =
\frac{1}{2}\)</span>. The score-funtion gradient is: <span class="math inline">\(\mathbb{E}_{p(x;\theta)} [x \frac{-1}{\theta}] =
-\frac{\theta/2}{\theta} = -\frac{1}{2}\)</span>.</p>
<p>Why the score-function estimator fails to provide the correct
gradient? The reason is that the measure is not absolutely continuous
with respect to <span class="math inline">\(\theta\)</span> at the
boundary of the support.</p></li>
</ul>
<p>Let's explain the absolute continuity in detail. <span class="math display">\[
\begin{aligned}
  \nabla_{\theta} \mathbb{E}_{p(x;\theta)}[f(x)] &amp;= \int
\nabla_{\theta} p(x;\theta) f(x) \text{d}x \\
&amp;= \int \lim_{h \to 0} \frac{p(x; \theta + h) - p(x;\theta)}{h} f(x)
\text{d}x \\
&amp;= \lim_{h \to 0} \frac{1}{h} \int p(x; \theta) \frac{p(x; \theta +
h) - p(x;\theta)}{p(x;\theta)} f(x) \text{d}x\\
&amp;= \lim_{h \to 0} \frac{1}{h} \int p(x; \theta) (\frac{p(x; \theta +
h)}{p(x;\theta)}-1) f(x)  \text{d}x\\
&amp;= \lim_{h \to 0} \frac{1}{h}
(\mathbb{E}_{p(x;\theta)}[\omega(\theta, h) f(x)] -
\mathbb{E}_{p(x;\theta)}[f(x)])   
\end{aligned}
\]</span> where the ratio <span class="math inline">\(\omega(\theta, h)
:= \frac{p(x; \theta+h)}{p(x;\theta)}\)</span>. The estimator makes an
implicit assumption of absolute continuity, where <strong>we require
<span class="math inline">\(p(x; \theta+h) &gt; 0\)</span> for all
points where <span class="math inline">\(p(x; \theta) &gt;
0\)</span>.</strong> Not all distributions of interest satisfy this
property, and failures of absolute continuity can result in a biased
gradient.</p>
<h3 id="estimator-variance">Estimator Variance</h3>
<p>Define the estimator mean as <span class="math inline">\(\mu(\theta)
:= \mathbb{E}_{p(x;\theta)}[\bar{\eta}_N]\)</span>, for <span class="math inline">\(N=1\)</span>, The variance of the score function
estimator is: <span class="math display">\[
\begin{aligned}
\text{Var}_{p(x;\theta)}(\bar{\eta}_1) &amp;=
\mathbb{E}_{p(x;\theta)}[(f(x) \nabla_{\theta} \log p(x; \theta))^2] -
\mu(\theta)^2,
\end{aligned}
\]</span> or <span class="math display">\[
\begin{aligned}
\text{Var}_{p(x;\theta)}(\bar{\eta}_1) &amp;= \lim_{h \to 0} \frac{1}{h}
\mathbb{E}_{p(x;\theta)}[(\omega(\theta, h) - 1)^2f(x)^2] -
\mu(\theta)^2, \\
&amp; \geq \sup_{h} \frac{(\mu(\theta + h) -
\mu(\theta))^2}{\mathbb{E}_{p(x;\theta)}[\omega(\theta, h) - 1]^2}.
\end{aligned}
\]</span> Three sources of variance:</p>
<ul>
<li><p>importance ratio <span class="math inline">\(\omega(\theta,
h)\)</span> (the need for absolute continuity);</p></li>
<li><p>The dimensionality of the parameters <span class="math inline">\(x\)</span>;</p></li>
<li><p>The variance of the cost function <span class="math inline">\(f(x)\)</span>.</p></li>
</ul>
<p><img src="/2023/10/21/Monte-Carlo-Gradient-Estimation/figure4.jpg"></p>
<h3 id="computational-cost">Computational Cost</h3>
<p>The computational cost of the score function estimator is low, it is
the order of <span class="math inline">\(O(N(D+L))\)</span> for <span class="math inline">\(N\)</span> samples, <span class="math inline">\(D\)</span> dimensional distributional parameters
<span class="math inline">\(\theta\)</span> and <span class="math inline">\(L\)</span> is the cost of evaluating the cost
function.</p>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li><p>The score funtion only need the final value of the cost in its
computation and it makes no assumptions about the internal structure of
the cost function. Any type of cost function can be used.</p></li>
<li><p>The measure must be differentiable with respect to the parameters
<span class="math inline">\(\theta\)</span>, and we can easily sample
from the measure. It is applicable to both discrete and continuous
distributions.</p></li>
<li><p>The estimator can be implemented using only a single sample,
making it computationally efficient.</p></li>
<li><p>There are too many sources of variance, we can use some variance
reduction techniques to reduce the variance.</p></li>
</ul>
<h1 id="pathwise-gradient-estimators">Pathwise Gradient Estimators</h1>
<h2 id="sampling-paths-sampling-process">Sampling Paths (sampling
process)</h2>
<p>For continuous distribution, the alternative way to generate samples
<span class="math inline">\(\hat{x}\)</span> from the distribution <span class="math inline">\(p(x; \theta)\)</span> is to sample from a simpler
base distribution <span class="math inline">\(p(\epsilon)\)</span> which
is independent of the parameters <span class="math inline">\(\theta\)</span>, and then transform the samples
through a deterministic <strong>path</strong> <span class="math inline">\(g(\epsilon;  \theta)\)</span>: <span class="math display">\[
\hat{x} \sim p(x; \theta) \quad \equiv \quad \hat{x} = g(\epsilon;
\theta), \quad \epsilon \sim p(\epsilon).
\]</span></p>
<p>This transformation is described by the rule for the change of
variables for probability: <span class="math display">\[
p(x; \theta) = p(\epsilon) |\nabla_{\epsilon} g(\epsilon;\theta)|^{-1}.
\]</span></p>
<h3 id="one-liners-reparameterization-trick">One-liners
[Reparameterization Trick]</h3>
<p>One whidely-known example is sampling from a multivariate Gaussian
distribution <span class="math inline">\(p(\bf x; \bf \theta) =
\mathcal{N}(\mathbf x|\mathbf \mu, \mathbf \Sigma)\)</span>:</p>
<ol type="1">
<li>First sample from a standard Gaussian distribution <span class="math inline">\(p(\mathbf \epsilon) = \mathcal{N}(\mathbf
\epsilon|\mathbf 0, \mathbf I)\)</span>;</li>
<li>Then transform the samples through the local-scale transformation
<span class="math inline">\(g(\epsilon; \theta) = \mu + \mathbf L
\epsilon\)</span>, where <span class="math inline">\(\mathbf{LL}^T =
\mathbf \Sigma\)</span>.</li>
</ol>
<p><span class="math display">\[
\hat{x} = \mu + \mathbf L \epsilon, \quad \epsilon \sim
\mathcal{N}(\mathbf 0, \mathbf I), \quad \mathbf L \mathbf L^T = \mathbf
\Sigma.
\]</span></p>
<p><img src="/2023/10/21/Monte-Carlo-Gradient-Estimation/figure7.png"></p>
<p>Many such transformations exist for common distributions, including
Dirichlet, Gamma, and many others. These types of transformations are
called <strong>one-liners</strong> because they can be implemented in a
single line of code.</p>
<p>The expectation of eq. (1) is then: <span class="math display">\[
\begin{aligned}
\mathbb{E}_{p(x; \theta)} [f(x)] = \mathbb{E}_{p(\epsilon)}
[f(g(\epsilon; \theta))]
\end{aligned}
\]</span> It is often used in Monte Carlo methods, and is called
<strong>reparameterisation</strong> trick.</p>
<h2 id="gradient-estimators">Gradient Estimators</h2>
<p>Assume that we have a distribution <span class="math inline">\(p(x;
\theta)\)</span> with known <strong>differentiable</strong> sampling
path <span class="math inline">\(g(\epsilon; \theta)\)</span> and base
distribution <span class="math inline">\(p(\epsilon)\)</span>. The
gradient estimator for the sensitivity analysis of eq. (2) is: <span class="math display">\[
\begin{aligned}
\eta &amp;= \nabla_{\theta} \mathbb{E}_{p(x; \theta)} [f(x)] \\
&amp;= \nabla_{\theta} \int p(\epsilon) f(g(\epsilon; \theta))
\text{d}\epsilon \\
&amp;= \mathbb{E}_{p(\epsilon)}[\nabla_{\theta} f(g(\epsilon;
\theta))]\\
\bar{\eta} &amp;= \frac{1}{N} \sum_{n=1}^{N} \nabla_{\theta}
f(g(\hat{\epsilon}^{(n)}; \theta)), \quad \hat{\epsilon}^{(n)} \sim
p(\epsilon).   \qquad (3)
\end{aligned}
\]</span></p>
<h3 id="decoupling-sampling-and-gradient-computation">Decoupling
Sampling and Gradient Computation</h3>
<p>The pathwise estimator (3) is limited to those distributions for
which we simultaneously have a differential path and use this same path
to generate samples. But, <strong>sampling from a distribution may not
provide a differentiable path</strong>. Thus, we can expand the
applicability of the pathwise gradient by <strong>decoupling</strong>
these two processes.</p>
<p>The pathwise estimator can be rewritten in a more general form:</p>
<p><span class="math display">\[
\begin{aligned}
  \eta &amp;= \nabla_{\theta} \mathbb{E}_{p(\mathbf x;\theta)}[f(\mathbf
x)] \\
  &amp;= \mathbb{E}_{p(\epsilon)}[\nabla_{\theta} f(\mathbf x)|_{\mathbf
x = g(\epsilon;\theta)}] \\
  &amp;= \int p(\epsilon) \nabla_{\mathbf x} f(\mathbf x)|_{\mathbf x =
g(\epsilon;\theta)} \nabla_{\theta} g(\epsilon; \theta) \text{d}
\epsilon \\
  &amp;= \int p(\mathbf x;\theta) \nabla_{\mathbf x} f(\mathbf
x)\nabla_{\theta} \mathbf x \text{d} \mathbf x \\
  &amp;= \mathbb{E}_{p(\mathbf x;\theta)}[\nabla_{\mathbf x} f(\mathbf
x) \nabla_{\theta} \mathbf x].
\end{aligned}
\]</span></p>
<p>One way to compute <span class="math inline">\(\nabla_{\theta}
\mathbf x\)</span> is to use <span class="math inline">\(\nabla_{\theta}
g(\epsilon; \theta)\)</span>, but this form is not always
convenient.Another way to compute <span class="math inline">\(\nabla_{\theta} \mathbf x\)</span> is to use the
inverse of the path <span class="math inline">\(g^{-1}(x;
\theta)\)</span>. <span class="math inline">\(g^{-1}(x; \theta)\)</span>
can be thought as the 'standardisation path' of the random variable--
that is the transformation that removes the dependence of the sampling
on the distribution parameters, standardising it to a zero mean unit
variance-like form.</p>
<p>Consider the equation <span class="math inline">\(\epsilon =
g^{-1}(x; \theta)\)</span>, evaluating the total derivative on both
sides: <span class="math display">\[
\begin{aligned}
  \nabla_{\theta} \epsilon &amp;= \nabla_{\theta} g^{-1}(x;\theta) \\
  0 &amp;= \nabla_{x} g^{-1}(x;\theta) \nabla_{\theta} x +
\nabla_{\theta} g^{-1}(x;\theta) \\
  \text{thus,} \nabla_{\theta} x &amp;= - (\nabla_{x}
g^{-1}(x;\theta))^{-1} \nabla_{\theta} g^{-1}(x; \theta).
\end{aligned}
\]</span></p>
<p>In this form, we can apply pathwise gradient estimator to a far wider
set of distributions and paths, such as for the Beta, Gamma, and
Dirichlet distributions.</p>
<ul>
<li>Example (Univariate distributions). For univariate distribution
<span class="math inline">\(p(x;\theta)\)</span>, we can use the
sampling path given by the inverse CDF: <span class="math inline">\(x =
g(\epsilon;\theta) = F^{-1}(\epsilon; \theta)\)</span>, where <span class="math inline">\(\epsilon \sim \mathcal{U}[0, 1]\)</span>.
Computing the derivative <span class="math inline">\(\nabla_{\theta} x =
\nabla_{\theta} F^{-1} (\epsilon; \theta)\)</span> is often complicated
and expensive. We can obtain an alternative expression by considering
the inverse path <span class="math inline">\(g^{-1}(x;\theta) = F(x;
\theta)\)</span>, we have: <span class="math display">\[
\nabla_{\theta} x = -\frac{\nabla_{\theta} F(x;\theta)}{\nabla_x F(x;
\theta)} = - \frac{\nabla_{\theta} F(x;\theta)}{p(x; \theta)}.
\]</span></li>
</ul>
<h3 id="bias-and-variance">Bias and variance</h3>
<p>When deriving the pathwise estimator, we exploited an interchange
between differentiation and integration. If this interchange is valid,
then the estimator is <strong>unbiased</strong>.</p>
<p>The variance of the pathwise estimator can be shown to be bounded by
the squared Lipschitz constant of the cost function <span class="math inline">\(f(x)\)</span>. (1) The variance bounds that exist
are independent of the dimensionality of the parameters <span class="math inline">\(\theta\)</span>, which means we can get
low-variance gradient estimates, even in high-dimensional space. (2) As
the cost funtion becomes highly-variable, i.e., the Lipschitz constant
increases, the variance of the pathwise estimator can be higher than
that of the score function methods.</p>
<p>The pathwise estimator will not always have lower variance when
compared to other methods since the variance is bounded by the Lipschitz
constant of the cost function.</p>
<h3 id="computational-cost-1">Computational cost</h3>
<p>The pathwise gradient estimator is restricted to differentiable cost
functions, which is a limitation when compared to the score function
estimator. Rapid convergence can be obtained even when using only a
single sample to compute the gradient, as is often done in practice.
There is a trade-off between the number of samples used and the
Lipschitz constant of the cost function, and may require more samples to
be used for functions with higher Lipschitz constants. This
consideration is why we will find that regularisation that promotes
smoothness of the functions we learn is important for successful
applications.</p>
<p>The computational cost of the pathwise estimator is the same as the
score function estimator and is of the order <span class="math inline">\(O(N(D+L))\)</span> for <span class="math inline">\(N\)</span> samples, <span class="math inline">\(D\)</span> dimensional distributional parameters
<span class="math inline">\(\theta\)</span> and <span class="math inline">\(L\)</span> is the cost of evaluating the cost
function and its gradient.</p>
<h3 id="conclusion-1">Conclusion</h3>
<ul>
<li>The pathwise estimator is only applicable to differentiable cost
functions.</li>
<li>When using the pathwise estimator, we do not need to know the
measure <span class="math inline">\(p(x; \theta)\)</span>, but we need
to know the deterministic and differentiable sampling path <span class="math inline">\(g(\epsilon; \theta)\)</span> and the base
distribution <span class="math inline">\(p(\epsilon)\)</span>.</li>
<li>The estimator can be implemented using only a single sample, making
it computationally efficient.</li>
<li>We might need to control the smoothness of the cost function to
ensure that the variance of the estimator is low, and may need to employ
variance reduction techniques.</li>
</ul>
<h3 id="gumbel-softmax-estimator">Gumbel softmax estimator</h3>
<h2 id="measure-valued-gradient-estimators">Measure-Valued Gradient
Estimators</h2>
<h3 id="weak-derivatives-measure-valued-derivatives">Weak Derivatives
(measure-valued derivatives)</h3>
<p>Consider the derivative of a density function <span class="math inline">\(p(x; \theta)\)</span> with respect to a single
parameter <span class="math inline">\(\theta_i\)</span>, with <span class="math inline">\(i\)</span> the index on the set of distributional
parameters. The derivative <span class="math inline">\(\nabla_{\theta_i}
p(x;\theta)\)</span> is not a density, since it may have negative values
and does not integrate to one. Using the properties of signed measures,
we can always decompose this derivative into a difference of two
densities, each multiplied by a constant: <span class="math display">\[
\nabla_{\theta_i} p(x;\theta) = c_{\theta_i}^+ p^+(x;\theta) -
c_{\theta_i}^- p^-(x;\theta),
\]</span> where <span class="math inline">\(p^+, p^-\)</span> are
densities, referred to as the positive and negative parts of <span class="math inline">\(p\)</span>. By integrating both sides of the
equation, we can obtain the constants <span class="math inline">\(c_{\theta_i}^+, c_{\theta_i}^-\)</span>: <span class="math display">\[
\begin{aligned}
  &amp;\int \nabla_{\theta_i} p(x;\theta) \text{d}x = \nabla_{\theta_i}
\int p(x;\theta) \text{d}x  = 0; \\
  &amp;\int c_{\theta_i}^+ p^+(x;\theta) - c_{\theta_i}^- p^-(x;\theta)
\text{d}x = c_{\theta_i}^+ - c_{\theta_i}^- .
\end{aligned}
\]</span> Thus, we have: <span class="math display">\[
c_{\theta_i}^+ = c_{\theta_i}^- := c_{\theta_i}
\]</span> The decomposition of the derivative becomes: <span class="math display">\[
\nabla_{\theta_i} p(x;\theta) = c_{\theta_i} (p^+(x;\theta) -
p^-(x;\theta)).
\]</span> The triple <span class="math inline">\((c_{\theta_i}, p^+,
p^-)\)</span> is called the i-th <strong>weak derivative</strong> of
<span class="math inline">\(p\)</span> with respect to <span class="math inline">\(\theta_i\)</span>.</p>
<p>For multivariate parameters <span class="math inline">\(\theta\)</span>, each dimension has one
triple.</p>
<p><img src="/2023/10/21/Monte-Carlo-Gradient-Estimation/figure5.png"></p>
<ul>
<li>The derivative is weak because we do not require the density to be
differentiable.</li>
<li>The weak derivative is not unique, but always exists and can be
obtained using the Hahn-Jordan decomposition of a signed measure into
two measures that have complementary support. see <a target="_blank" rel="noopener" href="https://www.math.uwaterloo.ca/~beforres/PMath451/Course_Notes/Chapter4.pdf">signed
measure</a>.</li>
</ul>
<h3 id="deriving-the-estimator">Deriving the estimator</h3>
<p>For D-dimensional parameters <span class="math inline">\(\theta\)</span>, we can write the gradient of the
expectation as: <span class="math display">\[
\begin{aligned}
\eta_i &amp;= \nabla_{\theta_i} \mathbb{E}_{p(x;\theta)}[f(x)] =
\nabla_{\theta_i} \int p(x;\theta) f(x) \text{d}x \\
&amp;= \int \nabla_{\theta_i} p(x;\theta) f(x) \text{d}x \\
&amp;= \int c_{\theta_i} (p_i^+(x;\theta) - p_i^-(x;\theta)) f(x)
\text{d}x \\
&amp;= c_{\theta_i} (\mathbb{E}_{p_i^+(x;\theta)}[f(x)] -
\mathbb{E}_{p_i^-(x;\theta)}[f(x)]). \\
\bar{\eta}_{i, N} &amp;=  \frac{c_{\theta_i}}{N} (\sum_{n=1}^{N}
f(\hat{x}^{+(n)}) - \sum_{n=1}^{N} f(\hat{x}^{-(n)})), \quad
\hat{x}^{+(n)} \sim p_i^+(x;\theta), \quad \hat{x}^{-(n)} \sim
p_i^-(x;\theta).
\end{aligned}
\]</span> The positive and negative components may be different
depending on which parameter of the measure the derivative is taken with
respect to. The constant <span class="math inline">\(c_{\theta_i}\)</span> will also change depending
the parameter being differentiated.</p>
<ul>
<li>Example (Bernoulli measure-valued gradient). Consider the Bernoulli
distribution <span class="math inline">\(p(x;\theta) = \theta^x
(1-\theta)^{1-x}\)</span>, with <span class="math inline">\(x \in \{0,
1\}\)</span> and <span class="math inline">\(\theta \in [0, 1]\)</span>.
By taking the derivative with respect to <span class="math inline">\(\theta\)</span>, we have: <span class="math display">\[
\begin{aligned}
  \nabla_{\theta} \int p(x;\theta) f(x) \text{d}x
&amp;=  \nabla_{\theta} (\theta f(1) + (1-\theta) f(0))\\
  &amp;= f(1) - f(0).
\end{aligned}
\]</span> By weak derivative, we have: <span class="math display">\[
\begin{aligned}
\nabla_{\theta} \int p(x;\theta) f(x) \text{d}x &amp;= \int
\nabla_{\theta} p(x;\theta) f(x) \text{d}x \\
&amp;= \int \delta_1 f(x) - \delta_0 f(x) \text{d}x \\
&amp;= f(1) - f(0).
\end{aligned}
\]</span> which is the same as the original gradient.</li>
</ul>
<h4 id="vector-case">Vector case</h4>
<p>If the measure is a factorised distribution <span class="math inline">\(p(x;\theta) = \prod_d p(x_d | \theta_d)\)</span>,
then the positive component and negative component of the weak
derivative will itself factorise across the dimensions. For the positive
component, this decomposition will be <span class="math inline">\(p^+_i(x;\theta) =
p(x_{-i})p^+_i(x_i;\theta_i)\)</span>, which is the product of the
marginal distribution <span class="math inline">\(p(x_{-i})\)</span> and
the positive component of the weak derivative with respect to <span class="math inline">\(\theta_i\)</span>. The negative component will be
<span class="math inline">\(p^-_i(x;\theta) =
p(x_{-i})p^-_i(x_i;\theta_i)\)</span>, which is the product of the
marginal distribution <span class="math inline">\(p(x_{-i})\)</span> and
the negative component of the weak derivative with respect to <span class="math inline">\(\theta_i\)</span>.</p>
<h3 id="estimator-properties-1">Estimator Properties</h3>
<h4 id="domination">Domination</h4>
<p>Remember in the score function estimator, we need the measure to be
absolutely continuous with respect to <span class="math inline">\(\theta\)</span>. We explored one example where we
were unable to ensure domination, because no bounding constant applies
at the boundaries of the domain. For weak derivatives, we can always
ensure the correctness of the interchange between differentiation and
integration： the fundamental property of weak derivatives states that
if the triple <span class="math inline">\((c, p^+, p^-)\)</span> is the
weak derivative of <span class="math inline">\(p(x;\theta)\)</span>,
then for every <strong>bounded continuous</strong> function <span class="math inline">\(f(x)\)</span>, we have: <span class="math display">\[
\nabla_{\theta} \int f(x)  p(x;\theta) \text{d}x = c_{\theta} [\int f(x)
p^+(x;\theta) \text{d}x - \int f(x) p^-(x;\theta) \text{d}x].
\]</span></p>
<ul>
<li>Example (Bounded support). Consider the measure-valued estimator for
a cost function <span class="math inline">\(f(x) = x\)</span> and
distribution <span class="math inline">\(p(x; \theta) = \frac{1}{\theta}
1_{\{0 &lt; x &lt; \theta\}}\)</span>, which is differential in <span class="math inline">\(\theta\)</span> when <span class="math inline">\(x
\in (0, \theta)\)</span>; The measure-valued derivative is <span class="math display">\[
\begin{aligned}
    \nabla_{\theta} \int f(x) \mathcal{U}_{[0, \theta]}(x) \text{d}x
&amp;= \nabla_{\theta} (\frac{1}{\theta} \int_{0}^{\theta} f(x)
\text{d}x) = \frac{1}{\theta} f(\theta) - \frac{1}{\theta^2}
\int_{0}^{\theta} f(x) \text{d} x \\
    &amp;= \frac{1}{\theta} (\int f(x) \delta_{\theta}(x) \text{d}x -
\int f(x) \mathcal{U}_{[0, \theta]}(x) \text{d}x) \\
\end{aligned}
\]</span></li>
</ul>
<p>The measure-valued derivative is given by the triple <span class="math inline">\((\frac{1}{\theta}, \delta_{\theta},
\mathcal{U}_{[0, \theta]})\)</span>. For specific cost function <span class="math inline">\(f(x) = x\)</span>, we have:</p>
<p>The true gradient is: <span class="math inline">\(\nabla_{\theta}
\mathbb{E}_{p(x;\theta)} [x] = \nabla_{\theta} (\frac{1}{\theta}
\int_{0}^{\theta} \frac{x^2}{2}) = \frac{1}{2}\)</span>. The
measure-valued gradient is: <span class="math inline">\(\frac{1}{\theta}
(\mathbb{E}_{\delta_{\theta}} [x] - \mathbb{E}_{\mathcal{U}_{[0,
\theta]}[x]}) = \frac{1}{\theta} (\theta - \frac{\theta}{2}) =
\frac{1}{2}.\)</span></p>
<h4 id="bias-and-variance-1">Bias and variance</h4>
<p>For bounded and continuous cost functions <span class="math inline">\(f\)</span>, by using the fundamental property of
weak derivatives, the measure-valued gradient estimator is
<strong>unbiased</strong>.</p>
<p>The variance of the measure-valued gradient estimator is: <span class="math display">\[
\begin{aligned}
\text{Var}_{p(x;\theta)}[\bar{\eta}_1] =
\text{Var}_{p^+(x;\theta)}[f(x)] + \text{Var}_{p^-(x;\theta)}[f(x)] - 2
\text{Cov}_{p^+(x';\theta)p^-(x;\theta)} [f(x'), f(x)].
\end{aligned}
\]</span></p>
<ul>
<li>The variance depends on the choice of decomposition of the weak
derivative into positive and negative components.</li>
<li>If the random variables can be 'coupled' in some way, where they
share the same underlying source of randomness, this will reduce the
variance of the gradient estimator by increasing the covariance term.
The most common way is to sample the variables <span class="math inline">\(x'\)</span> and <span class="math inline">\(x\)</span> using common random numbers. Another
way is to use variance reduction techniques.</li>
<li>Figure 5 shows that the measure valued estimator is not sensitive to
the dimensionality of the parameters <span class="math inline">\(\theta\)</span>. It is however sensitive to the
magnitude of the function.</li>
</ul>
<p><img src="/2023/10/21/Monte-Carlo-Gradient-Estimation/figure6.png"></p>
<h4 id="computational-cost-2">Computational cost</h4>
<p>Measure-valued gradients are much more computationally expensive than
the score-function or pathwise gradients. This is because the gradient
we computed is the gradient for a single parameter: for every parameter
we require two evaluations of the cost function to compute its gradient.
It is this structure of adapting the underlying sampling distributions
for each parameter that leads to the low variance of the estimator but
at the same time makes its application to high-dimensional parameter
spaces prohibitive.</p>
<p>The computational cost of the measure-valued gradient estimator is
the order of <span class="math inline">\(O(2NDL)\)</span> for <span class="math inline">\(N\)</span> samples, <span class="math inline">\(D\)</span> dimensional distributional parameters
<span class="math inline">\(\theta\)</span> and <span class="math inline">\(L\)</span> is the cost of evaluating the cost
function.</p>
<h3 id="conclusion-2">Conclusion</h3>
<ul>
<li>The measure-valued estimator can be used with any type of cost
function, differentiable or not. As long as we can evaluate the cost
function repeatedly for different inputs.</li>
<li>It is applicable to both discrete and continuous distributions.</li>
<li>Computationally expensice in high-dimensional parameter spaces.</li>
<li>We need methods to sample from the positive and negative
measures.</li>
<li>Using the weak derivative <strong>requires manual derivation of the
decomposition at first</strong>, although for many common distributions
the weak-derivative decompositions are known.</li>
</ul>
<h2 id="variance-reduction-techniques">Variance Reduction
Techniques</h2>
<p>The gradient variance is one of the principal sources of performance
issues. This paper introduces four common methods to reduce the variance
of gradient estimators: large-samples, coupling, conditioning, and
control variates.</p>
<h3 id="large-samples">Large-Samples</h3>
<p>The simplest way to reduce the variance of the gradient estimator is
to use more samples. The variance of an estimators will shrinks as <span class="math inline">\(O(\frac{1}{N})\)</span>, where <span class="math inline">\(N\)</span> is the number of samples. However, the
computational cost will increase linearly with the number of samples.
The computational cost can be reduces by parallelising the computation
of the gradient across multiple processors. Sometimes, increasing the
number of Monte Carlo samples will not be an option, such as when the
cost function involves a real-world experiment or interaction with a
user.</p>
<h3 id="coupling-and-common-random-numbers">Coupling and Common random
numbers</h3>
<p>When consider the difference between two expectations of a function
<span class="math inline">\(f(x)\)</span> under different but
closely-related distributions <span class="math inline">\(p_1(x)\)</span> and <span class="math inline">\(p_2(x)\)</span>: <span class="math display">\[
\begin{aligned}
\eta = \mathbb{E}_{p_1(x)}[f(x)] - \mathbb{E}_{p_2(x)}[f(x)]
\end{aligned}
\]</span></p>
<p>The direct method to compute the difference is to estimate each
expectation separately using Monte Carlo sampling, and then compute the
difference between the two estimates： <span class="math display">\[
\begin{aligned}
\bar{\eta}_{ind} = \frac{1}{N} \sum_{n=1}^{N} f(\hat{x}_1^{(n)}) -
\frac{1}{N} \sum_{n=1}^{N} f(\hat{x}_2^{(n)}),
\end{aligned}
\]</span> where <span class="math inline">\(\hat{x}_1^{(n)} \sim
p_1(x)\)</span> and <span class="math inline">\(\hat{x}_2^{(n)} \sim
p_2(x)\)</span>.</p>
<p>We can achieve a simple form of variance reduction by coupling <span class="math inline">\(\hat{x}_1^{(n)}\)</span> and <span class="math inline">\(\hat{x}_2^{(n)}\)</span>, so that each pair <span class="math inline">\((\hat{x}_1^{(n)}, \hat{x}_2^{(n)})\)</span> is
sampled from some joint distribution <span class="math inline">\(p_{12}(x_1, x_2)\)</span> with marginals <span class="math inline">\(p_1(x)\)</span> and <span class="math inline">\(p_2(x)\)</span>. The variance of the coupled
estimator is: <span class="math display">\[
\begin{aligned}
\text{Var}_{p_12(x_1, x_2)}[\bar{\eta}_{cpl}] &amp;=
\text{Var}_{p_12(x_1, x_2)}[f(x_1) - f(x_2)] \\
&amp;= \text{Var}_{p_1(x_1)}[f(x_1)] + \text{Var}_{p_2(x_2)}[f(x_2)] - 2
\text{Cov}_{p_12(x_1, x_2)}[f(x_1), f(x_2)] \\
&amp;= \text{Var}_{p_1(x_1)p_2(x_2)}[\bar{\eta}_{ind}] - 2
\text{Cov}_{p_1(x_1)}[f(x_1), f(x_2)].
\end{aligned}
\]</span> Thus, to reduce the variance we need to choose a coupling
<span class="math inline">\(p_{12}(x_1, x_2)\)</span> such that <span class="math inline">\(f(x_1)\)</span> and <span class="math inline">\(f(x_2)\)</span> are positively correlated. The
most common way to achieve this is to use <strong>common random
numbers</strong> when <span class="math inline">\(p_1(x_1)\)</span> and
<span class="math inline">\(p_2(x_2)\)</span> are close or in a related
family of distributions. This means that the random numbers used to
generate <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are the same. For example, in the
univariate case, we can first sample <span class="math inline">\(u \sim
\mathcal{U}[0,1]\)</span> and then apply the inverse CDF transformation
to obtain <span class="math inline">\(x_1 = F_{p_1}^{-1}(u)\)</span> and
<span class="math inline">\(x_2 = F_{p_2}^{-1}(u)\)</span>.</p>
<ul>
<li>Coupling may not always reduce the variance of the measure valued
estimator, depending on the cost function.</li>
</ul>
<h3 id="conditioning">Conditioning</h3>
<p>Rao-Blackwellisation is a variance reduction technique that
probabilistically conditions our estimator on a subset of dimensions and
integrates out the remaining dimensions.</p>
<p>Assume that the dimensions <span class="math inline">\(\{1,...,
D\}\)</span> of <span class="math inline">\(x\)</span> are partitioned
into a set of dimensions <span class="math inline">\(\mathcal{S}\)</span> and its complement <span class="math inline">\(\mathcal{S}^c = {1,...,D}\ \mathcal{S}\)</span>.
The expectation <span class="math inline">\(g(x_{\mathcal{S}^c}) =
\mathbb{E}_{p(x_{\mathcal{S}})}[f(x)|x_{\mathcal{S}^c}]\)</span>. We can
estimate <span class="math inline">\(\mathbb{E}_{p(x)}[f(x)]\)</span> by
performing Monte Carlo integration over the dimensions <span class="math inline">\(\mathcal{S}^c\)</span>: <span class="math display">\[
\begin{aligned}
\bar{g}_{N} &amp;= \frac{1}{N} \sum_{n=1}^{N}
g(\hat{x}_{\mathcal{S}^c}^{(n)}) \\
&amp;= \frac{1}{N} \sum_{n=1}^{N}
\mathbb{E}_{p(x_{\mathcal{S}})}[f(x)|\hat{x}_{\mathcal{S}^c}^{(n)}],  \quad
\hat{x}_{\mathcal{S}^c}^{(n)} \sim p(x_{\mathcal{S}^c}).
\end{aligned}
\]</span></p>
<p>By law of total expectation <span class="math inline">\(\text{Var}(Y)
= \mathbb{E}[\text{Var}(Y | X)] + \text{Var}(\mathbb{E}[Y |
X])\)</span>, we have: <span class="math display">\[
\begin{aligned}
\text{Var}_{p(x)}[f(x)] &amp;=
\mathbb{E}_{p(x_{\mathcal{S}^c})}[\text{Var}_{p(x_{\mathcal{S}})}[f(x)|x_{\mathcal{S}^c}]]
+
\text{Var}_{p(x_{S^c})}[\mathbb{E}_{p(x_{\mathcal{S}})}[f(x)|x_{\mathcal{S}^c}]]
\\
&amp;=
\mathbb{E}_{p(x_{\mathcal{S}^c})}[\text{Var}_{p(x_{\mathcal{S}})}[f(x)|x_{\mathcal{S}^c}]]
+ \text{Var}_{p(x_{\mathcal{S}^c})}[g(x_{\mathcal{S}^c})] \\
&amp; \geq \text{Var}_{p(x_{\mathcal{S}^c})}[g(x_{\mathcal{S}^c})]
\end{aligned}
\]</span></p>
<p>Thus, for unconditional one <span class="math inline">\(\bar{f}_N =
\frac{1}{N}\sum_{n=1}^{N} f(\hat{x}^{(n)})\)</span>, we have: <span class="math display">\[
\begin{aligned}
\text{Var}_{p(x)}[\bar{f}_N] = \frac{1}{N} \text{Var}_{p(x)}[f(x)] \geq
\frac{1}{N}  \text{Var}_{p(x_{\mathcal{S}^c})}[g(x_{\mathcal{S}^c})] =
\text{Var}_{p(x_{\mathcal{S}^c})}[\bar{g}_{N}].
\end{aligned}
\]</span></p>
<ul>
<li>Conditional estimator has lower variance than the unconditional
estimator.</li>
<li>This technique is useful in practice only if we can compute the
conditional expectation <span class="math inline">\(g(x_{\mathcal{S}^c})\)</span> efficiently.</li>
</ul>
<h2 id="control-variates">Control Variates</h2>
<p>Since all the gradient estimators have the same form <span class="math inline">\(\mathbb{E}_{p(x;\theta)}[f(x)]\)</span>, we will
focus on this general form. The strategy is to replace the function
<span class="math inline">\(f(x)\)</span> in the expectation with a
substitute function <span class="math inline">\(\tilde{f}(x)\)</span>
whose expectation is the same as <span class="math inline">\(\mathbb{E}_{p(x;\theta)}[f(x)]\)</span>, but whose
variance is lower.</p>
<p>If we have a function <span class="math inline">\(h(x)\)</span> with
a known expectation <span class="math inline">\(\mathbb{E}_{p(x;\theta)}[h(x)]\)</span>, then we
can construct a new function <span class="math display">\[\tilde{f}(x) =
f(x) - \beta(h(x)-\mathbb{E}_{p(x;\theta)}[h(x)]).\]</span> Here <span class="math inline">\(h(x)\)</span> is a control variate. <span class="math inline">\(\beta\)</span> is a coefficient that affects the
strength of the control variate. Then we can get a control variate
estimator: <span class="math display">\[
\begin{aligned}
\bar{\eta}_{N} &amp;= \frac{1}{N} \sum_{n=1}^{N}
\tilde{f}(\hat{x}^{(n)}) \\
&amp;= \bar{f} - \beta (\bar{h} - \mathbb{E}_{p(x;\theta)}[h(x)]).
\end{aligned}
\]</span></p>
<h3 id="bias-consistency-and-variance">Bias, consistency and
variance</h3>
<ol type="1">
<li><p>Unbiasedness. The control variate estimator is unbiased： <span class="math display">\[
\begin{aligned}
\mathbb{E}_{p(x;\theta)}[\bar{\eta}_{N}] &amp;=
\mathbb{E}_{p(x;\theta)}[\bar{f} - \beta (\bar{h} -
\mathbb{E}_{p(x;\theta)}[h(x)]) ]\\
&amp;= \mathbb{E}_{p(x;\theta)}[\bar{f}] \\
&amp;= \mathbb{E}_{p(x;\theta)}[f(x)].
\end{aligned}
\]</span></p></li>
<li><p>Consistency. The control variate estimator is consistent: <span class="math display">\[
\lim_{N \to \infty} \bar{\eta}_{N} =
\mathbb{E}_{p(x;\theta)}[\tilde{f}(x)] = \mathbb{E}_{p(x;\theta)}[f(x)].
\]</span></p></li>
<li><p>Variance. The variance of the control variate estimator is (N=1):
<span class="math display">\[
\begin{aligned}
\text{Var}_{p(x;\theta)}[\tilde{f}] &amp;= \text{Var}_{p(x;\theta)}[f -
\beta (h - \mathbb{E}_{p(x;\theta)}[h(x)]) ]\\
&amp;= \text{Var}_{p(x;\theta)}[f] + \beta^2 \text{Var}_{p(x;\theta)}[h]
- 2 \beta \text{Cov}_{p(x;\theta)}[f, h].
\end{aligned}
\]</span> By minimising the right-hand side of the equation with respect
to <span class="math inline">\(\beta\)</span>, we can obtain the optimal
value of <span class="math inline">\(\beta\)</span>: <span class="math display">\[
\beta^* = \frac{\text{Cov}_{p(x;\theta)}[f,
h]}{\text{Var}_{p(x;\theta)}[h]} =
\sqrt{\frac{\text{Var}_{p(x;\theta)}[f]}{\text{Var}_{p(x;\theta)}[h]}}
\text{Corr}(f, h).
\]</span> Using the optimal value of <span class="math inline">\(\beta\)</span>, the potential variance reduction
is: <span class="math display">\[
\begin{aligned}
\frac{\text{Var}_{p(x;\theta)}[\tilde{f}]}{\text{Var}_{p(x;\theta)}[f]}
= \frac{\text{Var}_{p(x;\theta)}[f - \beta (h -
\mathbb{E}_{p(x;\theta)}[h(x)])]}{\text{Var}_{p(x;\theta)}[f]} = 1 -
\text{Corr}(f, h)^2 \leq 1.
\end{aligned}
\]</span></p></li>
</ol>
<ul>
<li>The stronger the correlation between <span class="math inline">\(f\)</span> and <span class="math inline">\(h\)</span>, the greater the potential variance
reduction.</li>
<li>In practice, the optimal <span class="math inline">\(\beta^*\)</span> will not be known and it can be
estimated using the same <span class="math inline">\(N\)</span> samples.
But the samples used to estimate <span class="math inline">\(\bar{h}\)</span> will introduce a bias because
<span class="math inline">\(\bar{\beta}_N\)</span> and <span class="math inline">\(\bar{h}\)</span> will no longer be independent. In
practice, thi bias is often negligible and can be controlled since it
decreases quickly as the number of samples <span class="math inline">\(N\)</span> increases.</li>
</ul>
<h3 id="multiple-and-non-linear-controls">Multiple and Non-linear
Controls</h3>
<h3 id="designing-control-variates">Designing Control Variates</h3>
<ol type="1">
<li><p>Baselines. One simple way to reduce the variance of a
score-function gradient estimator is to use the score function itself as
a control variate, since its expectation under the measure is zero. The
modified estimator is: <span class="math display">\[
\begin{aligned}
\bar{\eta}_{N} &amp;= \frac{1}{N} \sum_{n=1}^{N} (f(\hat{x}^{(n)}) -
\beta)\nabla_{\theta} \log p(\hat{x}^n;\theta), \hat{x}^{(n)} \sim
p(x;\theta) \\
\end{aligned}
\]</span> In reinforcement learning, <span class="math inline">\(\beta\)</span> is called a baseline and it can be
estimated with a running average of the cost. While this approach is
easier to implement than optimising <span class="math inline">\(\beta\)</span> to minimise variance, it is not
optimal and does not guarantee lower variance compared to the vanilla
score-function estimator.</p></li>
<li><p>Bounds. We can use bounds on the cost function <span class="math inline">\(f\)</span> as ways of specifying the form of the
control variate <span class="math inline">\(h\)</span>. This is
intuitive because it maintains a correlation between <span class="math inline">\(f\)</span> and <span class="math inline">\(h\)</span>, and if chosen well, may be easily
integrable against the measure and available in closed form. This
approach requires more knowledge of the cost function, since we will
need to characterise the cost analytically in some way to bound it. In
general, unless the bounds used are tight, they will not be effective as
control variates, since the gap between the bound and the true function
is not controllable and will not necessarily give the information needed
for variance reduction.</p></li>
<li><p>Delta method. The delta method is a way of constructing a control
variate by using the Taylor expansion of the cost function. This
requires a cost function that is differentiable so that we can compute
the second-order Taylor expansion, but can be an effective and very
general approach for variance reduction that allows easy implementation.
It can be used for variance reduction in both the score-function
estimator (Paisley et al., 2012) and the pathwise estimator(Miller et
al., 2017).</p></li>
</ol>
<ul>
<li><p>Example. Define <span class="math inline">\(\gamma(x)\)</span> is
the gradient of the cost function <span class="math inline">\(f(x)\)</span>, <span class="math inline">\(H(x)\)</span> is the Hessian of the cost function
<span class="math inline">\(f(x)\)</span>. The second-order Taylor
expansion of a cost function expand around point <span class="math inline">\(\mu\)</span> and its derivate are <span class="math display">\[
\begin{aligned}
  h(x) &amp;= f(\mu) + (x - \mu)^T \gamma(\mu) + \frac{1}{2} (x - \mu)^T
H(\mu) (x - \mu), \\
  \nabla_{x} h(x) &amp;= \gamma(\mu)^T + (x - \mu)^T H(\mu).
\end{aligned}
\]</span></p>
<p>We can use this expansion directly as a control variate for the
score-function estimator:</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\bar{\eta}_{SF} &amp;= \nabla_{\theta} \mathbb{E}_{p(x;\theta)}[f(x)] \\
&amp;= \nabla_{\theta} \mathbb{E}_{p(x;\theta)}[f(x) - \beta^T h(x)] +
\beta^T \nabla_{\theta} \mathbb{E}_{p(x;\theta)}[h(x)] \\
&amp;= \mathbb{E}_{p(x;\theta)}[(f(x) - \beta^T h(x))\nabla_{\theta}
\log p(x;\theta)] + \beta^T \nabla_{\theta}
\mathbb{E}_{p(x;\theta)}[h(x)].
\end{aligned}
\]</span> In the Gaussian mean-field variational inference that Paisley
et al. (2012) consider, the second term is known in closed-form and
hence does not require Monte Carlo approximation. <span class="math inline">\(\beta\)</span> is a multivariate control
coefficient and is estimated separately.</p>
<p>For the pathwise estimator, using the sampling path <span class="math inline">\(x = g(\epsilon; \theta)\)</span>, we have: <span class="math display">\[
  \begin{aligned}
    \bar{\eta}_{PW} &amp;= \nabla_{\theta}
\mathbb{E}_{p(x;\theta)}[f(x)] \\
    &amp;= \nabla_{\theta} \mathbb{E}_{p(x;\theta)}[f(x) - \beta^T h(x)]
+ \beta^T \nabla_{\theta} \mathbb{E}_{p(x;\theta)}[h(x)] \\
    &amp;= \nabla_{\theta} \mathbb{E}_{p(x;\theta)}[f(g(\epsilon;
\theta)) - \beta^T h(g(\epsilon; \theta))] + \beta^T \nabla_{\theta}
\mathbb{E}_{p(x;\theta)}[h(x)] \\
    &amp;= \mathbb{E}_{p(\epsilon)}[\nabla_{x}f(x) \nabla_{\theta}
g(\epsilon; \theta) - \beta \nabla_x h(x)\nabla_{\theta} g(\epsilon;
\theta)] + \beta^T \nabla_{\theta} \mathbb{E}_{p(x;\theta)}[h(x)].
  \end{aligned}
  \]</span> Assume that the final term is known in closed-form and does
not require stochastic approximation.</p>
<h2 id="guidance-in-choosing-gradient-estimators">Guidance in Choosing
Gradient Estimators</h2>
<p>The authors provide some guidance in choosing gradient
estimators.</p>
<ul>
<li><p>If our estimation problem involves continuous functions and
measures that are continuous in the domain, then using the pathwise
estimator is a good default. It is relatively easy to implement and its
default implementation, without additional variance reduction, will
typically have variance that is low enough so as not to interfere with
the optimisation.</p></li>
<li><p>If the cost function is not differentiable or is a black-box
function then the score-function or the measure-valued gradients are
available. If the number of parameters is low, then the measure-valued
gradient will typically have lower variance and would be preferred. But
if we have a high-dimensional parameter set, then the score-function
estimator should be used.</p></li>
<li><p>If we have no control over the number of times we can evaluate a
black-box cost function, effectively only allowing a single evaluation
of it, then the score function is the only estimator of the three we
reviewed that is applicable.</p></li>
<li><p>The score-function estimator should, by default, always be
implemented with at least some basic variance reduction. The simplest
option is to use a baseline control variate estimated with a running
average of the cost value. • When using the score-function estimator,
some attention should be paid to the dynamic range of the cost function
and its variance, and ways found to keep its value bounded within a
reasonable range, e.g. by transforming the cost so that it is zero mean,
or using a baseline.</p></li>
<li><p>For all estimators, track the variance of the gradients if
possible and address high variance by using a larger number of samples
from the measure, decreasing the learning rate, or clipping the gradient
values. It may also be useful to restrict the range of some parameters
to avoid extreme values, e.g. by clipping them to a desired
interval.</p></li>
<li><p>The measure-valued gradient should be used with some coupling
method for variance reduction. Coupling strategies that exploit
relationships between the positive and negative components of the
density decomposition, and which have shared sampling paths, are known
for the commonly-used distributions.</p></li>
<li><p>If we have several unbiased gradient estimators, a convex
combination of them might have lower variance than any of the individual
estimators.</p></li>
<li><p>If the measure is discrete on its domain then the score-function
or measure-valued gradient are available. The choice will again depend
on the dimensionality of the parameter space.</p></li>
<li><p>In all cases, we strongly recommend having a broad set of tests
to verify the unbiasedness of the gradient estimator when
implemented.</p></li>
</ul>
<h1 id="reference">Reference</h1>
<p>(https://pages.stat.wisc.edu/~shao/stat609/stat609-07.pdf)</p>
<p>https://bochang.me/blog/posts/measure-val-grad/</p>
<p><a target="_blank" rel="noopener" href="https://www.math.uwaterloo.ca/~beforres/PMath451/Course_Notes/Chapter4.pdf">signed
measure</a></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://xueyu-ubc.github.io/2023/10/21/Monte-Carlo-Gradient-Estimation/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Monte-Carlo-Gradient-Estimator/" rel="tag">Monte Carlo Gradient Estimator</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2023/11/07/The%20Effect%20of%20Data%20Centering%20on%20PCA%20Models/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            The Effect of Data Centering on PCA Models
          
        </div>
      </a>
    
    
      <a href="/2023/09/11/deep-learning-with-structures/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Deep Learning</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "",
    app_key: "",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021-2025
        <i class="ri-heart-fill heart_icon"></i> Xue Yu
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Welcome to XueYu&#39;s Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2021/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i></p>
  <div class="reward-box">
    
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>
<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="I am a second PhD student at Renmin University of China. My research interests include federated learning, high dimensional data, machine learning, and optimization. I am currently working on latent graph learning in Prof.Renjie Liao&#39;s group." />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Transformer, KV Cache, MHA, MQA, GQA, BERT, ViT, Swin Transformer |  Welcome to XueYu&#39;s Blog
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

<link rel="alternate" href="/atom.xml" title="Welcome to XueYu's Blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-Transformer"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Transformer, KV Cache, MHA, MQA, GQA, BERT, ViT, Swin Transformer
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2024/08/26/Transformer/" class="article-date">
  <time datetime="2024-08-25T23:30:00.000Z" itemprop="datePublished">2024-08-26</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Foundation-Model/">Foundation Model</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">4.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">16 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="attention-is-all-you-need">Attention is all you need</h1>
<h2 id="comparison-with-rnn-and-cnn">Comparison with RNN and CNN</h2>
<p>RNN: 对于给定一个序列，从左向右进行计算。对于第<span class="math inline">\(t\)</span>个词，会对应一个隐藏状态向量 <span class="math inline">\(h_t\)</span>。该隐藏状态向量 <span class="math inline">\(h_t\)</span> 是由前一个词的隐藏状态向量 <span class="math inline">\(h_{t-1}\)</span> 和当前位置 <span class="math inline">\(t\)</span>
的输入词决定的。因此，历史信息可以通过隐藏状态 <span class="math inline">\(h_{t-1}\)</span> 传送到当下。</p>
<ul>
<li><p>优点：可以处理时序信息。</p></li>
<li><p>缺点：（1）由于是序列计算，无法进行并行计算，计算性能较差。（2）如果时序很长，历史信息可以无法有效传输到后面。虽然可以设置较大的<span class="math inline">\(h_{t}\)</span>缓解该问题，但是存储<span class="math inline">\(h_t\)</span>会提升内存的需求。</p></li>
</ul>
<p>CNN:</p>
<ul>
<li><p>优点：具有多个输出通道
(多个卷积核)，每个输出通道可以识别不同的模式。</p></li>
<li><p>缺点：对于较长的序列，卷积核只能观察到距离较近的像素点，否则需要进行多层卷积操作。</p></li>
</ul>
<h2 id="model-architecture">Model Architecture</h2>
<p>当前的时序模型主要是encoder-decoder的架构。对于一个序列表示 <span class="math inline">\((x_1, ...,
x_n)\)</span>，encoder将该序列映射为一个连续表征 <span class="math inline">\(\mathbf z = (\mathbf z_1,..., \mathbf
z_n)\)</span>，其中 <span class="math inline">\(\mathbf z_i \in
R^d\)</span>, <span class="math inline">\(d\)</span>
为隐藏向量维度。对于encoder输出的 <span class="math inline">\(\mathbf
z\)</span>，decoder <strong>依次</strong> 生成输出序列 <span class="math inline">\((y_1, ..., y_m)\)</span>。</p>
<p>注意，对于encoder而言，可以看到整个输入句子。但是，对于decoder而言，无法观察到序列后面的词，因此词是按照自回归模式一个一个生成的，<strong>过去时刻的输出也作为当前时刻的输入</strong>。</p>
<p><img src="https://github.com/xueyu-ubc/xueyu-ubc.github.io/tree/master/images/wechat.jpg" alt="描述" width="50%" height="50%"></p>
<p><img src="./Transformer/architecture.jpg" alt="Description" width="400" height="310"></p>
<h3 id="encoder-and-decoder-stacks">Encoder and Decoder Stacks</h3>
<p>Encoder: 包含 <span class="math inline">\(N=6\)</span>
个layer，每个layer具有两个 sub-layers，其中第一个子层是一个 multi-head
self-attention，第二个子层是一个position-wise fully connected
feed-forward network
(MLP)。对于每个子层，使用残差连接+layernorm，即Layernorm(<span class="math inline">\(x\)</span> + sublayer(<span class="math inline">\(x\)</span>))。每层的输出维度统一为<span class="math inline">\(d_{model}=512\)</span>。</p>
<p>Decoder: <span class="math inline">\(N=6\)</span>个layers。每个layer具有三个sub-layers，并且每个子层都使用残差连接+layernorm。对于第一个子层的self-attention，由于不能获取之后的输入，因此使用masked
MHA。</p>
<h3 id="attention">Attention</h3>
<p>Query: 需要查询的内容向量；</p>
<p>Key: 可以认为是用于被查询的关键信息向量；</p>
<p>Value: 通过将 query和
key进行匹配对比，可以获得不同value的权重，然后基于该权重对value进行加权获得输出向量。</p>
<p>Scaled dot-product attention: <span class="math display">\[
\begin{aligned}
\text{Attention}(Q,K,V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}}V),
\end{aligned}
\]</span> 其中，query Q，key K 以及value V是等长的，都是 <span class="math inline">\(d_k\)</span>.</p>
<p>对于encoder，使用<strong>self-attention</strong>，query, key and
value都是来自input embedding投影得到。</p>
<p>对于decoder, 使用<strong>masked self-attention</strong> 和
<strong>cross-attention</strong>。对于cross-attention，key和value来自encoder的输出，query是来自decoder的下一刻的输入得到。通过计算query和key的相似度，对value进行加权得到输出。</p>
<h2 id="position-wise-feed-forward-networks"><strong>Position-wise</strong>
feed-forward networks</h2>
<p>对于attention 外的sub-layers, 对于每一个position
的输入使用<strong>同一个</strong>MLP进行映射： <span class="math display">\[
\begin{aligned}
\text{FFN}(x) = \text{max}(0, xW_1 + b_1)W_2 + b_2.
\end{aligned}
\]</span> 其中, <span class="math inline">\(x\)</span>是一个 <span class="math inline">\(512\)</span> 的向量，inner-layer has
dimensionality <span class="math inline">\(d_{ff}=2048\)</span>，输出也是一个 <span class="math inline">\(512\)</span> 向量。</p>
<h2 id="为什么需要除以sqrtd_k">为什么需要除以<span class="math inline">\(\sqrt{d_k}\)</span></h2>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/h-24XRdJDDZDg65LTjXA0w">ref1</a></p>
<ol type="1">
<li>当维度 <span class="math inline">\(d_k\)</span>
比较大时，点积的大小会增大，元素的相对距离增大，进行softmax操作时，会推动softmax函数往仅有很小的梯度的方向靠拢，导致softmax
函数容易导致梯度消失问题。</li>
<li>假设Q和K的均值为0，方差为1。它们的矩阵乘积将有均值为0，方差为<span class="math inline">\(d_k\)</span>。因此，<span class="math inline">\(d_k\)</span>
的平方根被用于缩放（而非其他数值），因为，Q和K的矩阵乘积的均值本应该为0，方差本应该为1，这样会获得一个更平缓的softmax。</li>
<li>也可以使用其他缩放方式，只要能做到每层参数的梯度保持在训练敏感的范围内，不要太大，不要太小。那么这个网络就比较好训练。</li>
</ol>
<h2 id="mask-self-attention">Mask self-attention</h2>
<p>为了不看到 <span class="math inline">\(t\)</span>
时刻之后的内容，对于点积矩阵的上半部分添加一个较小的数字，比如 <span class="math inline">\(-1e10\)</span>，这样经过softmax函数后对应位置会变成零。</p>
<h2 id="mha">MHA</h2>
<p><img src="./Transformer/mha.jpg" alt="Description" width="400" height="170"></p>
<p>对原始的Q,K，V，先通过一个linear layer映射到低维向量，然后进行scaled
dot-product
attention操作，得到h个输出向量，再将h个输出向量进行拼接，最后再通过一个linear
layer回到<span class="math inline">\(d_{model}\)</span>维度。</p>
<p>直接进行dot-product时，没有什么需要学习的参数。而使用MHA时，linear
layer的投影参数 <span class="math inline">\(W^Q, W^K, W^V\)</span>
是需要学习的，因此可以学习到不同的模式信息。</p>
<p>计算公式： <span class="math display">\[
\begin{aligned}
\text{MultiHead}(Q,K,V) &amp;= \text{concat}(\text{head}_1,
\text{head}_2,...,\text{head}_h)W^O,\\
\text{head}_i &amp;= \text{Attention}(QW_i^Q, KW^K_i, VW^V_i),
\end{aligned}
\]</span> 其中, <span class="math inline">\(W_i^Q \in
\mathbb{R}^{d_{model} \times d_k}\)</span>, <span class="math inline">\(W_i^K \in \mathbb{R}^{d_{model} \times
d_k}\)</span>, <span class="math inline">\(W_i^V \in
\mathbb{R}^{d_{model} \times d_v}\)</span>, <span class="math inline">\(W_i^O \in \mathbb{R}^{hd_v \times
d_{model}}\)</span>. In this paper, they set <span class="math inline">\(h=8\)</span>, <span class="math inline">\(d_k =
d_v = d_{model}/h\)</span>.</p>
<h2 id="kv-cache-原理-mha-mqa-gqa">KV Cache 原理, MHA, MQA, GQA</h2>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/mKdliGu4WhUx4PHatBpewA">ref1</a></p>
<p><a target="_blank" rel="noopener" href="https://www.linsight.cn/3dc22f96.html">ref2</a></p>
<h2 id="positional-encoding">Positional Encoding</h2>
<p>对于rnn而言，当前时刻的输入包含了上一时刻的输出，依次传递序列信息。而attention是考虑所有词之间的关联性，权重与序列信息无关，并没有将序列/位置信息考虑进去。如果将句子的词打乱，语义可能有所不同，但是attention
无法捕捉这种情况。在transformer中，通过将position进行encoding记录时序信息，然后和词的embedding相加作为输入。</p>
<p><img src="/2024/08/26/Transformer/positional.png"> <!-- $$
\begin{aligned}
PE(pos, 2i) &= sin(pos/10000^{2i/d_{model}}) \\
PE(pos, 2i+1) &= cos(pos/10000^{2i/d_{model}}) \\
\end{aligned}
$$ --></p>
<p>pos is the index of the word in the sentence. (0-30) <span class="math inline">\(2i\)</span> and <span class="math inline">\(2i+1\)</span> is the index of the column, d_model
is the number of columns, it is a hyper-parameter(120). For each
word(token), we encode it to a vector with dimension d_model according
to its position.</p>
<p>Here we use denominator <span class="math inline">\(10000^{2i/d_{model}}\)</span> to make sure the
positional encoding is different for different tokens. The sin and cos
are periodic functions, if we don't use the denominator, then the
positional encoding could be same for different tokens.</p>
<ul>
<li>If there are two different sentences with the same size, will the
positional encodings be the same?? yes.</li>
</ul>
<h2 id="complexity">Complexity</h2>
<p><img src="/2024/08/26/Transformer/complexity.jpg"></p>
<h1 id="bert-bidirectional-encoder-representations-from-transformers">BERT:
Bidirectional Encoder Representations from Transformers</h1>
<ul>
<li>GPT: 单向，使用过去的信息预测未来。</li>
<li>ELMo: 基于rnn的架构，双向rnn,
在用到一些下游任务时，需要对架构进行调整。</li>
<li>BERT: 相较于gpt, 可以使用左右侧信息，进行双向预测。相较于ELMo,
基于transformer架构，结构简单，只需要修改最上层。</li>
</ul>
<p>Bert
结合了ELMo的双向性和gpt的transformer架构，将预测未来变成<strong>完形填空</strong>。</p>
<h2 id="framework">Framework</h2>
<p>Bert主要包括两部分，pre-training and
fine-tuning。在pre-training阶段，模型在一个没有进行标注的数据上进行训练，是一个
self-supervised per-training
task。在fine-tuning阶段，用同一个Bert模型，但是模型首先被初始化为预训练的权重，然后再在有标注的数据上进行微调。每一个下游任务都会创建一个不同的模型进行微调。</p>
<p><img src="/2024/08/26/Transformer/bert.jpg"></p>
<p>Model architecture: a multi-layer bidirectional transformer
encoder.</p>
<p><strong>主要包括三个参数</strong> 1. number of layers/ transformer
blocks, i.e., <span class="math inline">\(L\)</span>. 2. hidden
dimension, i.e., <span class="math inline">\(H\)</span> (<span class="math inline">\(d_{model}\)</span>). 3. the number of attention
heads, i.e., <span class="math inline">\(A\)</span>.</p>
<p>两个模型： 1. Bert <span class="math inline">\(_{base}\)</span>:
<span class="math inline">\(L=12, H=768, A=12\)</span>, total parameters
is <span class="math inline">\(110M\)</span>. 2. Bert <span class="math inline">\(_{large}\)</span>: <span class="math inline">\(L=24, H=1024, A=16\)</span>, total parameters is
<span class="math inline">\(340M\)</span>.</p>
<p><strong>如何根据超参数设置计算所需要训练的参数量？</strong></p>
<p>对于transformer架构，输入是字典（句子）的大小，这里假设为<span class="math inline">\(30k\)</span>。通过嵌入层得到输出，输出维度为<span class="math inline">\(H\)</span> (<span class="math inline">\(d_{model}\)</span>)。输出的embedding会喂给
transformer blocks，transformer block中包括两部分，分别是self-attention
和 mlp。 对于self-attention，dot-production
是没有学习参数的，但是对于MHA，会对Q, K, V分别通过一个linear
layer映射到低维向量，然后进行scaled dot-product attention操作，得到<span class="math inline">\(A\)</span>个输出向量，再将<span class="math inline">\(A\)</span>个输出向量进行拼接，最后再通过一个linear
layer回到<span class="math inline">\(H\)</span> (<span class="math inline">\(d_{model}\)</span>)维度。在MHA中，头的个数乘以低维投影的维度=<span class="math inline">\(H\)</span> (<span class="math inline">\(d_{model}\)</span>)，因此低维投影部分的参数量为 $
3 H H<span class="math inline">\(。这里乘以 3 的原因是Q, K,
V分别通过一个linear
layer进行投影操作。同样，对于得到的低维投影向量进行拼接后还会进行一次投影，可学习参数量是\)</span>H
H<span class="math inline">\(。因此，一个self-attention层的可学习参数量为\)</span>
4 H H = 4 H^2$ （观察上文中的MHA结构图，可以发现有 4
个linear模块）。接下来是 mlp,
mlp具有两个全连接层，第一个全连接层的输入输出是<span class="math inline">\(H \times
4H\)</span>，第二个全连接层的输入输出是<span class="math inline">\(4H
\times H\)</span>，总共为 <span class="math inline">\(8H^2\)</span>。因此，一个transformer
block的可学习参数总共为 <span class="math inline">\(12
H^2\)</span>。</p>
<p>假设模型有 <span class="math inline">\(L\)</span>个blocks，那么该模型的可学习参数总量为
<span class="math inline">\(30k \times H + L \times H^2 \times
12\)</span>。</p>
<p>对于Bert <span class="math inline">\(_{base}\)</span>，<span class="math inline">\(L=12, H=768, A=12\)</span>，根据公式计算得到：$30k
+ 12 ^2 = 108,514,656 110M $。</p>
<p><strong>输入输出</strong></p>
<p>对于transformer而言，输入是一个序列对，编码器和解码器会分别输入一个序列。Bert只有一个编码器，输入是一个序列，可以是一段连续的文字，未必是真正语义上的句子，也可以包含两个句子。</p>
<p>论文使用 <strong>WordPiece</strong>
embeddings。通常来讲，如果根据空格对句子进行划分，每个词为一个token，那么词字典会非常大，输入的嵌入层的token很多，增加可学习参数。WordPiece根据词出现的频率进行划分，如果一个词出现的频率不大，那么将该词切开，看它的一个子序列。如果它的某一个子序列出现的概率较大，那么只保留这个子序列。这种方式可以将一个较长的句子切分成出现频率较高的几个子序列，类似于词根，从而减少词典大小。</p>
<p>对于一个序列，序列的第一个词token永远是一个特殊的记号 [CLS]，表示
classification。这个词的作用是用来表示整个序列层面的信息。虽然该token被放在序列的开头，但是由于Bert使用的是transformer的编码器，依旧可以注意到整个序列中的词，所以可以放在第一个位置。</p>
<p>由于两个句子被连接到一起作为一个序列进行输入，有两种方式来区分不同的句子。一种是在句子后面添加一个特殊的标记token
[SEP]。其次，添加一个可学习的嵌入层来表示每个token所属于的句子id。具体来说，如下图所示，对于一个输入的序列，共有三个嵌入层。首先第一个嵌入层token
embedding 是对每个词元输出一个向量；第二个是 segment
embedding层，该层的输入是 2，表示该词元属于哪个句子。第三个是position
embedding层，输入的是每个词元在该序列里的位置信息，从 0
开始。最终得到的输出是词元本身的嵌入+所属句子的嵌入+位置嵌入。</p>
<p><img src="/2024/08/26/Transformer/bert1.jpg"></p>
<h2 id="pre-training-bert">Pre-training BERT</h2>
<p>We do not use traditional left-to-right or right-to-left language
models to pre-train BERT. Instead, we pre-train BERT using two
unsupervised tasks, described in this section.</p>
<h3 id="task-1-masked-lm.">Task #1: Masked LM.</h3>
<p>如果一个词元是由WordPiece生成，那么该词元有<span class="math inline">\(15\%\)</span>的概率被随机替换为掩码
[Mask]。对于特殊词元，比如第一个词元[CLS]和中间分割词元[SEP]，就不进行替换。但是这种操作会带来一个问题，在训练的时候会有序列中的词元被替换为特殊token
[Mask]，但是在fine-tuning的时候，输入的序列不会包含[Mask]这种
token，从而导致两个输入数据的分布不一致。</p>
<p>为了减少这种情况，预训练时并不总是用实际的 [MASK]
标记来替换被掩码的词。训练数据生成器会随机选择 <span class="math inline">\(15\%\)</span> 的词元位置进行预测。如果第 <span class="math inline">\(i\)</span> 个标记被选中，那么该词元 (1) 有 <span class="math inline">\(80\%\)</span> 的概率被替换为[MASK]；（2）<span class="math inline">\(10\%\)</span>
的概率替换为字典中的随机词元；（3）<span class="math inline">\(10\%\)</span> 的概率保持不变。模型会预测这<span class="math inline">\(15\%\)</span>的词元，而不是构建整个输入序列。用
<span class="math inline">\(T_i\)</span>表示预测原始标记的<span class="math inline">\(15\%\)</span>词元的交叉熵损失。</p>
<h3 id="task-2-next-sentence-prediction-nsp">Task #2: Next Sentence
Prediction (NSP)</h3>
<p>许多重要的下游任务，如问题解答（QA）和自然语言推断（NLI），都是基于对两个句子之间关系的理解。为了训练一个能理解句子关系的模型，本文预先训练了一个binarized
next sentence prediction
task。该任务可以从任何语料库中生成。具体来说，每个预训练的序列包含两个句子
A 和 B，<span class="math inline">\(50\%\)</span> 的情况下, B 是 A
后面的实际下一句（标记为 IsNext），<span class="math inline">\(50\%\)</span> 的情况下，B
是语料库中的随机句子（标记为 NotNext）。如下图所示。</p>
<p><img src="./Transformer/bert3.jpg" alt="Description" width="400" height="220"></p>
<p>其中，‘flight ##less’
是一个词，但是该词出现的概率较低，所以WordPiece中被划分为两个词，
'##'表示与前面词相连。 如图 1 所示，特殊标记[CLS]对应的输出向量 <span class="math inline">\(C\)</span> 用来进行下一个句子预测。</p>
<h2 id="fine-tuning-bert">Fine-tuning BERT</h2>
<p>输入：对于每项任务，只需将任务的输入输出转换为Bert要求格式的输入，然后end-to-end微调所有参数即可。预训练阶段的句子
A 和句子 B 类似于：(1) 解析中的句子对；(2) 推断中的假设-前提对；(3)
问题解答中的问题-答案对；(4) 当进行文本分类时，句子+<span class="math inline">\(\emptyset\)</span>。</p>
<p>输出：对于token-level tasks，比如问题解答。将每个词元的embedding fed
into 一个输出层；对于分类任务，[CLS] 表示被fed into
一个输出层。然后end-to-end进行调参。</p>
<h1 id="vit">ViT</h1>
<p>paper: AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE
RECOGNITION AT SCALE</p>
<h2 id="introduction">Introduction</h2>
<p>Transformer在cv中应用的难点：Transformer中一个self-attention的计算复杂度为<span class="math inline">\(O(n^2)\)</span>。对于2d图像，如果简单地将图像拉成一维序列，每个像素点作为一个词元。对于一个<span class="math inline">\(256 \times
256\)</span>的图像，那么self-attention的计算复杂度将会是 <span class="math inline">\((224 \times 224)^2 =
50176^2\)</span>。对于较大的图像，序列长度很长，计算复杂度很高。</p>
<p>在中小型数据集上，ViT的效果较弱，弱于ResNets。主要原因是Transformer不具备归纳偏置
(inductive bias)
能力。卷积神经网络具有归纳偏置能力，该能力类似于一种先验知识/假设。比如对于卷积神经网络来说，具有两个
inductive
bias。（1）locality。卷积神经网络假设相邻区域具有相邻特征，因此通过滑动窗口进行学习。（2）translation
equivariance，平移等价性。<span class="math inline">\(f(g(x)) =
g(f(x))\)</span>。在卷积神经网络中，无论是对图片中物体先进行平移再卷积，还是先卷积再平移，只要是对于同一个不变的输入，结果不变。卷积神经网络具备这两个归纳偏置能力，等同于拥有很多先验信息，可以在中小型数据集上表现不错。</p>
<p>通过在大数据集上进行预训练，作者发现，即使
transformer不具备归纳偏置能力，依旧具有很好的表现，且可以扩展到下游任务中。</p>
<p>以往的工作要么是将卷积神经网络和自注意力结合，要么直接用自注意力取代卷积神经网络。但是没有工作直接只用transformer到图像领域。因此，本文直接使用标准的transformer结构，只是对图片进行预处理，划分成块。</p>
<h2 id="model-architecture-1">Model Architecture</h2>
<p><img src="./Transformer/vit.jpg" alt="Description" width="400" height="200"></p>
<p>如Figure 1所示，首先将原始图片划分为<span class="math inline">\(3
\times 3 = 9\)</span>个patch，然后按照顺序组成一个序列，通过一个linear
layer得到patch
embedding。为了表示每个patch在原始图片中的位置信息，类似于transformer，添加了一个position
embedding。然后通过一个标准的transformer encoder
得到输出。对于分类任务，仿照BERT，在序列的开头添加一个特殊标记[CLS]，
<strong>位置信息为
0</strong>。因为使用的transformer架构，该token可以注意到序列中其他pathch的信息，所以可以根据该token的输出进行判断得到有效信息。</p>
<p>具体来说，</p>
<h1 id="swin-transformer">Swin Transformer</h1>
<h1 id="references">References:</h1>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/mli/paper-reading">沐神,
论文精读</a></p></li>
<li><p><a target="_blank" rel="noopener" href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The
Annotated Transformer</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.03762">Attention is all you
need</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-transformer/" class="uri">https://jalammar.github.io/illustrated-transformer/</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.11929">ViT</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.14030">Swin Transformer:
Hierarchical Vision Transformer using Shifted Windows</a></p></li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://xueyu-ubc.github.io/2024/08/26/Transformer/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/2023/11/29/Generative-Models/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Generative Models</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "",
    app_key: "",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021-2024
        <i class="ri-heart-fill heart_icon"></i> Xue Yu
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Welcome to XueYu&#39;s Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2021/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i></p>
  <div class="reward-box">
    
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>
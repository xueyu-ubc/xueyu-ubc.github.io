<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="I am a second PhD student at Renmin University of China. My research interests include federated learning, high dimensional data, machine learning, and optimization. I am currently working on latent graph learning in Prof.Renjie Liao&#39;s group." />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Transformer, KV Cache, MHA, MQA, GQA, ViT, Swin Transformer |  Welcome to XueYu&#39;s Blog
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

<link rel="alternate" href="/atom.xml" title="Welcome to XueYu's Blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-Transformer"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Transformer, KV Cache, MHA, MQA, GQA, ViT, Swin Transformer
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2024/08/26/Transformer/" class="article-date">
  <time datetime="2024-08-25T23:30:00.000Z" itemprop="datePublished">2024-08-26</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Foundation-Model/">Foundation Model</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">1.6k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">6 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="attention-is-all-you-need">Attention is all you need</h1>
<h2 id="comparison-with-rnn-and-cnn">Comparison with RNN and CNN</h2>
<p>RNN: 对于给定一个序列，从左向右进行计算。对于第<span class="math inline">\(t\)</span>个词，会对应一个隐藏状态向量<span class="math inline">\(h_t\)</span>。该隐藏状态向量<span class="math inline">\(h_t\)</span>是由前一个词的隐藏状态向量<span class="math inline">\(h_{t-1}\)</span>和当前位置<span class="math inline">\(t\)</span>的输入词决定的。因此，历史信息可以通过隐藏状态<span class="math inline">\(h_{t-1}\)</span>传送到当下。</p>
<ul>
<li><p>优点：可以处理时序信息。</p></li>
<li><p>缺点：（1）由于是序列计算，无法进行并行计算，计算性能较差。（2）如果时序很长，历史信息可以无法有效传输到后面。虽然可以设置较大的<span class="math inline">\(h_{t}\)</span>缓解该问题，但是存储<span class="math inline">\(h_t\)</span>会提升内存的需求。</p></li>
</ul>
<p>CNN:</p>
<ul>
<li><p>优点：具有多个输出通道
(多个卷积核)，每个输出通道可以识别不同的模式。</p></li>
<li><p>缺点：对于较长的序列，卷积核只能观察到距离较近的像素点，否则需要进行多层卷积操作。</p></li>
</ul>
<h2 id="model-architecture">Model Architecture</h2>
<p>当前的时序模型主要是encoder-decoder的架构。对于一个序列表示<span class="math inline">\((x_1, ...,
x_n)\)</span>，encoder将该序列映射为一个连续表征 <span class="math inline">\(\bm z = (\bm z_1,..., \bm z_n)\)</span>，其中
<span class="math inline">\(\bm z_i \in R^d\)</span>, <span class="math inline">\(d\)</span> 为隐藏向量维度。对于encoder输出的<span class="math inline">\(\bm z\)</span>，decoder <strong>依次</strong>
生成输出序列 <span class="math inline">\((y_1, ..., y_m)\)</span>。</p>
<p>注意，对于encoder而言，可以看到整个输入句子。但是，对于decoder而言，无法观察到序列后面的词，因此词是按照自回归模式一个一个生成的，<strong>过去时刻的输出也作为当前时刻的输入</strong>。</p>
<p><img src="/2024/08/26/Transformer/architecture.jpg"></p>
<h3 id="encoder-and-decoder-stacks">Encoder and Decoder Stacks</h3>
<p>Encoder: 包含<span class="math inline">\(N=6\)</span>个layer，每个layer具有两个sub-layers，其中第一个子层是一个multi-head
self-attention，第二个子层是一个position-wise fully connected
feed-forward network
(MLP)。对于每个子层，使用残差连接+layernorm，即Layernorm(<span class="math inline">\(x\)</span> + sublayer(<span class="math inline">\(x\)</span>))。每层的输出维度统一为<span class="math inline">\(d_{model}=512\)</span>。</p>
<p>Decoder: <span class="math inline">\(N=6\)</span>个layers。每个layer具有三个sub-layers，并且每个子层都使用残差连接+layernorm。对于第一个子层的self-attention，由于不能获取之后的输入，因此使用masked
MHA.</p>
<h3 id="attention">Attention</h3>
<p>Query: 需要查询的内容向量；</p>
<p>Key: 可以认为是用于被查询的关键信息向量；</p>
<p>Value: 通过将 query和
key进行匹配对比，可以获得不同value的权重，然后基于该权重对value进行加权获得输出向量。</p>
<p>Scaled dot-product attention: <span class="math display">\[
\begin{aligned}
\text{Attention}(Q,K,V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}}V),
\end{aligned}
\]</span> 其中，query Q，key K 以及value V是等长的，都是 <span class="math inline">\(d_k\)</span>.</p>
<p>对于encoder，使用<strong>self-attention</strong>，query, key and
value都是来自input embedding投影得到。</p>
<p>对于decoder, 使用<strong>masked self-attention</strong> 和
<strong>cross-attention</strong>。对于cross-attention，key和value来自encoder的输出，query是来自decoder的下一刻的输入得到。通过计算query和key的相似度，对value进行加权得到输出。</p>
<h2 id="position-wise-feed-forward-networks"><strong>Position-wise</strong>
feed-forward networks</h2>
<p>对于attention 外的sub-layers, 对于每一个position
的输入使用<strong>同一个</strong>MLP进行映射： <span class="math display">\[
\begin{aligned}
\text{FFN}(x) = \text{max}(0, xW_1 + b_1)W_2 + b_2.
\end{aligned}
\]</span> 其中, <span class="math inline">\(x\)</span>是一个 512
的向量，inner-layer has dimensionality <span class="math inline">\(d_{ff}=2048\)</span>，输出也是一个 512 向量.</p>
<h2 id="为什么需要除以sqrtd_k">为什么需要除以<span class="math inline">\(\sqrt{d_k}\)</span></h2>
<p>https://mp.weixin.qq.com/s/h-24XRdJDDZDg65LTjXA0w</p>
<ol type="1">
<li>当维度<span class="math inline">\(d_k\)</span>比较大时，点积的大小会增大，元素的相对距离增大，进行softmax操作时，会推动softmax函数往仅有很小的梯度的方向靠拢，导致softmax
函数容易导致梯度消失问题。</li>
<li>假设Q和K的均值为0，方差为1。它们的矩阵乘积将有均值为0，方差为<span class="math inline">\(d_k\)</span>。因此，<span class="math inline">\(d_k\)</span>的平方根被用于缩放（而非其他数值），因为，Q和K的矩阵乘积的均值本应该为0，方差本应该为1，这样会获得一个更平缓的softmax。</li>
<li>也可以使用其他缩放方式，只要能做到每层参数的梯度保持在训练敏感的范围内，不要太大，不要太小。那么这个网络就比较好训练。</li>
</ol>
<h2 id="mask-self-attention">Mask self-attention</h2>
<p>为了不看到 <span class="math inline">\(t\)</span>
时刻之后的内容，对于点积矩阵的上半部分添加一个较小的数字，比如<span class="math inline">\(-1e10\)</span>，这样经过softmax函数后对应位置会变成零。</p>
<h2 id="mha">MHA</h2>
<p><img src="/2024/08/26/Transformer/mha.jpg">
对原始的Q,K，V，先通过一个linear layer映射到低维向量，然后进行scaled
dot-product
attention操作，得到h个输出向量，再将h个输出向量进行拼接，最后再通过一个linear
layer回到<span class="math inline">\(d_{model}\)</span>维度。</p>
<p>直接进行dot-product时，没有什么需要学习的参数。而使用MHA时，linear
layer的投影参数<span class="math inline">\(W^Q, W^K,
W^V\)</span>是需要学习的，因此可以学习到不同的模式信息。</p>
<p>计算公式： <span class="math display">\[
\begin{aligned}
\text{MultiHead}(Q,K,V) &amp;= \text{concat}(\text{head}_1,
\text{head}_2,...,\text{head}_h)W^O,\\
\text{head}_i &amp;= \text{Attention}(QW_i^Q, KW^K_i, VW^V_i),
\end{aligned}
\]</span> 其中, <span class="math inline">\(W_i^Q \in
\mathbb{R}^{d_{model} \times d_k}\)</span>, <span class="math inline">\(W_i^K \in \mathbb{R}^{d_{model} \times
d_k}\)</span>, <span class="math inline">\(W_i^V \in
\mathbb{R}^{d_{model} \times d_v}\)</span>, <span class="math inline">\(W_i^O \in \mathbb{R}^{hd_v \times
d_{model}}\)</span>. In this paper, they set <span class="math inline">\(h=8\)</span>, <span class="math inline">\(d_k =
d_v = d_{model}/h\)</span>.</p>
<h2 id="kv-cache-原理-mha-mqa-gqa">KV Cache 原理, MHA, MQA, GQA</h2>
<p>https://mp.weixin.qq.com/s/mKdliGu4WhUx4PHatBpewA</p>
<p>https://www.linsight.cn/3dc22f96.html</p>
<h2 id="positional-encoding">Positional Encoding</h2>
<p>对于rnn而言，当前时刻的输入包含了上一时刻的输出，依次传递序列信息。而attention是考虑所有词之间的关联性，权重与序列信息无关，并没有将序列/位置信息考虑进去。如果将句子的词打乱，语义可能有所不同，但是attention
无法捕捉这种情况。在transformer中，通过将position进行encoding记录时序信息，然后和词的embedding相加作为输入。</p>
<p><img src="./deep-learning-with-structures/positional.png"> <span class="math display">\[
\begin{aligned}
PE(pos, 2i) &amp;= sin(pos/10000^{2i/d_{model}}) \\
PE(pos, 2i+1) &amp;= cos(pos/10000^{2i/d_{model}}) \\
\end{aligned}
\]</span></p>
<p>pos is the index of the word in the sentence. (0-30) <span class="math inline">\(2i\)</span> and <span class="math inline">\(2i+1\)</span> is the index of the column, d_model
is the number of columns, it is a hyper-parameter(120). For each
word(token), we encode it to a vector with dimension d_model according
to its position.</p>
<p>Here we use denominator <span class="math inline">\(10000^{2i/d_model}\)</span> to make sure the
positional encoding is different for different tokens. The sin and cos
are periodic functions, if we don't use the denominator, then the
positional encoding could be same for different tokens.</p>
<ul>
<li>If there are two different sentences with the same size, will the
positional encodings be the same?? yes.</li>
</ul>
<h2 id="complexity">Complexity</h2>
<p><img src="/2024/08/26/Transformer/complexity.jpg"></p>
<h1 id="vit">ViT</h1>
<p>paper: AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE
RECOGNITION AT SCALE</p>
<p><img src="/2024/08/26/Transformer/vit.jpg"></p>
<h1 id="swin-transformer">Swin Transformer</h1>
<h1 id="references">References:</h1>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/mli/paper-reading">李沐,
Transformer论文精读</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://courses.cs.duke.edu/spring13/compsci590.2/slides/lec5.pdf">Markov
Chains and Coupling</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.03762">Attention is all you
need</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-transformer/" class="uri">https://jalammar.github.io/illustrated-transformer/</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.11929">ViT</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.14030">Swin Transformer:
Hierarchical Vision Transformer using Shifted Windows</a></p></li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://xueyu-ubc.github.io/2024/08/26/Transformer/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/2023/11/29/Generative-Models/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Generative Models</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "",
    app_key: "",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021-2024
        <i class="ri-heart-fill heart_icon"></i> Xue Yu
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Welcome to XueYu&#39;s Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2021/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i></p>
  <div class="reward-box">
    
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>
<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="I am a second PhD student at Renmin University of China. My research interests include federated learning, high dimensional data, machine learning, and optimization. I am currently working on latent graph learning in Prof.Renjie Liao&#39;s group." />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Machine Learning |  Welcome to XueYu&#39;s Blog
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

<link rel="alternate" href="/atom.xml" title="Welcome to XueYu's Blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>

</html>
<script src="/js/hexo_resize_image.js"></script>
<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-statistic"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Machine Learning
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2024/10/08/statistic/" class="article-date">
  <time datetime="2024-10-08T02:10:10.000Z" itemprop="datePublished">2024-10-08</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">48.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">175 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="一机器学习相关">一、机器学习相关</h1>
<h2 id="基本概念">1. 基本概念</h2>
<h3 id="排序">1.1. 排序</h3>
<h4 id="why-does-sorting-a-collection-have-at-least-on-log-n-complexity-n-is-the-length-of-the-collection.">1.
Why does sorting a collection have (at least) <span class="math inline">\(O(n log n)\)</span> complexity? n is the length of
the collection.</h4>
<ul>
<li><span class="math inline">\(O(n log n)\)</span> is the optimal value
for a comparison sort.
[https://theartofmachinery.com/2019/01/05/sorting_is_nlogn.html].</li>
</ul>
<h4 id="几种排序算法介绍以及复杂度分析">2.
几种排序算法介绍以及复杂度分析。</h4>
<ul>
<li><p>排序有内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。</p></li>
<li><p>排序的稳定性是指：若待排序的序列中，存在多个具有相同元素，经过排序，
这些元素的相对次序保持不变，则称该算法是稳定的；若经排序后，元素的相对次序发生了改变，则称该算法是不稳定的。</p></li>
<li><p>常见的八种排序方法都属于内部排序，交换排序（冒泡排序、快速排序）、选择排序（简单选择排序、堆排序）、插入排序（直接插入排序、希尔排序）、归并排序、基数排序。
<img src="/2024/10/08/statistic/sort.jpg"></p></li>
<li><p>冒泡排序：两两比较待排序数据元素的大小，如果两个数据元素的次序相反时则进行交换，直到没有反序的数据元素未知。<strong>平均时间复杂度为
<span class="math inline">\(O(n^2)\)</span>，空间复杂度为 <span class="math inline">\(O(1)\)</span>，属于稳定排序。</strong></p></li>
<li><p>快速排序：
在当前无序区任取一个元素作为待比较的基准，用此基准将当前无序区划分为左右两个较小的无序区，其中左边无序子区的数据元素均小于等于基准元素，右边无序子区中的元素均大于等于基准元素，而基准则始终位于最终排序位置上。依次再对左右两个无序子区进行上述划分过程，直到所有无序子区中的元素都已排序为止。<strong>平均时间复杂度为
<span class="math inline">\(O(n \log_2 n)\)</span>，空间复杂度为 <span class="math inline">\(O(\log_2 n) - O(n)\)</span>
（可能退化为冒泡排序），属于不稳定算法。</strong></p></li>
<li><p>简单选择排序：每一趟从待排序的数据元素中选出最小（或最大）的一个元素，顺序放在已排好序的数列最后，直到全部待排序的数据元素排完。<strong>平均时间复杂度为
<span class="math inline">\(O(n^2)\)</span>，空间复杂度为<span class="math inline">\(O(1)\)</span>，属于稳定排序。</strong></p></li>
<li><p>堆排序：将数组看成是一棵完全二叉树的顺序存储结构，利用完全二叉树中的双亲结点和孩子结点之间的内在关系来选择最小的元素。小根堆：树中任一非叶子结点的值均小于等于其孩子结点的值（堆顶最小）；大根堆：树中任一非叶子结点的值均大于等于其孩子结点的值（堆顶最大）。<strong>平均时间复杂度为
<span class="math inline">\(O(n \log_2 n)\)</span>，空间复杂度为 <span class="math inline">\(O(1)\)</span>，属于不稳定排序。</strong></p></li>
<li><p>直接插入排序：每次将一个待排序的数据元素，插入到前面已经排好序的数列中的适当位置，使数列依然有序；直到待排序数据元素全部插入完为止。<strong>平均时间复杂度为
<span class="math inline">\(O(n^2)\)</span>，空间复杂度为 <span class="math inline">\(O(1)\)</span>，属于稳定排序。</strong></p></li>
<li><p>希尔排序：先取一个小于 n 的整数 <span class="math inline">\(d_1\)</span>
作为第一个增量，把所有元素分为若干组，所有下标距离为 <span class="math inline">\(d_1\)</span>
的倍数的元素放在同一组中。先在各组内进行直接插入排序。然后取第二个增量
<span class="math inline">\(d_2 &lt;
d_1\)</span>，按照原始位置下标，重复上述分组和排序，直到所取的增量 <span class="math inline">\(d_t =
1\)</span>，即所有元素都放在同一组中进行直接插入排序为止。<strong>平均时间复杂度为
<span class="math inline">\(O(n^{1.3}
)\)</span>，空间复杂度为O(1)，不稳排序。</strong></p></li>
<li><p>归并排序：归并排序最核心的部分是合并（merge）过程，将两个有序的数组
a 和 b 合并为一个有序数组 c。从左往右枚举 a[i] 和
b[j]，找出最小的值并放入数组 c[k]；重复上述过程直到 a 和 b
有一个为空时，将另一个数组剩下的元素放入
c。为保证排序的稳定性，前段首元素小于或等于后段首元素时（a[i] &lt;=
b[j]）而非小于时（a[i] &lt; b[j]）就要作为最小值放入
c[k]。<strong>平均时间复杂度为 <span class="math inline">\(O(n \log
n)\)</span>，空间复杂度为 <span class="math inline">\(O(1)\)</span>，稳定排序。</strong></p></li>
<li><p>基数排序：将待排序的元素拆分为 <span class="math inline">\(k\)</span> 个关键字，先对第 <span class="math inline">\(1\)</span>
关键字进行稳定排序，然后对于每组具有相同关键字的元素 再对第 <span class="math inline">\(2\)</span>
关键字进行稳定排序（递归执行）。最后对于每组 具有相同关键字的元素 再对第
<span class="math inline">\(k\)</span>
关键字进行稳定排序。如果对自然数进行比较，将自然数按个位对齐后往高位补齐
<span class="math inline">\(0\)</span>，则一个数字从左往右数第 <span class="math inline">\(i\)</span> 位数就可以作为第 <span class="math inline">\(i\)</span> 关键字。<strong>设数据量为<span class="math inline">\(n\)</span>, 数据为<span class="math inline">\(d\)</span>进制, 最大位数为 <span class="math inline">\(k\)</span>, 则对某一位执行计数排序使用<span class="math inline">\(O(n+d)\)</span>时间，排序所有 <span class="math inline">\(k\)</span> 位使用<span class="math inline">\(O((n
+ d) \times k)\)</span> 时间。空间复杂度为 <span class="math inline">\(O(n + d)\)</span>,
非原地排序。如果对内层关键字的排序是稳定的，则基数排序是稳定的排序算法。</strong></p></li>
</ul>
<h3 id="二分查找">1.2. 二分查找</h3>
<p>以在一个升序数组中查找一个数为例。它每次考察数组当前部分的中间元素，如果中间元素刚好是要找的，就结束搜索过程；如果中间元素小于所查找的值，那么左侧的只会更小，不会有所查找的元素，只需到右侧查找；如果中间元素大于所查找的值同理，只需到左侧查找。</p>
<p>二分查找的最优时间复杂度为 <span class="math inline">\(O(1)\)</span>。二分查找的平均时间复杂度和最坏时间复杂度均为
<span class="math inline">\(O(\log
n)\)</span>。因为在二分搜索过程中，算法每次都把查询的区间减半，所以对于一个长度为
<span class="math inline">\(n\)</span> 的数组，至多会进行 <span class="math inline">\(O(\log n)\)</span> 次查找。</p>
<p>迭代版本的二分查找的空间复杂度为 <span class="math inline">\(O(1)\)</span>。</p>
<h3 id="回归模型和分类模型常用损失函数有哪些">1.3.
回归模型和分类模型常用损失函数有哪些？</h3>
<h4 id="回归模型常用的损失函数">回归模型常用的损失函数</h4>
<ol type="1">
<li><p>0-1损失函数： <span class="math display">\[
L(\hat{y},y) =
\begin{cases}
  1,
&amp;
y \neq \hat{y} \\
0,
&amp;
y = \hat{y}
\end{cases}
  \]</span></p></li>
<li><p>平均绝对误差MAE：异常点多的情况下鲁棒性更强，不像MSE那样过度惩罚大误差；但不方便求导
<span class="math display">\[
L(\hat{y}, y) = \frac{1}{n} \sum_{i=1}^{n}|y_i - \hat{y}_i|.
\]</span></p></li>
<li><p>均方误差MSE：求导方便，能够用梯度下降法优化；对异常值敏感，异常值的存在会导致MSE值急剧增大，从而影响模型效果。
<span class="math display">\[
L(\hat{y},y) = \frac{1}{n} \sum_{i=1}^{n}(y_i - \hat{y}_i)^2.
\]</span></p></li>
<li><p>对数损失函数/对数似然损失函数： <span class="math display">\[
L(P(Y|X),Y) = -{\rm log} P(Y|X)
\]</span></p></li>
<li><p>Huber
损失函数：结合了MAE和MSE的优点，对异常值更加鲁棒，比MSE对大的误差的惩罚更加温和；在误差较小时仍然能够提供与MSE类似的梯度更新；缺点是需要调整超参数
<span class="math inline">\(\delta\)</span> <span class="math display">\[
L_{Huber}(\hat{y}, y) =
\begin{cases}
(\hat{y}-y)^2
&amp;
|\hat{y}-y| \leq \delta
\\
2 \delta |\hat{y}-y| - \delta^2
&amp;
|\hat{y}-y| &gt; \delta
\end{cases}
\]</span></p></li>
<li><p>对数余弦 Log-Cosh
损失函数：近似于MSE，但对大误差的惩罚更温和，兼顾了MSE和MAE的优点。同时二阶处处可微（牛顿法要求二阶可微），更加平滑且容易优化。但是，不如MSE那样简单直观，在某些应用中表现不如MSE。
<span class="math display">\[
L(\hat{y},y) = \log \cosh(\hat{y}-y)
\]</span></p></li>
</ol>
<h4 id="分类模型中常用的损失函数">分类模型中常用的损失函数</h4>
<ol type="1">
<li>交叉熵损失。对于二元分类，公式为如下。其中，<span class="math inline">\(y\)</span>是真实标签，<span class="math inline">\(p\)</span>是模型预测的概率。 <span class="math display">\[
  L(p,y) = -[y \log p + (1-y) \log (1-p)].
  \]</span></li>
</ol>
<ul>
<li>优点：直接衡量模型预测的概率与真实分类标签之间的差异，适合分类任务。对概率差异敏感，能够较好地区分高概率和低概率的预测。</li>
<li>缺点：当预测的概率非常接近0或1时，交叉熵的梯度可能变得极端，导致训练不稳定。对于不平衡数据，模型倾向于偏向多数类，需要配合其他技术如加权损失函数或欠采样来处理。</li>
</ul>
<ol start="2" type="1">
<li>Hinge loss。通常用于支持向量机，公式如下。<span class="math inline">\(y \in {-1,1}\)</span>是真实标签，<span class="math inline">\(f(x)\)</span>是模型输出。 <span class="math display">\[
  L(f(x),y) = \max(0, 1 - y \times f(x))
  \]</span></li>
</ol>
<ul>
<li>优点：强调分类边界的最大化，适用于SVM；对小的误差不敏感，能够防止过拟合。</li>
<li>缺点：不适用于概率输出的分类模型。仅适用于二分类问题，多分类任务中扩展性较差。</li>
</ul>
<ol start="3" type="1">
<li>Kullback-Leibler 散度。假设<span class="math inline">\(p(x)\)</span>是真实分布，<span class="math inline">\(q\)</span>是模型预测的概率分布，公式如下： <span class="math display">\[
  D_{\text{KL}}(p||q) = \sum p(x) \log(\frac{p(x)}{q(x)}),
  \]</span></li>
</ol>
<ul>
<li>优点：可以量化两个分布之间的差异，适合概率模型；</li>
<li>缺点：对极端概率值（接近于1或0）的预测非常敏感，可能导致数值不稳定。</li>
</ul>
<h3 id="什么是结构误差和经验误差">1.4. 什么是结构误差和经验误差？</h3>
<p>经验风险（经验损失）：模型 <span class="math inline">\(f(X)\)</span>关于训练数据集的平均损失 <span class="math display">\[
R_{\rm emp}(f) = \frac{1}{N} \sum_{i=1}^N L(y_i,f(x_i)).
\]</span></p>
<p>结构风险：是在经验风险上加上表示模型复杂度的正则化项 <span class="math display">\[
R_{\rm srm}(f) = \frac{1}{N} \sum_{i=1}^{N}L(y_i,f(x_i))+\lambda J(f).
\]</span></p>
<p>经验风险最小化的策略认为，经验风险最小的模型是最优的模型。</p>
<p>结构风险最小化是为了防止过拟合而提出的，结构风险最小化等价于正则化。结构风险最小化的策略认为结构风险最小的模型是最优的模型。</p>
<h3 id="如何选择合适的模型评估指标rocauc精准度召回率f1值">1.5.
如何选择合适的模型评估指标？ROC、AUC、精准度、召回率、F1值</h3>
<p>模型评估指标用于衡量机器学习模型在测试集或验证集上的表现，帮助评估其性能。</p>
<p>混淆矩阵，又称误差矩阵，就是分别统计分类模型归错类，归对类的观测值个数，然后把结果放在一个表里展示出来。这个表就是混淆矩阵。</p>
<p>混淆矩阵是ROC曲线绘制的基础，同时它也是衡量分类型模型准确度中最基本，最直观，计算最简单的方法。</p>
<table>
<thead>
<tr>
<th style="text-align: center;">混淆矩阵</th>
<th style="text-align: center;">预测结果</th>
<th style="text-align: center;">预测结果</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">真实情况</td>
<td style="text-align: center;">反例</td>
<td style="text-align: center;">正例</td>
</tr>
<tr>
<td style="text-align: center;">反例</td>
<td style="text-align: center;">TN（真反例）</td>
<td style="text-align: center;">FP（假正例）</td>
</tr>
<tr>
<td style="text-align: center;">正例</td>
<td style="text-align: center;">FN（假反例）</td>
<td style="text-align: center;">TP（真正例）</td>
</tr>
</tbody>
</table>
<ul>
<li>TN：True Negative，将样本中的负类样本预测为负类的数量</li>
<li>FP：False Positive，将样本中的负类样本预测为正类的数量</li>
<li>FN：False Negative，将样本中的正类样本预测为负类的数量</li>
<li>TP：True Positive，将样本中的正类样本预测为正类的数量</li>
</ul>
<h4 id="分类任务指标">分类任务指标</h4>
<h4 id="accuracy准确率分类正确的样本占总样本个数的比例">Accuracy（准确率）：分类正确的样本占总样本个数的比例</h4>
<p><span class="math display">\[
\text{Accuracy} = \frac{n_{correct}}{n_{total}}
\]</span> -
缺点：不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。比如，当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。
-
解决：可以使用每个类别下的样本准确率的算术平均（平均准确率）作为模型评估的指标。</p>
<p>在数据集不平衡的情况下（阴性数据多，阳性数据少），精确度和召回率是合适的性能指标。精确度和召回率都只关注阳性类（少数类），而不关心真正的阴性类（多数类）。简单地说，在数据类别不平衡的情况下，即有大量反类和少量正类时，精确度和召回率是首选指标。换句话说，精确度和召回率可以评估分类器在少数类别上的性能。</p>
<h4 id="precision精确率分类正确的正样本个数占分类器判定为正样本的样本个数的比例">Precision（精确率）：分类正确的正样本个数占分类器判定为正样本的样本个数的比例</h4>
<p>取值范围：0 到 1，其中 1 表示完全精确（没有误报），0
表示没有正确的正预测。 <span class="math display">\[
\text{Precision} = \frac{TP}{TP+FP}
\]</span></p>
<h4 id="recall召回率-又称灵敏度-sensitivity分类正确的正样本数占真正的正样本个数的比例">Recall（召回率，
又称灵敏度
sensitivity）：分类正确的正样本数占真正的正样本个数的比例</h4>
<p>取值范围：0 至 1，其中 1 表示完全召回（无假阴性），0
表示未识别出真阳性。 <span class="math display">\[
\text{Recall} = \frac{TP}{TP+FN}
\]</span></p>
<h4 id="f1-scoreprecision和recall的调和平均值当精确率和召回率都高时f1值也会高特别适用于类别不平衡的数据集">F1-score：precision和recall的调和平均值；当精确率和召回率都高时，F1值也会高；特别适用于类别不平衡的数据集</h4>
<p><span class="math display">\[
F1 = \frac{2 \times \text{Precision} \times \text{Recall}
}{\text{Precision} + \text{Recall} }
\]</span> 取值范围：0 到 1，其中 1 表示精确度和召回率之间的最佳平衡，0
表示精确度、召回率或两者均为 0。</p>
<p>如果我们认为精确率或召回率中的某一个比另一个更重要，那么可以使用
<span class="math inline">\(F_{\beta}\)</span>分数，这是精确率和召回率的加权调和平均数。这个分数特别适用于一些特定的应用场景，例如在医学检测中，假阴性可能比假阳性代价更高的情况。<span class="math inline">\(F_{\beta}\)</span>
能够根据实际需求调整精确率和召回率的相对权重。</p>
<p><span class="math inline">\(F_{\beta}\)</span> 分数公式： <span class="math display">\[
F_{\beta} = (1 + \beta^2) \cdot \frac{ {\text{Precision} \cdot
\text{Recall}}}{ {\beta^2 \cdot \text{Precision} + \text{Recall}} }.
\]</span> - <span class="math inline">\(\beta\)</span>:
用于控制精确率和召回率之间的权衡。 - 如果 <span class="math inline">\(\beta&gt;1\)</span>，则更重视召回率；适用于假阴性代价较高的场景。
- 如果 <span class="math inline">\(\beta&lt;1\)</span>，则更重视精确率；适用于假阳性代价较高的场景。
- 当 <span class="math inline">\(\beta = 1\)</span>时，<span class="math inline">\(F_{\beta}\)</span> 分数即为常见的 F1
分数，它将精确率和召回率同等看待。</p>
<ul>
<li>在医学检测中，<strong>假阴性</strong>可能意味着病人未能及时得到治疗，因此我们可能更关注召回率，选择较高的
<span class="math inline">\(\beta\)</span> 值以降低漏诊的概率。</li>
<li>在反垃圾邮件系统中，<strong>假阳性</strong>（将正常邮件误判为垃圾邮件）可能带来更大影响，此时可以使用较小的
<span class="math inline">\(\beta\)</span> 值，更加注重精确率。</li>
</ul>
<h4 id="pr指标应用场景">PR指标应用场景</h4>
<ul>
<li>一个完美的分类器的精确度和召回率都等于 1。</li>
<li>精确度和召回率应一并报告，不应单独报告。因为很容易通过改变模型的召回率（灵敏度）来提高精确度，反之亦然。</li>
</ul>
<p>在正类（也称为少数类）稀少的情况下，PR
能够处理类不平衡问题。但是，如果数据集不平衡，负类是罕见的一类，那么 PR
曲线就不是最佳曲线，可能会产生误导。在这种情况下，ROC
曲线可能更合适。</p>
<p>具体应用场景：</p>
<ul>
<li>当两个类别同样重要时：如果模型的目标是在两个类别上都有同样好的表现，那么
PR
是可使用的指标。猫和狗的图像分类就是一个很好的例子，因为在猫上的表现与在狗上的表现同样重要。</li>
<li>当少数类别更重要时：如果模型的重点是正确识别出尽可能多的正面样本，那么
PR
就是要使用的指标。以垃圾邮件检测器为例，其目标是找出所有可能的垃圾邮件。普通邮件根本不值得关注--它们会影响阳性样本的数量。</li>
</ul>
<h4 id="p-r-曲线">P-R 曲线</h4>
<p>在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用Top
N返回结果的Precision和Recall值来衡量排序模型的性能。即认为模型返回的Top
N结果就是模型判定的正样本，计算前N个位置的Precision@N和Recall<span class="citation" data-cites="N">@N</span>。为了综合评估一个排序模型的好坏，不仅要看模型在不同Top
N下的Precision@N和Recall<span class="citation" data-cites="N">@N</span>，而且最好画出模型的P-R曲线。P-R曲线的横轴是Recall，纵轴是Precision。</p>
<p>当数据集的类别不平衡时，精度和召回率是比准确率更好的指标。同样，对于不平衡的类别，精度-召回曲线比
ROC 曲线更合适。精确度-召回率曲线是不同阈值下精确度（y 轴）和召回率（x
轴）的曲线图，与 ROC
曲线类似。需要注意的是，在计算精确度和召回率时，绝对不能使用真实负值，这些指标只考虑正确预测。</p>
<p><strong>Area Under the PR Curve (AUPRC)</strong>：AUPRC
将一系列阈值的曲线汇总为一个分数。该分数可作为二元分类问题中不同模型之间的比较点，其中
1.0 分代表最完美的分类器。</p>
<p><strong>ROC
曲线适用于每个类别之间的样本平衡的情况，而精度-召回曲线则适用于不平衡的数据集。</strong></p>
<h4 id="特异性specificity">特异性（specificity）</h4>
<p><strong>Specificity</strong>（特异性）用于衡量模型在识别负类时的准确性。特异性反映了模型避免将真实的负类样本误判为正类样本的能力，通俗地说就是“没有病的人被正确地诊断为没有病的比例”。
<span class="math display">\[
\text{Specificity} = \frac{\text{TN}}{\text{TN} + \text{FP}}
\]</span></p>
<ul>
<li>如果特异性高，说明模型能够很好地避免误报（将实际的负类错判为正类）。</li>
<li>特异性常与敏感性(sensitivity)一起使用，后者用于衡量模型识别正类（“有病”的人）能力的表现。</li>
</ul>
<p>Image credits to <a target="_blank" rel="noopener" href="https://medium.com/swlh/how-to-remember-all-these-classification-concepts-forever-761c065be33">source</a></p>
<p><img src="/2024/10/08/statistic/pr_ss.jpeg"></p>
<h4 id="roc-曲线">ROC 曲线</h4>
<p>横坐标为假阳性率（False Positive Rate，FPR）；纵坐标为真阳性率（True
Positive Rate，TPR） <span class="math display">\[
FPR = \frac{FP}{N}, \quad
TPR = \frac{TP}{P},
\]</span>
其中，P是真实的正样本的数量，N是真实的负样本的数量，TP是P个正样本中被分类器预测为正样本的个数，FP是N个负样本中被预测为正样本的个数。</p>
<p><strong>如何绘制ROC曲线</strong></p>
<p>通过不断移动分类器的“截断点”来生成曲线上的一组关键点。在二分类问题中，模型输出一般是预测样本为正例的概率，在输出最终的正例负例之前，我们需要制定一个阈值。大于该阈值的样本判定为正例，小于该阈值的样本判定为负例。通过动态调整截断点，绘制每个截断点对应位置，再连接所有点得到最终的ROC曲线。
比如，阈值为0时，此时所有样本被预测为负例，TPR = 0, FPR =
0；当阈值增加为1时，此时所有样本被预测为正例，TPR = 1, FPR = 1.</p>
<p><strong>一般情况下，PR曲线易受样本数量的影响，样本数量不均衡情况下PR曲线会有明显变化，故一般使用ROC曲线。</strong></p>
<p><strong>AUC</strong>：ROC曲线下的面积大小。计算AUC值只要沿着ROC横轴做积分就可以。AUC取值在0.0~1之间。AUC越大，分类性能越好。AUC表示预测的正例排在负例前面的概率。</p>
<p>指标想表达的含义，简单来说其实就是随机抽出一对样本（一个正样本，一个负样本），然后用训练得到的分类器来对这两个样本进行预测，预测得到正样本的概率大于负样本概率的概率。AUC为0.5表明对正例和负例没有区分能力，对于不论真实类别是1还是0，分类器预测为1的概率是相等的。</p>
<p>我们希望分类器达到的效果：对于真实类别为1的样本，分类器预测为1的概率（TPR）要大于真实类别为0而预测类别为1的概率（FPR），即y&gt;x</p>
<p>AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。</p>
<h4 id="回归任务指标">回归任务指标</h4>
<h4 id="均方根误差rmse计算预测值和实际值的平均误差">均方根误差RMSE：计算预测值和实际值的平均误差</h4>
<p><span class="math display">\[
{\rm RMSE} = \sqrt{\frac{\sum_{i=1}^n (y_i-\hat{y}_i)^2}{n}}
\]</span></p>
<h4 id="均方误差mse">均方误差MSE</h4>
<h4 id="平均绝对误差mae">平均绝对误差MAE</h4>
<h4 id="决定系数-r2">决定系数 <span class="math inline">\(R^2\)</span></h4>
<p>表示模型解释变量总方差的比例，反映了模型拟合的好坏。</p>
<p>SST: sum of squares total，总的偏差平方和，表示变量<span class="math inline">\(y\)</span>相对于中心<span class="math inline">\(\bar{y}\)</span>的异动。 <span class="math display">\[
SST = \sum_{i=1}^n (y_i - \bar{y}_i)^2.
\]</span></p>
<p>SSR: sum of squares regression, 回归平方和，表示估计值 <span class="math inline">\(\hat{y}\)</span>相对于中心 <span class="math inline">\(\bar{y}\)</span>的异动。</p>
<p><span class="math display">\[
SSR = \sum_{i=1}^{n} (\hat{y}_i - \bar{y}_i)^2.
\]</span></p>
<p>SSE: sum of squares error,
残差平方和，表示拟合数据和原始数据之间的误差的平方和。 <span class="math display">\[
SSE = \sum_{i=1}^n(y_i - \hat{y}_i)^2.
\]</span></p>
<p><span class="math display">\[
R^2 = 1 - \frac{\sum_{i=1}^n(y_i - \hat{y}_i)^2}{\sum_{i=1}^n(y_i -
\bar{y})^2} = 1 - \frac{SSE}{SSR}.
\]</span></p>
<p>决定系数<span class="math inline">\(R^2\)</span>的取值范围为<span class="math inline">\([0,1]\)</span>，0表示没有线性关系，1表示拟合模型可以解释所有变异y。</p>
<h4 id="调整的决定系数-barr2">调整的决定系数 <span class="math inline">\(\bar{R}^2\)</span></h4>
<p>对于决定系数 <span class="math inline">\(R^2\)</span>，当解释变量个数增加（即模型复杂度提高，偏差降低）时，<span class="math inline">\(R^2\)</span>
会不断增加。但是，随着模型复杂度的提高，方差可能会越来越大。因此，引入了调整的决定系数<span class="math inline">\(\bar{R}^2\)</span>： <span class="math display">\[
\bar{R}^2 = 1 - \frac{SSE/df_{err}}{SSR/df_{tot}} = 1 - （1 - R^2)
\times \frac{n-1}{n-p-1},
\]</span> 其中，df_{err} 表示残差平方和的自由度，为<span class="math inline">\(n-p-1\)</span>，df_{tot}
表示关于总平方和的自由度，为 <span class="math inline">\(n-1\)</span>。</p>
<p>调整后的 <span class="math inline">\(\bar{R}^2\)</span>
可以是负值，其值总是小于或等于 <span class="math inline">\({R}^2\)</span>。当引入更多解释变量时，决定系数<span class="math inline">\({R}^2\)</span>会增加，导致<span class="math inline">\(\bar{R}^2\)</span>的增加。但是后面的分数项会降低<span class="math inline">\(\bar{R}^2\)</span>。只有当减少的偏差大于引入的方差时，<span class="math inline">\(\bar{R}^2\)</span>才会增加。因此，<span class="math inline">\(\bar{R}^2\)</span> 可以看作是对
bias-variance间的tradeoff.</p>
<h4 id="平均绝对百分比误差mean-absolute-percentage-error-mape">平均绝对百分比误差：（Mean
Absolute Percentage Error, MAPE）</h4>
<p>MAPE表示预测误差相对于真实值的百分比。 <span class="math display">\[
MAPE = \frac{1}{n}\sum_{1}^{n} |\frac{y_i - \hat{y}_i}{y_i}| \times
100\%.
\]</span>
优点：易于解释，特别适用于需要对误差进行相对度量的场景。缺点：当真实值接近0时，MAPE会变得不稳定。</p>
<h3 id="bias-variance-trade-off模型过拟合欠拟合">1.6. Bias-variance
trade-off，模型过拟合、欠拟合</h3>
<p><img src="/2024/10/08/statistic/bias_variance.jpg"></p>
<p><strong>误差分析</strong>：通过训练误差和测试误差来分析模型是否存在高方差、高偏差。</p>
<ul>
<li>如果训练误差较高：说明模型的偏差较大，模型出现了欠拟合。</li>
<li>如果训练误差较低，而测试误差较高：说明模型的方差较大，出现了过拟合。</li>
<li>如果训练误差较低，测试误差也较低：说明模型的方差和偏差都适中，是一个比较理想的模型。</li>
<li>如果训练误差较高，且测试误差更高：说明模型的方差和偏差都较大。</li>
</ul>
<p>上述分析的前提是：训练集、测试集的数据来自于同一个分布，且最优误差较小。否则讨论更复杂。</p>
<p><strong>欠拟合</strong>：模型过于简单，没有很好地学习到数据间的关系，训练集效果差。<strong>模型复杂度低，此时模型预测的方差较小，表示预测较稳定。但是模型预测的偏差会较大，表示预测不准确。。</strong></p>
<p><strong>过拟合</strong>：指学习时选择的模型所包含的参数过多，以至出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。训练集效果好，测试集效果差。
<strong>模型复杂度高，此时模型预测的方差大，偏差小。</strong></p>
<h4 id="欠拟合解决方法">欠拟合解决方法</h4>
<ol type="1">
<li>增加特征</li>
<li>提高模型复杂度：神经网络提高神经元数、增加层数；SVM使用核函数；</li>
<li>减小正则项的系数</li>
</ol>
<h4 id="过拟合解决方法">过拟合解决方法</h4>
<ol type="1">
<li>提高样本数量。神经网络：Data Augmentation（数据增强）</li>
<li>简化模型。神经网络使用 Dropout、Early
Stopping；决策树剪枝、限制树的深度。</li>
<li>加入正则化项（L1或L2）或提高惩罚系数</li>
<li>使用集成学习</li>
<li>神经网络中使用dropout机制</li>
<li>early stopping</li>
</ol>
<h3 id="奥卡姆剃刀定律是什么对机器学习模型优化有何启发">1.7.
奥卡姆剃刀定律是什么？对机器学习模型优化有何启发？</h3>
<p>奥卡姆剃刀定律：若有多个假设与观察一致，则选最简单的那个。</p>
<p>奥卡姆剃刀原理应用于模型选择时变为以下想法：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的，也就是应该选择的模型。</p>
<p>从贝叶斯估计的角度来看，正则化项对应于模型的先验概率。可以假设复杂的模型有较小的先验概率，简单的模型有较大的先验概率。</p>
<h3 id="线性模型-vs.-非线性模型-生成式模型-vs.-判别式模型-概率模型-vs.-非概率模型-参数化模型-vs.-非参数化模型">1.8.
线性模型 vs. 非线性模型， 生成式模型 vs. 判别式模型， 概率模型 vs.
非概率模型， 参数化模型 vs. 非参数化模型</h3>
<p><strong>线性模型 vs. 非线性模型</strong></p>
<p>非概率模型可以分为线性模型和非线性模型。如果函数 <span class="math inline">\(y=f(x)\)</span> 或 <span class="math inline">\(z =
g(x)\)</span>
是线性函数，则称模型是线性模型，否则成模型为非线性模型。</p>
<p>线性模型：感知机、线性支持向量机、k近邻、k均值、潜在语义分析</p>
<p>非线性模型：核函数支持向量机、AdaBoost，神经网络</p>
<p><strong>生成式模型 vs. 判别式模型</strong></p>
<p>监督学习方法分为生成方法（generative
approach）和判别方法（discriminative
approach）。所学习到的模型分别称为生成模型和判别模型。监督学习的模型一般形式为决策函数：<span class="math inline">\(Y = f(X)\)</span> 或者条件概率分布 <span class="math inline">\(P(Y|X)\)</span>。</p>
<p>生成方法：由数据学习联合概率分布 <span class="math inline">\(P(X,Y)\)</span>，然后求出条件概率分布 <span class="math inline">\(P(Y|X)\)</span>作为预测模型： <span class="math display">\[
P(Y|X) = \frac{P(X,Y)}{P(X)}
\]</span> 之所以叫做生成方法，是因为模型表示了给定输入 <span class="math inline">\(X\)</span> 产生输出 <span class="math inline">\(Y\)</span>的生成关系。典型的生成模型：朴素贝叶斯法、隐马尔可夫模型。</p>
<p>判别方法：由数据直接学习决策函数 <span class="math inline">\(f(X)\)</span> 或者条件概率分布 <span class="math inline">\(P(X,Y)\)</span>作为预测的模型，关心的是对给定的输入
<span class="math inline">\(X\)</span>，应该预测什么样的输出 <span class="math inline">\(Y\)</span>。典型的判别模型：k近邻、感知机、决策树、逻辑斯蒂回归、最大熵模型、支持向量机、提升方法、条件随机场。</p>
<p><strong>概率模型 vs. 非概率模型</strong></p>
<p>概率模型与非概率模型的区别在于模型的内在结构。<strong>概率模型一定可以表示为联合概率分布的形式</strong>，其中的变量表示输入、输出、因变量甚至参数。而针对非概率模型则不一定存在这样的联合概率分布。</p>
<p>统计学习的模型可以分为概率模型（probabilistic
model）和非概率模型（non-probabilistic
model）或者确定性模型（deterministic
model）。在监督学习中，概率模型取条件概率分布形式 <span class="math inline">\(p(y|x)\)</span>，非概率模型取函数形式 <span class="math inline">\(y=f(x)\)</span>，其中<span class="math inline">\(x\)</span>是输入，<span class="math inline">\(y\)</span>是输出。在无监督学习中，概率模型取条件概率分布形式
<span class="math inline">\(p(z|x)\)</span>或 <span class="math inline">\(p(x|z)\)</span>，其中<span class="math inline">\(x\)</span>是输入，<span class="math inline">\(z\)</span>是输出。在监督学习中，概率模型是生成模型，非概率模型是判别模型。</p>
<p>概率模型：决策树、朴素贝叶斯、隐马尔可夫模型、条件随机场、概率潜在语义分析、潜在狄利克雷分布、高斯混合模型</p>
<p>非概率模型：感知机、支持向量机、k近邻、AdaBoost、k均值、潜在语义分析、神经网络</p>
<p>逻辑斯蒂回归即可看做概率模型，又可看做非概率模型。</p>
<p><strong>参数化模型 vs. 非参数化模型</strong></p>
<p>统计学习模型又可以分为参数化模型（parametric
model）和非参数化模型（non-parametric
model）。参数化模型假设模型参数的维度固定，模型可以由有限维参数完全刻画；非参数模型假设模型参数的维度不固定或者说无穷大，随着训练数据量的增加而不断增大。</p>
<p>参数化模型：感知机、朴素贝叶斯、逻辑斯蒂回归、k均值、高斯混合模型</p>
<p>非参数化模型：决策树、支持向量机、AdaBoost、k近邻、潜在语义分析、概率潜在语义分析、潜在狄利克雷分配</p>
<h3 id="缺失值如何处理">1.9. 缺失值如何处理？</h3>
<p><strong>1.</strong>
缺失值较多.直接将该特征舍弃掉，否则可能反倒会带入较大的噪声，对结果造成不良影响。</p>
<p><strong>2.</strong>
缺失值较少,其余的特征缺失值都在10%以内，我们可以采取很多的方式来处理:（1）把NaN直接作为一个特征，假设用0表示；（离散特征取值k维扩充到k+1维）（2）用均值填充；（连续特征-均值，离散特征-特征取值的众数）（3）用随机森林等算法预测填充。</p>
<h3 id="标准化归一化介绍">1.10. 标准化、归一化介绍</h3>
<p>为了消除数据特征之间的量纲影响，我们需要对特征进行归一化/标准化处理，使得不同指标之间具有可比性。以梯度下降过程为例，如果不做归一化/标准化处理，在学习速率相同的情况下，大量纲变量的更新速度会大于小量纲，需要较多迭代才能找到最优解。如果将其变换到相同的数值区间后，更新速度变得更为一致，容易更快地通过梯度下降找到最优解。</p>
<p><strong>1. 归一化（Min-Max
Scaling）</strong>：将数据缩放到一个特定的范围（通常是 [0, 1] 或 [-1,
1]）。它的核心思想是通过线性变换，将数据映射到指定区间中。 <span class="math display">\[
  X_{norm} = \frac{X-X_{min}}{X_{max}-X_{min}}
\]</span>
用于输入范围已知的模型（如神经网络），或者需要对距离敏感的算法（如
KNN）。不适用于有异常值的数据，例如有异常大的数值，其他数据会被压缩到很小的数值。</p>
<p><strong>2. 标准化（Z-score
Normalization）</strong>：是将数据进行中心化和缩放处理，使得数据的均值为
0，标准差为
1。这是通过减去数据的均值再除以数据的标准差来实现的，也叫Z-score
标准化。假设原始特征的均值为 <span class="math inline">\(\mu\)</span>，方差为 <span class="math inline">\(\sigma\)</span> ，那么标准化公式定义为 <span class="math display">\[
  z = \frac{x-\mu}{\sigma}.
  \]</span>
适用于数据服从高斯分布（正态分布）或在模型中需要假设数据是标准正态分布的情况，尤其在一些线性模型（如线性回归、逻辑回归、支持向量机）和PCA等算法中较为常用。</p>
<p><strong>3.
对比分析</strong>：归一化可以保持原数据的形状和分布，仅改变其取值范围，因此不会改变数据的分布类型（例如正态分布仍是正态分布）。标准化会改变了数据的中心和尺度，将数据转化为标准正态分布，因此数据的分布会被改变。</p>
<h3 id="l1和l2正则为什么l1比l2更容易产生稀疏解">1.11.
L1和L2正则，为什么L1比L2更容易产生稀疏解?</h3>
<p>L1和L2正则，都可以防止过拟合，增强模型的泛化能力；区别在于L1使参数更稀疏，达到特征选取的作用；L2使参数更接近于0.</p>
<p><img src="/2024/10/08/statistic/l1_l2.jpeg"></p>
<p><strong>从解空间的形状来看：</strong>
L1正则项约束后的解空间是多边形，而L2正则项约束后的解空间是圆形。而多边形的解空间更容易在尖角处与等高线碰撞出稀疏解。图中红色等高线表示不同正则参数下的残差平方和，椭圆中心点为最小二乘估计。绿色区域分别表示使用
<span class="math inline">\(l_1\)</span> 正则函数和<span class="math inline">\(l_2\)</span>正则函数对应的约束域。等高线与约束域的切点表示目标函数的最优解。从图中可以看出，当使用<span class="math inline">\(l_1\)</span>
正则函数时，最优解有可能为稀疏解。</p>
<p><strong>从函数叠加的观点：</strong>
L2正则化使得权重衰减，降低模型复杂度，避免模型过拟合问题。（1）通过限制权重的大小，L2
正则化可以让模型更为“平滑”，即更关注输入特征的整体趋势而不是单个特征的微小变化。这降低了模型过度拟合训练数据中的噪声。（2）权重较小的模型通常更具泛化性，因为它们对数据中偶然的扰动（噪声）不太敏感。权重减小后，模型在验证集或测试集上也会有更好的表现。</p>
<h2 id="经典机器学习算法">2. 经典机器学习算法</h2>
<h3 id="线性回归和逻辑回归">2.1 线性回归和逻辑回归</h3>
<h4 id="线性回归">线性回归</h4>
<p>线性回归的五个基本假设条件： 1.
自变量（解释变量）与因变量（响应变量）之间为线性关系。 2.
自变量之间相互独立，无多重共线性。如果存在多重共线性，就很难确定每个预测因子的单独影响。可以通过计算皮尔逊相关系数，或者方差膨胀因子系数（VIF)进行检验。
3.
误差项之间相互独立，不存在自相关性。尤其是对时间序列数据尤为重要。可以使用DW检验。如果存在自相关性，可以采取自回归模型。
4.
误差项与自变量之间相互独立，无内生性。这一假设可确保自变量真正独立于误差项，且不会产生遗漏变量偏差。可以使用工具变量法等进行检验和处理。
5.
误差项应该呈正态分布，期望为0，方差为定值。这两个假设是为了保证回归模型在小样本下能够顺利进行假设检验，在进行假设检验（如计算
p
值或置信区间）时尤为重要。可以使用Q-Q图可视化来检验是否满足正态分布，Q-Q图趋近于落在一条直线上，说明残差满足正态分布。如果误差项的方差不是恒值（可以通过可视化残差观察到），那么存在异方差性，可以使用加权回归、稳健回归等方法解决。</p>
<p><strong>关于内生变量和外生变量</strong>：与干扰项（误差项）相关的变量称为内生变量(endogenous
variable)；与干扰项不相关的变量称为外生变量(exogenous
variable)。对于线性回归模型，自变量会对因变量产生影响，干扰项也会对因变量产生影响，且干扰项与自变量假设无关。那么此时，自变量就是外生变量，因变量是内生变量。但是有时，可能由于某种原因，干扰项也会对因变量产生一定影响，此时干扰项和因变量相关，出现内生性。主要原因有遗漏变量、双向因果和测量误差等导致无法满足第四条假设。</p>
<p>线性回归模型： <span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ...+ \beta_p x_p + \epsilon.
\]</span> 通过最小化残差平方和SSE来进行求解。最小二乘解为： <span class="math display">\[
\hat{\beta} = (X^T X)^{-1}X^T y.
\]</span></p>
<p><strong>模型评估</strong>： MSE 和 决定系数 <span class="math inline">\(R^2\)</span>。二者的具体定义可见section 1.5。</p>
<ul>
<li>线性假设指的是模型参数的线性，而不一定是原始数据的线性。可以引入变换或非线性特征（如交叉项
<span class="math inline">\(x_1 \times x_2\)</span>、多项式项 <span class="math inline">\(x_1^2\)</span>），只要因变量与参数之间的关系保持线性即可。此时加入非线性特征（如交叉特征或多项式项）并不违反线性回归的假设，因为模型的参数仍然是
"线性的"。</li>
</ul>
<p><strong>多重共线性</strong></p>
<p>当线性回归模型中的两个或多个自变量高度相关，导致信息重叠或冗余时，就会产生多重共线性。在这种情况下，模型很难分离出每个自变量对因变量的单独影响，从而导致不可靠的系数估计、标准误差膨胀以及解释上的挑战。</p>
<p>如何检测和解决多重共线性问题？ 1. 方差膨胀因子 (VIF)：VIF
是一种常见的诊断工具，用于衡量回归系数的方差因多重共线性而膨胀的程度。VIF
超过 5 或 10 表示多重共线性很高。 2.
相关矩阵：检查自变量的相关矩阵可以发现高度相关的变量对（相关性接近 1
或-1）。这表明存在潜在的多重共线性。 3.
放弃其中一个相关变量：如果两个或多个变量高度相关，可考虑放弃其中一个变量。这可以简化模型并减少多重共线性。
4. 主成分分析（PCA）：PCA
可以将相关变量转化为一组不相关的成分，用于回归分析。这可以降低数据维度，避免多重共线性。
5.
岭回归或lasso回归：这些正则化技术有助于减轻多重共线性的影响。岭回归会对系数的大小进行惩罚，从而降低系数对多重共线性的敏感性（不具备变量筛选的能力，无法完全解决）。lasso回归则更进一步，可以将某些系数缩减为零，从而有效地选择预测因子的子集。</p>
<h4 id="逻辑回归">逻辑回归</h4>
<p>逻辑回归是一种广泛用于二元分类任务的监督学习算法。在机器学习中，监督学习包括对输入输出对进行模型训练，以学习能够预测未见数据的模式。逻辑回归专门预测基于输入特征的分类结果的概率，其中结果属于两个类别之一。虽然逻辑回归可以扩展到多个类别，但其最常见的应用还是二元分类。</p>
<p>逻辑回归模型： <span class="math display">\[
p(y = 1 | x) = sigmoid(z) = \frac{1}{1 + e^{-z}}, z = {\beta}_0 +
{\beta}_1 x_1 + ...+ {\beta}_k x_k.
\]</span></p>
<p><strong>模型评估</strong></p>
<p>逻辑回归模型使用损失函数进行评估，该函数用于衡量模型预测真实结果的能力。对于二元分类，合适的损失函数是
Log-Loss（也称为二元交叉熵）。对于有 <span class="math inline">\(n\)</span> 个样本的给定数据集，Log-Loss 的定义为:
<span class="math display">\[
Log-loss = - \sum_{i=1}^{n} [y_i \log p_i + (1-y_i)\log (1-p_i)],
\]</span> 其中，<span class="math inline">\(y_i\)</span> 为第<span class="math inline">\(i\)</span>个样本的真实标签，<span class="math inline">\(p_i\)</span> 为第<span class="math inline">\(i\)</span>个样本的输出概率。</p>
<p><strong>系数估计算法</strong></p>
<p>有两种主流的方式去估计模型的参数 <span class="math inline">\({\beta}\)</span>，（1）梯度下降；（2）最大似然估计（MLE).</p>
<p>最大似然估计：对于逻辑回归，定义函数 <span class="math inline">\(h_{\beta}(x) = \frac{1}{1 +
e^{-z}}\)</span>，其似然函数为所有样本观测值出现概率的乘积，可以表示为：
<span class="math display">\[
L(\beta) = \prod_{i=1}^{n} [h_{\beta}(x_i)]^{y_i}[1 -
h_{\beta}(x_i)]^{(1-y_i)}.
\]</span>
最大化该似然函数，通常会转化为最大化其对数似然，然后用梯度下降法求解。对数似然函数为：
<span class="math display">\[
\log L(\beta) = \sum_{i=1}^{n} [y_i \log h_{\beta}(x_i)+(1-y_i)\log(1 -
h_{\beta}(x_i))].
\]</span> 显然，最大化对数似然等价于最小化log-loss。</p>
<p><strong>多标签分类</strong>：假设每个样本属于不同标签的概率服从几何分布，可以使用softmax
regression进行分类： $$ h_= = </p>
<p></p>
<p> $$ 其中 <span class="math inline">\(\theta_1,\theta_2 \dots,\theta_k
\in \mathbb{R}^n\)</span></p>
<p>如果存在样本可能属于多个标签的情况时，可以训练k个二分类的逻辑回归分类器。第i个分类器用以区分每个样本是否可以归为第i类。</p>
<h4 id="二者之间的联系">二者之间的联系</h4>
<p>如果把一个事件的几率（odds）定义为该事件发生的概率与不发生概率的比值
<span class="math inline">\(\frac{p}{1-p}\)</span>
，那么逻辑回归可以看做是对于"y=1|x"这一事件的对数几率的线性回归 <span class="math display">\[
{\rm log} \frac{p}{1-p} = \theta^{T}x ，其中\ p  = P(y=1|x).
\]</span></p>
<h3 id="k-近邻算法k-nearest-neighborsknn">2.2. K-近邻算法（K-Nearest
Neighbors，KNN）</h3>
<p>K-近邻算法（KNN）是一种监督学习算法，主要用于分类和回归问题。KNN
是一种基于实例的学习方法，其核心思想是：给定一个未标记的样本，找到与该样本最相似的
<span class="math inline">\(k\)</span>
个已知标签的样本（最近邻居），然后通过这些邻居的类别信息进行预测。 KNN
适合小数据集的分类和回归任务。然而，随着数据规模的增长和维度的增加，KNN
的计算成本和性能都会变得较差，因此在实际应用中常结合其他优化技术使用，比如
KD 树、Ball 树等。</p>
<h4 id="计算流程">计算流程</h4>
<ol type="1">
<li><p><strong>数据预处理</strong>：对于每个输入样本，<strong>首先需要进行标准化或归一化操作，确保不同特征值处于相同的数值范围，否则距离计算时可能会被某些特征主导。</strong></p></li>
<li><p><strong>计算距离</strong>：对新的测试样本，基于某一距离标准，计算它与所有训练样本之间的距离。</p></li>
<li><p><strong>选择K值</strong>：选择一个合适的 <span class="math inline">\(k\)</span>
值（即考虑的邻居数量），通常是一个正整数。较小的 <span class="math inline">\(k\)</span> 可能导致模型过拟合，较大的 <span class="math inline">\(k\)</span> 则可能导致模型过于平滑。</p></li>
<li><p><strong>选择最近的K个邻居</strong>：根据距离计算的结果，选择离测试样本最近的
<span class="math inline">\(k\)</span> 个训练样本。</p></li>
<li><p><strong>进行投票或加权</strong>：</p>
<ul>
<li><strong>分类问题</strong>：通过这 <span class="math inline">\(k\)</span>
个最近邻居的类别进行投票，选择出现最多的类别作为预测结果。</li>
<li><strong>回归问题</strong>：通过这 <span class="math inline">\(k\)</span>
个最近邻居的数值标签，通常取它们的均值或加权平均值作为预测结果。</li>
</ul></li>
<li><p><strong>输出预测结果</strong>：得到最终预测值，完成预测。</p></li>
</ol>
<p>在实际应用中，<span class="math inline">\(k\)</span>
值一般取一个比较小的数值，例如采用交叉验证法来选择最优的 <span class="math inline">\(k\)</span> 值。</p>
<h4 id="优点">优点</h4>
<ol type="1">
<li><p><strong>简单易懂</strong>：KNN
不需要进行复杂的模型训练，只需要存储所有训练数据，直观易理解。</p></li>
<li><p><strong>无参数学习</strong>：KNN
不假设数据的分布情况，它是一种非参数学习方法，因此对数据的分布形式没有要求。</p></li>
<li><p><strong>灵活性强</strong>：可以用于分类和回归问题，距离度量方法也可以根据实际需要灵活更改。</p></li>
<li><p><strong>增量学习</strong>：KNN
可以适应动态变化的数据集，因为新样本只需要加入到训练集中即可，不需要重新训练模型。</p></li>
</ol>
<h4 id="缺点">缺点</h4>
<ol type="1">
<li><p><strong>计算量大</strong>：每次预测都需要计算新样本与所有训练样本之间的距离，因此计算开销大，特别是在样本数量多时，效率较低。</p></li>
<li><p><strong>高维数据效果较差</strong>：在高维空间中，数据变得稀疏，"距离"的直观意义减弱，KNN
在高维数据下表现通常不佳，这就是所谓的"维度灾难"。</p></li>
<li><p><strong>对数据量敏感</strong>：KNN
对噪声和异常值敏感，噪声点可能严重影响最终的分类结果，尤其在 $ k $
值较小的情况下。</p></li>
<li><p><strong>对特征缩放敏感</strong>：不同特征的量纲差异可能会导致某些特征主导距离计算，因此需要对数据进行标准化或归一化处理。</p></li>
</ol>
<h4 id="常用的距离衡量公式">常用的距离衡量公式</h4>
<p><strong>1. 闵可夫斯基距离</strong></p>
<p>假设特征空间 <span class="math inline">\(\mathcal X\)</span>
是n维实数向量空间 <span class="math inline">\(\mathbf{R}^n\)</span>
，<span class="math inline">\(x_i, x_j \in \mathcal{X}, x_i =
(x_i^{(1)}, x_i^{(2)},\cdots x_i^{(n)}  ),  x_j = (x_j^{(1)}, x_j^{(2)},
\cdots, x_j^{(n)})\)</span> 。则 <span class="math inline">\(x_i,
x_j\)</span> 的 <span class="math inline">\(L_p\)</span>
距离（闵可夫斯基距离）定义为 <span class="math display">\[
  L_p(x_i, x_j) = (\sum_{l=1}^n |x_i^{(l)}-x_j^{(l)}|^p)^{\frac{1}{p}},
\quad p \geq 1.
\]</span></p>
<p><strong>2. 欧式距离</strong></p>
<p>当闵可夫斯基距离公式中 <span class="math inline">\(p=2\)</span>
时，称为欧氏距离，用来衡量两点在多维空间中的直线距离，是严格定义的距离，满足正定性、对称性、三角不等式。
<span class="math display">\[
  L_2(x_i, x_j) = (\sum_{l=1}^n |x_i^{(l)}-x_j^{(l)}|^2)^{\frac{1}{p}}.
\]</span>
欧式距离对较大的差异很敏感，如果某个特征值差异大，欧氏距离会受到很大影响，因此数据常需要进行归一化或标准化。</p>
<p><strong>3. 曼哈顿距离</strong></p>
<p>当闵可夫斯基距离公式中 <span class="math inline">\(p=1\)</span>
时，称为曼哈顿距离，用于衡量点与点之间的坐标差异之和，即从一个点到另一个点走直角路径的总距离。
<span class="math display">\[
  L_1(x_i, x_j) = \sum_{l=1}^n |x_i^{(l)}-x_j^{(l)}|.
\]</span>
曼哈顿距离通常用于街区格子的路径计算，模拟只能沿着水平和垂直方向移动的场景。在高维空间中，由于它对特征值间差异的处理方式相对温和，因此它可能比欧氏距离对噪声更加鲁棒。</p>
<p><strong>4. 切比雪夫距离</strong></p>
<p>当 <span class="math inline">\(p = \infty\)</span>
时，称作切比雪夫距离。两个向量各个坐标距离数值差的绝对值的最大值。 <span class="math display">\[
  L_{\infty}(x_i, x_j) = \mathop{\max}_{l} \  |x_i^{(l)}-x_j^{(l)}|.
\]</span> 切比雪夫距离对数据的最大变化特别敏感。</p>
<p><strong>5. 马氏距离</strong></p>
<p>考虑各个分量（特征）之间的相关性并与各个分量的尺度无关。给定一个样本集合
<span class="math inline">\(X\)</span>，<span class="math inline">\(X=(x_{ij})_{m\times n}\)</span>，其协方差矩阵记为
<span class="math inline">\(S\)</span>。样本 <span class="math inline">\(x_i\)</span> 与样本 <span class="math inline">\(x_j\)</span> 之间的马氏距离 <span class="math inline">\(d_{ij}\)</span> 定义为 <span class="math display">\[
d_{ij} = [(x_i - x_j)^TS^{-1}(x_i - x_j)]^{\frac{1}{2}}.
\]</span> 当 <span class="math inline">\(S\)</span>
为单位矩阵时，即样本数据的各个分量互相独立且各个分量的方差为1时，马氏距离就是欧氏距离。</p>
<p>马氏距离不仅考虑了点与点之间的距离，还考虑了特征之间的相关性（通过协方差矩阵），适合特征相关性较强的场景，在这些情况下比欧氏距离更加准确。</p>
<p><strong>6. 汉明距离</strong></p>
<p>汉明距离用于衡量<strong>两个等长的二进制向量或字符串</strong>之间有多少位不相同。换句话说，它表示两个字符串之间的不同字符个数。通常用于编码、错误检测与纠正等领域。</p>
<p>对于两个长度相同的二进制序列 $ p $ 和 $ q <span class="math inline">\(，汉明距离的定义为：\)</span>$ d(p, q) =
_{i=1}^{n} (p_i, q_i). $$ 其中，$ (p_i, q_i) $ 为指示函数，当 $ p_i q_i
$ 时，$ (p_i, q_i) = 1 $，否则 $ (p_i, q_i) = 0 $。</p>
<p>1011101 与 1001001 之间的汉明距离是 2。</p>
<p>2143896 与 2233796 之间的汉明距离是 3。</p>
<p>"toned" 与 "roses" 之间的汉明距离是 3。</p>
<p><strong>7. 相关系数</strong>（correlation coefficient）</p>
<p>相关系数用于衡量两个向量或变量之间的<strong>线性相关性</strong>。它的值范围在
<span class="math inline">\([-1, 1]\)</span> 之间： - $ 1 $
表示完全正相关； - $ -1 $ 表示完全负相关； - $ 0 $
表示没有线性关系。</p>
<p>最常用的相关系数是<strong>皮尔逊相关系数</strong>（Pearson
Correlation Coefficient）。 <span class="math inline">\(x_i\)</span> 与
<span class="math inline">\(x_j\)</span> 之间的相关系数定义为 <span class="math display">\[
r_{ij} =
\frac{\sum_{k=1}^{m}\left(x_{k i}-\overline{x}_{i}\right)\left(x_{k
j}-\overline{x}_{j}\right)}{\left[\sum_{k=1}^{m}\left(x_{k
i}-\overline{x}_{i}\right)^{2} \sum_{k=1}^{m}\left(x_{k
j}-\overline{x}_{j}\right)^{2}\right]^{\frac{1}{2}}}.
\]</span></p>
<p><span class="math display">\[
\overline{x}_{i}=\frac{1}{m} \sum_{k=1}^{m} x_{k i}, \quad
\overline{x}_{j}=\frac{1}{m} \sum_{k=1}^{m} x_{k j}
\]</span></p>
<p><strong>8. 余弦相似度</strong></p>
<p>余弦相似度用于衡量两个向量之间的夹角，它用于计算两个向量在<strong>方向上</strong>的相似性，而不是在大小上的相似性。不是严格定义的距离，满足正定性、对称性，不满足三角不等式。
余弦相似度的取值范围在 <span class="math inline">\([-1, 1]\)</span>
之间: - 1 表示两个向量完全相同（方向一致）； - 0
表示两个向量正交（没有相似性）； - -1 表示两个向量方向完全相反。</p>
<p>公式定义为： <span class="math display">\[
  cos(A,B) = \frac{A \cdot B}{||A||_2 ||B||_2}.
\]</span></p>
<p><strong>使用场景</strong></p>
<ol type="1">
<li><p><strong>欧氏距离</strong>：适合维度较低、特征彼此独立且已归一化的数据。计算点与点之间的"直线距离"。</p></li>
<li><p><strong>曼哈顿距离</strong>：当特征值的分布差异较大或者关注的是各维度变化总和时效果较好。用于计算只能沿着水平和垂直方向的移动（如城市网格或棋盘）。</p></li>
<li><p><strong>闵可夫斯基距离</strong>：通用的度量方式，适合需要灵活调整距离公式的场景。</p></li>
<li><p><strong>切比雪夫距离</strong>：适合在某些场景下只关心各坐标轴的最大差异，如国际象棋中的"国王路径"问题。</p></li>
<li><p><strong>马氏距离</strong>：适用于多维数据且特征之间存在相关性，考虑数据的分布情况。</p></li>
<li><p><strong>汉明距离</strong>：适用于二进制向量或字符串的比较，主要衡量离散值之间的差异。</p></li>
<li><p><strong>相关系数</strong>：用于衡量两个数值变量的线性相关性，适合线性关系的分析。</p></li>
<li><p><strong>余弦相似度</strong>：用于评估向量之间的方向相似性，广泛用于文本处理和推荐系统中。</p></li>
</ol>
<h3 id="支持向量机svmsupport-vector-machine">2.3.
支持向量机（SVM，Support Vector Machine）</h3>
<p>支持向量机（SVM）是一种<strong>监督学习</strong>算法，主要用于<strong>分类</strong>和<strong>回归</strong>问题，尤其擅长处理<strong>二分类问题</strong>。
它的基本模型是定义在特征空间的<strong>间隔最大的线性分类器</strong>。SVM
尝试在多维空间中找到一个<strong>超平面</strong>，将不同类别的数据点分开。在许多情况下，数据是线性不可分的，因此
SVM
通过将数据映射到<strong>高维特征空间</strong>，使得在这个新空间中可以找到一个线性可分的超平面。</p>
<ul>
<li><p>线性可分支持向量机：当训练数据线性可分，通过硬间隔最大化，学习一个线性的分类器</p></li>
<li><p>线性支持向量机：当训练数据近似线性可分，通过软间隔最大化，学习一个线性的分类器</p></li>
<li><p>非线性支持向量机：当训练数据线性不可分，通过使用核技巧及软间隔最大化，学习非线性分类器</p></li>
</ul>
<h4 id="超平面与支持向量">超平面与支持向量</h4>
<ul>
<li><p><strong>超平面</strong>：在二分类问题中，超平面是将数据点划分为两类的决策边界。在二维空间中，超平面是一个直线；在三维空间中，超平面是一个平面；在更高维的情况下，超平面是一个
<span class="math inline">\(n-1\)</span> 维的结构。</p></li>
<li><p><strong>支持向量</strong>：支持向量是距离超平面<strong>最近的</strong>数据点。SVM
通过这些支持向量来定义和构建超平面，因此它们对决策边界的确定具有重要作用。</p></li>
<li><p><strong>间隔（Margin）</strong>：SVM
的核心思想是找到一个能<strong>最大化间隔</strong>的超平面，即使得支持向量到超平面的距离最大化。间隔越大，模型的泛化能力越强。</p></li>
</ul>
<h4 id="线性可分-svm">线性可分 SVM</h4>
<p>在<strong>线性可分</strong>的情况下，SVM
寻找的是能够完全分离两类数据的超平面。给定一组训练样本 ${(x_1, y_1),
(x_2, y_2), , (x_n, y_n)} $，其中 $ x_i ^n $ 是样本，$ y_i {-1, 1} $
是类别标签，SVM 要找到的超平面可以表示为： <span class="math display">\[
w \cdot x + b = 0,
\]</span> 其中，$ w $ 是超平面的法向量，$ b $
是偏移量。为了使超平面将两类数据完全分开，我们希望满足以下约束条件： -
对于 $ y_i = 1 $ 类别的点，要求 $ w x_i + b $。 - 对于 $ y_i = -1 $
类别的点，要求 $ w x_i + b $。</p>
<p>对于一个点 $ x $，它到超平面 $ w x + b = 0 $ 的几何距离可以表示为：
<span class="math display">\[
d(x, \text{hyperplane}) = \frac{|w \cdot x + b|}{\|w\|}.
\]</span> 对于支持向量 $ x_i $，它们距离超平面最近，因此满足 $ w x_i + b
= $ 的约束。 两个类别的支持向量分别位于 $ w x + b = 1 $ 和 $ w x + b =
-1 $ 的平面上。</p>
<p><strong>间隔</strong>（即两个支持向量之间的距离）可以表示为两个支持向量平面之间的距离：
<span class="math display">\[
\text{Margin} = \frac{|1 - (-1)|}{\|w\|} = \frac{2}{\|w\|}
\]</span> SVM 的目标就是<strong>最大化间隔</strong>，等价于**最小化 $
|w| <span class="math inline">\(**。最终的优化问题可以写作：\)</span>$
|w|^2 y_i (w x_i + b) , , i $$</p>
<h4 id="线性不可分-svm">线性不可分 SVM</h4>
<p>在很多实际场景中，数据并非线性可分。此时，我们可以引入<strong>软间隔（Soft
Margin）</strong>，允许一些数据点出现在错误的侧面，从而使模型更具弹性。
为了处理这种情况，SVM 引入了<strong>松弛变量</strong> $ <em>i <span class="math inline">\(，允许某些数据点不满足分类约束条件。优化问题变为：\)</span>$
|w|^2 + C </em>{i=1}^{n} _i y_i (w x_i + b) - _i, , _i , $$ 其中，<span class="math inline">\(C\)</span>
是一个正的常数，用于控制<strong>间隔大小和分类错误惩罚</strong>之间的权衡。较大的
$ C $ 值会导致模型更加关注分类准确性，忽略间隔；较小的 $ C $
值则更关注间隔大小，允许更多的分类错误。</p>
<p>通过拉格朗日乘子法，将 SVM
原始问题中的约束优化问题转化为对偶形式的二次规划问题。使用二次规划求解器或
SMO 算法求解对偶问题。 <span class="math display">\[
\max_{\alpha} \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n}
\sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (x_i \cdot x_j).
\]</span> <span class="math display">\[
\text{s.t.} \quad \sum_{i=1}^{n} \alpha_i y_i = 0, \quad 0 \leq \alpha_i
\leq C.
\]</span></p>
<p>对于训练一个不加入松弛变量的SVM模型时，训练误差为0的SVM分类器一定存在。对于加入松弛变量的SVM的训练误差不一定能达到0。</p>
<h4 id="核方法kernel-trick">核方法（Kernel Trick）</h4>
<p>在处理<strong>非线性分类问题</strong>时，直接在原始特征空间中很难找到线性可分的超平面。SVM
通过<strong>核方法</strong>（Kernel
Trick）将原始数据映射到一个<strong>高维空间</strong>，在这个空间中数据可以线性分离。</p>
<p><strong>核函数定义</strong>：设 <span class="math inline">\(\mathcal{X}\)</span> 是输入空间，又设 <span class="math inline">\(\mathcal{H}\)</span> 为特征空间，如果存在一个从
<span class="math inline">\(\mathcal{X}\)</span>到 <span class="math inline">\(\mathcal{H}\)</span> 的映射 <span class="math display">\[
\phi(x) : \mathcal{X} \rightarrow \mathcal{H}
\]</span> 使得对所有<span class="math inline">\(x, z \in
\mathcal{X}\)</span>，函数<span class="math inline">\(K(x,
z)\)</span>满足条件 <span class="math display">\[
K(x, z)=\phi(x) \cdot \phi(z)
\]</span> 则称 <span class="math inline">\(K(x,
z)\)</span>为核函数，<span class="math inline">\(\phi(x)\)</span>
为映射函数，式中 <span class="math inline">\(\phi(x) \cdot
\phi(z)\)</span> 为 <span class="math inline">\(\phi(x)\)</span> 和
<span class="math inline">\(\phi(z)\)</span>的内积。</p>
<p>在对偶问题中，可以将 <span class="math inline">\(x \cdot z\)</span>
中的数据分别进行变换，即 <span class="math inline">\(\phi(x) \cdot
\phi(z)\)</span>。为方便计算，可以直接使用核函数 <span class="math inline">\(K(x, z)\)</span> 代替。</p>
<p><strong>线性核函数</strong> <span class="math display">\[
K(x,z) = x \cdot z
\]</span>
主要用于线性可分的情况。可以看到特征空间到输入空间的维度是一样的，其参数少速度快，对于线性可分数据，其分类效果很理想，因此我们通常首先尝试用线性核函数来做分类，看看效果如何，如果不行再换别的。</p>
<p><strong>多项式核函数</strong>（polynomial kernel function） <span class="math display">\[
K(x, z)=(x \cdot z+1)^{p}
\]</span> 对应的支持向量机是一个p次多项式分类器。分类决策函数为 <span class="math display">\[
f(x)=\operatorname{sign}\left(\sum_{i=1}^{N_{s}} a_{i}^{*}
y_{i}\left(x_{i} \cdot x+1\right)^{p}+b^{*}\right)
\]</span> 其中 <span class="math inline">\(x\)</span> 是待分类样本。
多项式核函数可以实现将低维的输入空间映射到高维的特征空间，但是多项式核函数的参数多，当多项式的阶数比较高的时候，核矩阵的元素值将趋于无穷大或者无穷小，计算复杂度会大到无法计算。</p>
<p><strong>高斯核函数</strong>（Gaussian kernel function） <span class="math display">\[
K(x,z) = exp(-\frac{1}{2} \ ||x - z ||_2 ) = \phi(x) \cdot \phi(z)
\]</span> 对应的支持向量机是高斯径向基函数（radial basis
function）分类器，分类决策函数为 <span class="math display">\[
f(x)=\operatorname{sign}\left(\sum_{i=1}^{N_{s}} a_{i}^{*} y_{i} \exp
\left(-\frac{\|x-x_i\|^{2}}{2 \sigma^{2}}\right)+b^{*}\right)
\]</span>
高斯径向基函数是一种局部性强的核函数，其可以将一个样本映射到一个更高维的空间内，该核函数是应用最广的一个，无论大样本还是小样本都有比较好的性能，而且其相对于多项式核函数参数要少。</p>
<p><strong>Sigmod核函数</strong> <span class="math display">\[
K\left(x, z\right)=\tanh \left(\eta \ x \cdot z +\theta\right)
\]</span></p>
<p>核方法的关键在于，我们无需显式地将数据映射到高维空间，而是通过<strong>核函数</strong>直接在原始空间中计算高维空间的内积，从而实现非线性分类。</p>
<h4 id="优缺点">优缺点</h4>
<h5 id="优点-1">优点：</h5>
<ul>
<li><strong>高效处理高维数据</strong>：SVM
在高维空间中仍能表现良好，尤其是使用核方法时可以处理复杂的非线性分类问题。</li>
<li><strong>强大的泛化能力</strong>：通过最大化间隔，SVM
通常能够很好地避免过拟合问题，具有良好的泛化性能。</li>
<li><strong>对少量样本较为有效</strong>：即使在样本量较小的情况下，SVM
也能表现出色，因为它只关注支持向量而非所有样本点。</li>
</ul>
<h5 id="缺点-1">缺点：</h5>
<ul>
<li><strong>对大规模数据集的效率较低</strong>：由于 SVM
的复杂度较高，在处理非常大规模的数据集时，训练时间可能较长。</li>
<li><strong>对核函数的选择敏感</strong>：选择不恰当的核函数可能导致模型性能不佳，且参数（如
$ C $ 和 $ $）需要精心调优。</li>
<li><strong>不适合噪声数据</strong>：SVM
对噪声敏感，尤其是在数据中有重叠或混合时，模型可能表现不稳定。</li>
<li><strong>仅支持二分类问题</strong>：原生的 SVM
是二分类模型，虽然可以通过某些策略扩展到多分类（如一对一、多对多方法），但相对其他多分类算法显得复杂。</li>
</ul>
<h4 id="svm-和-感知机的区别">SVM 和 感知机的区别</h4>
<ul>
<li><p>感知机的目标是<strong>找到一个可以将数据点分开的线性超平面</strong>，即将两类数据点尽可能正确地划分。感知机的训练过程是通过逐步调整权重来消除分类错误，直到找到一个可以完全分类的数据超平面。它不考虑<strong>分类间隔</strong>。SVM
不仅要求找到一个分离超平面，还要找到能<strong>最大化分类间隔（margin）</strong>的超平面。最大化间隔可以使模型具有更好的泛化能力，因此
SVM 的目标是找到分类超平面并且使到支持向量的间隔最大化。</p></li>
<li><p>感知机使用的是<strong>误分类驱动的梯度下降法</strong>，即每次在出现误分类时更新权重，直到所有数据点都被正确分类。SVM
通过<strong>凸优化</strong>技术，直接求解带约束的优化问题。其目标函数是最大化分类间隔，通常通过<strong>拉格朗日对偶优化</strong>或<strong>二次规划</strong>求解，或者通过梯度下降法结合核方法来求解非线性问题。</p></li>
<li><p>感知机的泛化能力较弱，它只要找到一个可以完全分离数据的超平面即可，但在实际应用中可能会<strong>过拟合</strong>。SVM
最大化间隔的策略使得它对<strong>噪声和过拟合</strong>有更强的抗性，泛化能力更强。尤其是在小样本或高维数据下，SVM
的表现优于感知机。</p></li>
<li><p>感知机不考虑数据的线性不可分性，如果数据是线性不可分的，它将无法收敛。SVM
可以通过引入<strong>软间隔</strong>处理线性不可分的情况，允许一些数据点处于错误的一侧。此外，SVM
可以通过<strong>核技巧（Kernel
Trick）</strong>将数据映射到高维空间，在高维空间中实现线性分离。</p></li>
</ul>
<h3 id="朴素贝叶斯模型">2.4. 朴素贝叶斯模型</h3>
<p>朴素贝叶斯（Naive
Bayes）模型是一种基于贝叶斯定理的简单而高效的分类算法，广泛应用于文本分类、垃圾邮件检测、情感分析等任务。它在假设特征之间相互独立的前提下进行分类，尽管这一假设在现实中通常不成立，但朴素贝叶斯在许多实际应用中表现仍然相当好。</p>
<h4 id="贝叶斯定理">贝叶斯定理</h4>
<p>朴素贝叶斯模型的基础是<strong>贝叶斯定理</strong>，该定理描述了在给定某些证据的情况下，如何计算某个事件发生的概率。贝叶斯定理的公式如下：
<span class="math display">\[
P(C|X) = \frac{P(X|C) \cdot P(C)}{P(X)},
\]</span> 其中： - $ P(C|X) $：给定特征 $ X $ 时类别 $ C $
发生的<strong>后验概率</strong>； - $ P(C) $：类别 $ C $
的<strong>先验概率</strong>，即在没有观察到特征 $ X $ 时类别 $ C $
发生的概率； - $ P(X|C) $：给定类别 $ C $ 时，特征 $ X $
发生的概率，即<strong>似然函数</strong>； - $ P(X) $：特征 $ X $
的<strong>边缘概率</strong>，即所有类别中特征 $ X $ 发生的概率。</p>
<h4 id="朴素贝叶斯分类器">朴素贝叶斯分类器</h4>
<p>朴素贝叶斯模型被称为“朴素”的原因是它基于一个<strong>朴素的独立假设</strong>，即假设所有特征
$ X = [X_1, X_2, , X_n] $ 之间是相互独立的，给定类别 $ C $
时，特征之间没有相关性。根据这一假设，贝叶斯定理中的 $ P(X|C) $
可以简化为： <span class="math display">\[
P(X|C) = P(X_1|C) \cdot P(X_2|C) \cdot \ldots \cdot P(X_n|C)
\]</span> 即特征的联合概率可以表示为每个特征条件概率的乘积。</p>
<p>基于上述假设，朴素贝叶斯分类器的目标是对于每个类别 $ C
$，计算后验概率 $ P(C|X) <span class="math inline">\(，并选择概率最大的类别作为预测结果：\)</span>$ =
_C P(C|X) = <em>C P(C) </em>{i=1}^{n} P(X_i|C) $$</p>
<p><strong>朴素贝叶斯模型之所以被认为是线性分类器，主要是因为它在对数空间下，分类决策边界呈现为一个线性函数。</strong></p>
<h4 id="后验概率最大化的含义是什么">后验概率最大化的含义是什么？</h4>
<p>朴素贝叶斯法将实例分到后验概率最大的类中。后验概率最大化这等价于期望风险最小化。</p>
<p>假设选择0-1损失函数： <span class="math display">\[
  L(Y, f(X))=\left\{
    \begin{array}
    {ll}{1,} &amp; {Y \neq f(X)} \\ {0,} &amp; {Y=f(X)}
    \end{array}
    \right.
  \]</span> 其中 <span class="math inline">\(f(X)\)</span>是分类决策函数。这是期望风险函数为
<span class="math display">\[
  R_{\operatorname{cap}}(f)=E[L(Y, f(X))]
  \]</span> 期望是对联合分布 <span class="math inline">\(P(X,Y)\)</span>
取的。由此取条件期望 <span class="math display">\[
  R_{\mathrm{exp}}(f)=E_{X} \sum_{k=1}^{K}\left[L\left(c_{k},
f(X)\right)\right] P\left(c_{k} | X\right)
  \]</span> 为了使期望奉献最小化，只需对 <span class="math inline">\(X=x\)</span> 逐个最小化，由此得到 <span class="math display">\[
  \begin{aligned} f(x) &amp;=\arg \min _{y \in \mathcal{Y}}
\sum_{k=1}^{K} L\left(c_{k}, y\right) P\left(c_{k} | X=x\right) \\
&amp;=\arg \min _{y \in \mathcal{Y}} \sum_{k=1}^{K} P\left(y \neq c_{k}
| X=x\right) \\ &amp;=\arg \min _{y \in
\mathcal{Y}}\left(1-P\left(y=c_{k} | X=x\right)\right) \\ &amp;=\arg
\max _{y \in \mathcal{Y}} P\left(y=c_{k} | X=x\right) \end{aligned}
  \]</span> 这样一来，根据期望风险最小化准则就得到了后延概率最大化准则：
<span class="math display">\[
  f(x)=\arg \max _{c_{k}} P\left(c_{k} | X=x\right)
  \]</span> 即朴素贝叶斯法所采用原理</p>
<h4 id="朴素贝叶斯的三种常见类型">朴素贝叶斯的三种常见类型</h4>
<p>根据特征的不同类型，朴素贝叶斯模型可以分为几种常见的变体：</p>
<p><strong>1. 高斯朴素贝叶斯（Gaussian Naive Bayes）</strong></p>
<p>当特征是<strong>连续值</strong>时，假设特征符合正态分布（高斯分布）。对于每个类别
$ C $，特征的条件概率 $ P(X_i|C) $
可以用以下正态分布的概率密度函数表示： <span class="math display">\[
P(X_i|C) = \frac{1}{\sqrt{2\pi\sigma_C^2}} \exp\left( -\frac{(X_i -
\mu_C)^2}{2\sigma_C^2} \right),
\]</span> 其中，$ _C $ 和 $ _C $ 是特征 $ X_i $ 在类别 $ C $
下的均值和标准差。</p>
<p><strong>1. 多项式朴素贝叶斯（Multinomial Naive Bayes）</strong></p>
<p>用于<strong>离散值特征</strong>，特别适合处理<strong>文本分类</strong>任务。假设每个特征是某个离散事件发生的次数或频率。此时，条件概率
$ P(X_i|C) $ 被建模为多项式分布： <span class="math display">\[
P(X_i|C) = \frac{N_{i,C} + 1}{N_C + |V|},
\]</span> 其中： - $ N_{i,C} $ 是类别 $ C $ 中特征 $ X_i $ 出现的次数；
- $ N_C $ 是类别 $ C $ 中所有特征的总和； - $ |V| $
是特征词汇表的大小（加 1 处理为拉普拉斯平滑）。</p>
<p><strong>3. 伯努利朴素贝叶斯（Bernoulli Naive Bayes）</strong></p>
<p>适用于<strong>二元离散特征</strong>，即特征值仅为 0 或
1（表示特征是否存在）。这在文本分类中常用于二元词袋模型（Binary Bag of
Words），其中每个词的出现与否作为特征： <span class="math display">\[
P(X_i|C) = p_C^{X_i} (1 - p_C)^{(1 - X_i)},
\]</span> 其中，$ p_C $ 是特征 $ X_i $ 在类别 $ C $ 中的概率。</p>
<h4 id="训练过程">训练过程</h4>
<ol type="1">
<li><p><strong>计算先验概率</strong>：先验概率 $ P(C) $ 可以通过类别 $ C
$ 在训练集中出现的频率估计： <span class="math display">\[
P(C) = \frac{\text{样本中类别 } C \text{ 的数量}}{\text{样本总数}}
\]</span></p></li>
<li><p><strong>计算条件概率</strong>：对于每个特征 $ X_i $，计算它在类别
$ C $ 下的条件概率 $ P(X_i|C)
$。根据具体任务的不同，这个概率可能通过频率估计或假设的分布（如高斯分布）来计算。</p></li>
<li><p><strong>构建分类器</strong>：利用贝叶斯定理，将计算得到的条件概率和先验概率结合在一起，构建分类模型。</p></li>
</ol>
<h4 id="优缺点-1">优缺点</h4>
<p><strong>优点：</strong></p>
<ul>
<li><strong>简单高效</strong>：模型非常简单，易于实现，尤其适用于高维数据。</li>
<li><strong>计算速度快</strong>：训练和预测的计算开销很小，适合大规模数据集。</li>
<li><strong>对小数据集有效</strong>：朴素贝叶斯模型对小数据集通常表现良好。</li>
<li><strong>处理缺失数据</strong>：可以轻松处理部分特征缺失的样本。</li>
<li><strong>适合文本分类</strong>：在文本分类任务中，朴素贝叶斯模型表现良好，常用于垃圾邮件分类、情感分析等任务。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>特征独立性假设不现实</strong>：朴素贝叶斯的独立性假设通常在现实数据中不成立，导致模型性能可能受到影响。</li>
<li><strong>对稀有类别敏感</strong>：如果某一类别中某个特征从未出现过（即其条件概率为
0），模型可能会错误地认为该类别不可能发生。这可以通过拉普拉斯平滑来缓解。</li>
<li><strong>无法处理复杂关系</strong>：由于假设特征之间相互独立，朴素贝叶斯无法处理特征之间复杂的依赖关系。</li>
</ul>
<h4 id="贝叶斯网络">贝叶斯网络</h4>
<p>朴素贝叶斯法假设输入变量都是条件独立的，如果假设它们之间<strong>存在概率依存关系</strong>，模型就被成了贝叶斯网络。
贝叶斯网络也称为“信念网”，借助<strong>有向无环图</strong>来刻画属性之间的依赖关系，并使用<strong>条件概率表</strong>来描述属性的联合概率分布。贝叶斯网结构有效地表达了属性的条件独立性。</p>
<p>具体来说，一个贝叶斯网B由结构 <span class="math inline">\(G\)</span>
和参数 <span class="math inline">\(\theta\)</span> 表示，即 <span class="math inline">\(B = &lt;G,\theta&gt;\)</span>
。网络结构G是一个有向无环图，其每个节点对应于一个属性，若两个属性有直接依赖关系，则它们由一条边连接起来；参数
<span class="math inline">\(\theta\)</span>
定量描述这种依赖关系，假设属性 <span class="math inline">\(x_i\)</span>
在G中的父节点集为 <span class="math inline">\(\pi_i\)</span>，则 <span class="math inline">\(\theta\)</span>包含了每个属性的条件概率 <span class="math inline">\(\theta_{x_i|\pi_i} = P_B(x_i|\pi_i)\)</span>。</p>
<p>给定父节点集，贝叶斯网假设每个属性与它的非后裔属性独立，于是将属性的联合概率分布定义为
<span class="math display">\[
P_{B}\left(x_{1}, x_{2}, \ldots, x_{d}\right)=\prod_{i=1}^{d}
P_{B}\left(x_{i} | \pi_{i}\right)=\prod_{i=1}^{d} \theta_{x_{i} |
\pi_{i}}
\]</span></p>
<p>贝叶斯网的一个核心概念是条件独立性。通过有向无环图，可以直接可视化出哪些变量在条件下是独立的。具体来说，贝叶斯网通过图的结构来表示变量之间的条件独立性，简化联合概率的计算。
- 父子节点之间的依赖性：每个节点依赖于它的父节点。 -
马尔可夫性：给定某个节点的父节点，节点与其非后代节点条件独立。</p>
<p>贝叶斯网的推断可以通过多种算法实现，常见的推断算法包括：</p>
<ul>
<li>精确推断：如变量消去算法（Variable
Elimination）、信念传播算法（Belief Propagation）。</li>
<li>近似推断：如马尔可夫链蒙特卡罗方法（Markov Chain Monte Carlo,
MCMC）和粒子过滤（Particle Filtering）。</li>
</ul>
<h3 id="决策树decision-tree">2.5. 决策树（Decision Tree）</h3>
<p>决策树是一种监督学习算法，广泛用于分类和回归任务。决策树通过一系列的特征划分逐步将数据集分成不同的子集，从而生成树状的结构，最终可以对输入样本进行分类或预测。其结构类似于树形图，由节点和分支组成：</p>
<ul>
<li><strong>根节点（Root
Node）</strong>：包含整个数据集，代表模型开始进行决策的地方。</li>
<li><strong>内部节点（Internal
Nodes）</strong>：表示根据某个特征进行的决策（如按年龄划分，收入划分等）。</li>
<li><strong>叶节点（Leaf
Nodes）</strong>：代表最终的输出（分类标签或回归值）。</li>
</ul>
<h4 id="建树过程">建树过程</h4>
<ol type="1">
<li><p><strong>选择划分特征。</strong>
在每一步，决策树会选择一个最优特征将数据集划分成若干子集。这个选择标准可以是<strong>信息增益</strong>、<strong>基尼系数</strong>等。</p></li>
<li><p><strong>划分数据集。</strong>
选择最优的特征后，数据集被划分为若干子集。决策树的每一个子节点对应一个划分后的子集。</p></li>
<li><p><strong>递归地构建子树。</strong>
对于每个子节点，重复第1步和第2步，直到满足停止条件。停止条件一般有以下几种：</p></li>
</ol>
<ul>
<li>节点的所有样本属于同一类别（即纯节点）。</li>
<li>达到树的最大深度。</li>
<li>节点中的样本数量少于某个阈值。</li>
</ul>
<ol start="4" type="1">
<li><strong>生成叶节点。</strong>
当递归停止时，生成叶节点，叶节点代表最终的决策结果（分类标签或回归值）。</li>
</ol>
<h4 id="决策树生成的算法">决策树生成的算法</h4>
<ol type="1">
<li><p><strong>ID3算法（Iterative Dichotomiser 3）。</strong>
该算法使用<strong>信息增益</strong>作为选择特征的标准，选择信息增益最大的特征进行划分。</p></li>
<li><p><strong>C4.5算法。</strong>
这是ID3算法的改进版本，使用<strong>信息增益比</strong>作为划分标准，以避免ID3算法偏向多值特征的问题。</p></li>
<li><p><strong>CART算法（Classification and Regression Tree）。</strong>
适用于分类和回归问题。对于分类任务，CART使用<strong>基尼指数</strong>选择特征；对于回归任务，使用<strong>最小方差</strong>来进行划分。</p></li>
</ol>
<h4 id="决策树的剪枝">决策树的剪枝</h4>
<p>通过<strong>剪枝</strong>防止过拟合。</p>
<p><strong>预剪枝</strong>是指在决策树生成的过程中，对每个节点在划分前先进行估计，若当前节点的划分不能带来决策树泛化性能提升，则停止划分，并将当前节点标记为叶子节点；此时可能存在不同类别的样本同时存于同个节点中，按照多数投票的原则判断节点所属类别</p>
<p>预剪枝对于何时停止决策树的生长：</p>
<ol type="1">
<li><p>当树达到一定深度</p></li>
<li><p>当到达当前节点的样本数量小于某个阈值</p></li>
<li><p>计算每次分裂对测试集的准确度提升，小于某个阈值时停止</p></li>
</ol>
<p><strong>后剪枝</strong>则是先从训练集生成一棵完整的决策树，然后自底向上地对<strong>非叶子节点</strong>进行考察，若该节点对应的<strong>子树替换成叶子结点</strong>能带来泛化性能提升，则将该子树替换为叶子节点。</p>
<h4 id="熵联合熵条件熵kl散度信息增益信息增益比gini系数">熵、联合熵、条件熵、KL散度、信息增益、信息增益比、gini系数</h4>
<p><strong>熵</strong></p>
<p>熵（entropy）是表示随机变量不确定性的度量， <span class="math inline">\(X\)</span>
是一个取有限个值的离散随机变量，其概率分布为 <span class="math display">\[
P(X = x_i) = p_i, \ i=1,2,\cdots,n
\]</span> 则随机变量 <span class="math inline">\(X\)</span> 的熵定义为
<span class="math display">\[
H(X) = -\sum_{i=1}^{n} p_i {\rm log } \ p_i
\]</span> 熵越大，随机变量的不确定性就越大。</p>
<p>而熵其实表示的是一个系统的平均信息量。<strong>自信息量</strong>是用来描述某一事件带来的信息量大小
<span class="math display">\[
I = - {\rm log} \ p_i
\]</span>
通常以2为底，单位是bit；事件的概率越低，那么该事件发生时带来的信息量越大。而通常我们衡量整个系统的信息量，系统存在多个事件
<span class="math inline">\(X=\{x_1,\cdots,x_n\}\)</span>
，每个事件的概率分布<span class="math inline">\(P=\{p_1,\cdots,p_n\}\)</span>
，<strong>熵是整个系统的平均信息量</strong> 。</p>
<p><strong>联合熵</strong>：将一维随机变量分布推广到多维随机变量分布
<span class="math display">\[
H(X,Y) = -\sum\limits_{x,y} p(x,y)\ {\rm log}\ p(x,y)
\]</span> <strong>条件熵</strong>：某个特征A对于数据集D的经验条件熵
<span class="math inline">\(H(D|A)\)</span> 为 <span class="math display">\[
H(D|A) = - \sum_{i=1}^{n} \frac{|D_i|}{|D|} H(D_i) \\ = - \sum_{i=1}^{n}
\frac{|D_i|}{|D|} \lgroup \sum_{k=1}^{K} \frac{|D_{ik}|}{|D_i|} {\rm log
} \frac{|D_{ik}|}{|D_i|} \rgroup
\]</span> <strong>信息增益</strong>： <span class="math inline">\(g(D,A)\)</span> 定义为数据集D的经验熵 <span class="math inline">\(H(D)\)</span> 与特征A给定条件下D的经验条件熵 <span class="math inline">\(H(D|A)\)</span> 的差 <span class="math display">\[
g(D,A) = H(D) - H(D|A)
\]</span></p>
<p><strong>信息增益比</strong>：特征A对于数据集D 的信息增益比定义为
<span class="math display">\[
g_R(D|A) = \frac{g(D|A)}{H_A(D)}
\]</span> 其中 <span class="math display">\[
H_A{(D)} = - \sum_{i=1}^{n} \frac{|D_i|}{|D|} {\rm log }
\frac{|D_i|}{|D|}
\]</span> 为数据集D关于A的取值熵；n为特征A在D上的取值数目；</p>
<p><strong>Gini系数</strong>：描述数据的不确定性。数据集D的Gini系数为
<span class="math display">\[
{\rm Gini}(D) = 1 - \sum_{k=1}^{K
}(\frac{|C_k|}{|D|})^2
\]</span> 其中 <span class="math inline">\(C_k\)</span>是
D中第k类的样本子集，K是类的个数。例如二分类问题，K=2。基尼系数越大，样本集合的不确定性也就越大，这一点与熵相似。基尼系数Gini(D,A)表示经A=a分割后集合D的不确定性。</p>
<p><strong>交叉熵</strong>：刻画两个概率分布之间的距离，通过q来表示p的交叉熵为；一般<strong>p(x)为真实分布</strong>，<strong>q(x)为预测分布</strong></p>
<p>交叉熵不对称。交叉熵越小，概率分布越接近 <span class="math display">\[
H(p,q) = - \sum\limits_{x} p(x) {\rm log } \ q(x)
\]</span></p>
<p><strong>KL散度/相对熵</strong></p>
<p><span class="math display">\[
D_{K L}(p \| q)=\sum_{i=1}^{n} p\left(x_{i}\right) \log
\left(\frac{p\left(x_{i}\right)}{q\left(x_{i}\right)}\right)
\]</span>
n表示事件可能发生的情况总数，KL散度的值越小表示两个分布越接近。 <span class="math display">\[
D_{KL}(p||q) = H(p,q) - H(p)
\]</span></p>
<p>机器学习中，我们常常使用KL散度来评估predict和label之间的差别，但是由于KL散度的后半部分是一个常量，所以我们常常将前半部分的交叉熵作为损失函数，其实二者是一样的。</p>
<p><strong>ID3 最大信息增益</strong></p>
<p>信息增益 <span class="math inline">\(g(D,A)\)</span>
定义为数据集D的经验熵 <span class="math inline">\(H(D)\)</span>
与特征A给定条件下D的经验条件熵 <span class="math inline">\(H(D|A)\)</span> 的差 <span class="math display">\[
g(D,A) = H(D) - H(D|A)
\]</span> 选择 <span class="math inline">\(g(D,A)\)</span>
最大的特征，所有样本根据此特征，划分到不同的节点上。在经验熵不为0的节点中继续生长。ID3算法只有树的生成，容易产生过拟合。</p>
<p><strong>C4.5 最大信息增益比</strong></p>
<p>因为信息增益对取值数目多的属性有所偏好，为了减少这种偏好带来的影响，使用信息增益比来选择最优划分属性。</p>
<p><strong>CART 基尼指数</strong></p>
<p>基尼系数Gini（D）用来表示集合D的不确定性。CART在每一次迭代中选择划分后<strong>基尼指数最小</strong>的特征及其对应的切分点进行分类。CART是一颗二叉树，每次将数据按特征A的区分分成两份，分别进入左右子树。</p>
<h4 id="优缺点-2">优缺点</h4>
<p><strong>优点</strong></p>
<ul>
<li>简单易懂，直观可解释。</li>
<li>适合处理类别和数值型数据。</li>
<li>可以处理不完整的数据。</li>
<li>无需进行特征缩放。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>容易过拟合，特别是当树很深时。</li>
<li>对数据的微小变化敏感，可能生成完全不同的树。</li>
</ul>
<h3 id="随机森林random-forest">2.6. 随机森林（Random Forest）</h3>
<p><strong>随机森林</strong>是一种基于<strong>集成学习（Ensemble
Learning）</strong>思想的算法，它通过构建多个决策树进行训练，并结合这些树的结果进行预测。随机森林可以用于<strong>分类</strong>和<strong>回归</strong>任务。由于它结合了多棵树的优点，具有较强的鲁棒性、抗噪能力，且能够有效防止<strong>过拟合</strong>。</p>
<p>随机森林通过组合多棵决策树的输出结果来提高预测的准确性。其基本原理主要包括两个关键部分：</p>
<ol type="1">
<li><p><strong>Bootstrap抽样</strong>：从原始数据集中随机选择多个有放回的子集，用于训练每一棵树。这意味着每棵树看到的数据并不完全相同，有些样本会被多次选择，而有些样本可能不会被选中。</p></li>
<li><p><strong>特征随机性</strong>：在每次节点分裂时，随机选择特征的子集进行划分，而不是使用所有特征。这进一步增加了树的多样性，减少了单棵树的过拟合风险。</p></li>
</ol>
<p>随机森林使用了Bagging的思想，通过对数据再抽样，然后在每组样本上训练出来的模型取平均。Bagging是降低方差，防止过拟合。对n个独立不相关的模型的预测结果取平均，方差近似为原来单个模型的
<span class="math inline">\(1/n\)</span> 。</p>
<h4 id="工作流程">工作流程</h4>
<p>随机森林的工作可以分为以下步骤：</p>
<ol type="1">
<li><strong>构造随机森林</strong>
<ul>
<li><strong>数据集随机抽样</strong>：从训练数据集中进行Bootstrap抽样，生成若干个随机的子集，每个子集用于训练一棵决策树。</li>
<li><strong>构建决策树</strong>：对于每个样本子集，训练一棵决策树。不同于传统决策树，每次分裂时会随机选择特征子集来决定最优的划分。</li>
</ul></li>
<li><strong>训练过程</strong>
<ul>
<li>对于每个决策树，通过数据子集和随机选择的特征构造完全树，通常不对树进行剪枝。</li>
<li>每棵树会独立学习数据集中的模式。</li>
</ul></li>
<li><strong>预测过程</strong>
<ul>
<li><strong>分类问题</strong>：随机森林中的每棵树都会对输入样本进行预测，然后通过<strong>投票</strong>机制决定最终的分类结果。即选择预测次数最多的类别作为最终分类。</li>
<li><strong>回归问题</strong>：随机森林中的每棵树都会给出一个预测值，最终的预测结果通过所有树的<strong>平均值</strong>来决定。</li>
</ul></li>
</ol>
<h4 id="可否将rf的基分类模型由决策树改成线性模型或者knn">可否将RF的基分类模型由决策树改成线性模型或者knn？</h4>
<p>随机森林属于bagging类的集成学习方法，主要好处是减小集成后分类器的方差，比基分类器的方差小。所以Bagging所采用的的基分类器最好是本身对样本分布较为敏感（不稳定分类器），这样bagging才能体现效果。而线性分类器和KNN属于较为稳定的分类器，本身方差不大，所以将他们作为基分类器使用bagging不能再原基分类器的基础上获得更好的表现。相反地，可能因为bagging的采样而使得训练中难以收敛从而增大集成分类器的偏差。</p>
<h4 id="优缺点-3">优缺点</h4>
<p><strong>优点</strong></p>
<ol type="1">
<li><strong>高精度</strong>：在多数情况下，随机森林的准确性高于单个决策树，特别是在大数据集或复杂任务上。</li>
<li><strong>抗过拟合能力强</strong>：由于集成了多棵树，随机森林的模型复杂度较低，避免了单棵决策树容易过拟合的问题。</li>
<li><strong>处理高维特征能力强</strong>：随机森林可以处理包含大量特征的数据集，且不需要对特征进行筛选。</li>
<li><strong>处理缺失值和不平衡数据</strong>：随机森林能够处理部分缺失的数据和类别不平衡的问题。</li>
<li><strong>重要特征选择</strong>：通过计算特征的重要性，随机森林可以帮助确定哪些特征对预测最为重要。</li>
</ol>
<p><strong>缺点</strong></p>
<ol type="1">
<li><strong>计算开销大</strong>：构造大量的决策树需要较多的计算资源，尤其是在数据集较大时，训练时间可能较长。</li>
<li><strong>模型解释性较弱</strong>：相比于单棵决策树，随机森林的结构较为复杂，不容易解释单个决策路径。</li>
<li><strong>预测时间较慢</strong>：虽然训练时间较长，但随机森林的预测时间也会因为多棵树的组合而增加，尤其在实时预测系统中表现较为明显。</li>
</ol>
<h3 id="gradient-boosting梯度提升">2.7. Gradient
Boosting（梯度提升）</h3>
<p>Gradient Boosting
是一种<strong>集成学习方法</strong>，通过将多个弱学习器（通常是决策树）串联起来，形成一个强大的预测模型。它逐步改进模型的预测能力，通过每一步的模型修正先前模型中的错误。常见的变种包括XGBoost，LightGBM，CatBoost等。</p>
<h4 id="工作原理">工作原理</h4>
<p>Gradient Boosting
的核心思想是：每个新的模型都尝试减少前一组模型的<strong>残差（误差）</strong>。具体流程如下：
1.
<strong>初始模型</strong>：从简单的模型（如决策树）开始，预测目标变量。
2.
<strong>计算残差</strong>：计算模型的预测值和真实值之间的误差（残差）。
3.
<strong>构建新模型</strong>：新模型拟合前一个模型的残差（目标是修正错误）。新模型用来减少误差而不是直接预测目标变量。
4.
<strong>迭代过程</strong>：重复第2步和第3步，不断加入新的模型来修正前一轮模型的误差。
5.
<strong>加权求和</strong>：最终的预测结果是所有模型加权后的和，通常最后使用的是步长（learning
rate）来控制加权的比例。</p>
<h4 id="算法步骤">算法步骤</h4>
<p>以回归为例，假设我们有训练数据 $ (x_1, y_1), (x_2, y_2), , (x_n, y_n)
$，目标是拟合一个模型 $ F(x) $ 来最小化损失函数 $ L(y, F(x)) $：</p>
<ul>
<li><p><strong>步骤1</strong>：初始化模型 $ F_0(x)
$，使其最小化损失函数（通常为目标值的均值）。</p>
<p><span class="math display">\[
F_0(x) = \arg \min \sum_{i=1}^{n} L(y_i, F(x_i))
\]</span></p></li>
<li><p><strong>步骤2</strong>：对每个迭代步骤 $ m = 1, 2, ..., M
$，执行以下步骤：</p>
<ol type="1">
<li>计算残差 $ r_{im} = - $，即目标函数的梯度。</li>
<li>训练一个新的模型 $ h_m(x) $ 来拟合残差 $ r_{im} $。</li>
<li>更新模型 $ F_{m}(x) = F_{m-1}(x) + h_m(x) $，其中 $ $
是学习率，控制每一步的模型更新步长。</li>
</ol></li>
<li><p><strong>步骤3</strong>：最终模型为 $ F_M(x) = F_0(x) + _{m=1}^{M}
h_m(x) $。</p></li>
</ul>
<p>负梯度方向就是残差拟合的方向，拟合负梯度就是在最小化损失函数，这使得每一轮的弱学习器都朝着减少预测误差的方向优化。</p>
<h4 id="优缺点-4">优缺点</h4>
<p><strong>优点：</strong> -
<strong>强大的预测能力</strong>：通过修正之前模型的残差，最终模型性能通常非常优秀。
-
<strong>处理偏差-方差权衡</strong>：通过调整基学习器的复杂度（如决策树的深度）和学习率，Gradient
Boosting 可以很好地在偏差与方差之间取得平衡。</p>
<p><strong>缺点：</strong> -
<strong>训练时间长</strong>：由于是逐步构建模型，训练时间相对较长。 -
<strong>参数敏感</strong>：模型对超参数（如学习率、树的深度等）比较敏感，通常需要仔细调参。
-
<strong>容易过拟合</strong>：如果基学习器数量过多或者树太深，模型可能会过拟合，需要通过正则化手段（如早停、学习率调整等）来避免。</p>
<h4 id="梯度提升和梯度下降有什么区别和联系">梯度提升和梯度下降有什么区别和联系？</h4>
<p>两者都是在每一轮迭代中，利用损失函数相对于模型的负梯度方向的信息来对当前模型进行更新。梯度下降是一种优化算法，用于找到函数的最小值或最大值。通常应用在单一模型的训练过程中，用于优化模型的参数（如线性回归、神经网络等）。它通过计算损失函数的梯度，逐步调整模型参数，直到损失函数达到局部或全局最小值。梯度提升是一种集成学习方法，通过多个弱学习器（如决策树）的组合来提升预测性能。它逐步构建多个模型，每个模型通过拟合前一个模型的残差（即负梯度），从而改进预测结果。梯度提升算法使用梯度下降的思想来优化整个模型的性能，但其目标不是直接优化模型参数，而是优化模型集成的效果。</p>
<table>
<colgroup>
<col style="width: 14%">
<col style="width: 43%">
<col style="width: 42%">
</colgroup>
<thead>
<tr>
<th>特性</th>
<th>梯度下降（Gradient Descent）-优化算法</th>
<th>梯度提升（Gradient Boosting） - 集成学习方法</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>作用对象</strong></td>
<td>单一模型的参数</td>
<td>集成模型中的多个弱学习器（如决策树）</td>
</tr>
<tr>
<td><strong>目标</strong></td>
<td>优化模型参数，使损失函数最小化</td>
<td>通过弱学习器的逐步组合，减少整体预测误差</td>
</tr>
<tr>
<td><strong>更新方式</strong></td>
<td>逐步更新模型的参数，沿着负梯度方向调整</td>
<td>逐步添加弱学习器，拟合前一轮的残差（负梯度）</td>
</tr>
<tr>
<td><strong>算法流程</strong></td>
<td>计算梯度 -&gt; 更新参数 -&gt; 重复迭代</td>
<td>计算残差（负梯度）-&gt; 训练新模型拟合残差 -&gt; 组合模型</td>
</tr>
<tr>
<td><strong>使用场景</strong></td>
<td>线性回归、神经网络等优化问题</td>
<td>回归、分类等场景下的集成学习方法，如 XGBoost、LightGBM</td>
</tr>
</tbody>
</table>
<h4 id="boosting和bagging的异同">Boosting和Bagging的异同？</h4>
<p>Bagging通过模型集成降低方差，提高弱分类器的性能。</p>
<p>Boosting通过模型集成降低偏差，提高弱分类器的性能。</p>
<table>
<colgroup>
<col style="width: 15%">
<col style="width: 42%">
<col style="width: 42%">
</colgroup>
<thead>
<tr>
<th>特性</th>
<th><strong>Bagging</strong></th>
<th><strong>Boosting</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>工作机制</strong></td>
<td><strong>并行训练</strong>：多个弱学习器<strong>独立</strong>训练，并行执行。</td>
<td><strong>串行训练</strong>：多个弱学习器<strong>顺序</strong>训练，每个模型依赖上一个模型的结果。</td>
</tr>
<tr>
<td><strong>样本处理</strong></td>
<td><strong>有放回随机抽样</strong>：每个弱学习器在一个随机采样的子集上训练。</td>
<td><strong>加权训练</strong>：每个弱学习器在原始训练集上训练，但每个样本有不同的权重。</td>
</tr>
<tr>
<td><strong>目标</strong></td>
<td>通过减少模型的<strong>方差</strong>，提升模型的稳定性和泛化能力。</td>
<td>通过逐步减少<strong>偏差和方差</strong>，提升模型的整体准确性。</td>
</tr>
<tr>
<td><strong>模型关注点</strong></td>
<td>各模型<strong>独立</strong>，无关其他模型的错误。</td>
<td>每个模型<strong>依赖</strong>前一个模型，集中在纠正之前模型的错误。</td>
</tr>
<tr>
<td><strong>弱学习器权重</strong></td>
<td>各个弱学习器权重相同，预测结果通过简单投票（分类）或平均（回归）来合并。</td>
<td>每个弱学习器根据其性能赋予不同权重，表现好的学习器权重大。</td>
</tr>
<tr>
<td><strong>处理偏差/方差</strong></td>
<td><strong>主要减少方差</strong>，通过减少模型对数据噪声的敏感性来提高泛化能力。</td>
<td><strong>同时减少偏差和方差</strong>，通过纠正错误逐步改进模型。</td>
</tr>
<tr>
<td><strong>算法代表</strong></td>
<td><strong>Random Forest</strong> 是 Bagging 的典型算法。</td>
<td><strong>AdaBoost</strong>、<strong>Gradient Boosting</strong> 是
Boosting 的典型算法。</td>
</tr>
<tr>
<td><strong>并行性</strong></td>
<td>支持并行训练，因各模型独立，可在多核或分布式系统上加速。</td>
<td>顺序训练，难以并行化，因为每个学习器依赖于前一个学习器的结果。</td>
</tr>
</tbody>
</table>
<h3 id="k-means">2.8. K-means</h3>
<p><strong>K-means</strong>
是一种常用的<strong>无监督学习算法</strong>，用于<strong>聚类分析</strong>。它试图将数据集划分为
$ K $
个互不重叠的簇（Cluster），每个簇由具有相似特征的数据点组成。K-means
的目标是最小化簇内数据点与簇中心（质心，Centroid）之间的距离，从而使簇内的数据点更加紧密，簇间的数据点差异更大。</p>
<h4 id="k-means-算法的步骤">K-means 算法的步骤</h4>
<ol type="1">
<li><p><strong>确定簇的数量 $ K $</strong>：事先指定 $ K
$，即要将数据集划分成 $ K $ 个簇。</p></li>
<li><p><strong>随机初始化质心</strong>：随机选择 $ K $
个数据点作为初始的质心（Centroid），质心是用于表示每个簇中心的点。</p></li>
<li><p><strong>分配数据点到簇</strong>：将每个数据点分配给距离其最近的质心，形成
$ K $ 个簇。距离通常通过<strong>欧氏距离</strong>计算： <span class="math display">\[
  \text{距离} = \sqrt{(x_1 - \mu_1)^2 + (x_2 - \mu_2)^2 + \cdots + (x_n
- \mu_n)^2}
  \]</span> 其中，$ x_i $ 表示数据点的坐标，$ _i $
表示质心的坐标。</p></li>
<li><p><strong>更新质心</strong>：对每个簇，重新计算该簇所有数据点的平均值，作为该簇的新质心：
<span class="math display">\[
  \mu_j = \frac{1}{|C_j|} \sum_{x \in C_j} x
  \]</span> 其中，$ _j $ 是簇 $ C_j $ 的新质心，$ |C_j| $
是簇中数据点的数量。</p></li>
<li><p><strong>重复分配和更新</strong>：反复执行<strong>分配数据点到簇</strong>和<strong>更新质心</strong>这两个步骤，直到质心不再变化或变化很小，或者达到指定的迭代次数。</p></li>
<li><p><strong>算法结束</strong>：当质心收敛时，K-means
算法结束，最终形成 $ K $ 个簇。</p></li>
</ol>
<p>K-means 的目标是<strong>最小化簇内平方误差和（Sum of Squared Errors,
SSE）</strong>，即每个簇内数据点与其质心的距离平方和。数学形式为： <span class="math display">\[
SSE = \sum_{j=1}^{K} \sum_{x \in C_j} ||x - \mu_j||^2
\]</span> 其中，$ K $ 是簇的数量，$ C_j $ 是第 $ j $ 个簇，$ x $
是簇内的数据点，$ _j $ 是第 $ j $ 个簇的质心。</p>
<h4 id="优缺点-5">优缺点</h4>
<p><strong>优点：</strong></p>
<ol type="1">
<li><p><strong>简单易实现</strong>：K-means
算法的流程清晰明了，容易理解和实现。</p></li>
<li><p><strong>计算效率高</strong>：K-means 的时间复杂度为 $ O(n K d t)
$，其中 $ n $ 是数据点数，$ K $ 是簇的数量，$ d $ 是特征维度，$ t $
是迭代次数。适合大规模数据集的处理。</p></li>
<li><p><strong>适用于凸形簇</strong>：对于形状规则、分布较为均匀的数据，K-means
能很好地分离不同的簇。</p></li>
</ol>
<p><strong>缺点：</strong> 1. <strong>需要预先指定 K
值</strong>：K-means 需要事先确定聚类数 $ K
$，但是在实际应用中，往往无法确定数据集的簇数量。</p>
<ol start="2" type="1">
<li><p><strong>对初始质心敏感</strong>：K-means
的结果依赖于初始质心的选择，可能会陷入局部最优解。为了解决这个问题，可以使用<strong>K-means++</strong>，通过一种巧妙的质心初始化方法来改进初始质心的选择。
kmeans聚类属于启发式方法，不能保证收敛到全局最优，初始中心的选择会直接影响聚类结果。</p></li>
<li><p><strong>只能找到线性可分的簇</strong>：K-means
只能找到形状为圆形或球形的簇，不能很好地处理非凸形的簇。</p></li>
<li><p><strong>对噪声和离群点敏感</strong>：K-means
使用欧氏距离来衡量相似度，容易受到极端数据点（离群点）的影响，导致结果偏差。</p></li>
<li><p><strong>簇大小不平衡问题</strong>： 对于大小相差较大的簇，K-means
可能无法正确聚类，较大的簇可能会掩盖较小的簇。</p></li>
</ol>
<h4 id="k-means-1">K-means++</h4>
<p><strong>K-means++</strong> 是 K-means
算法的一种改进版本，主要针对<strong>初始质心选择</strong>问题。K-means++
的初始化步骤如下： 1. 随机选择一个数据点作为第一个质心。 2.
对于每一个剩下的数据点，计算它与最近质心的距离平方。 3.
按照距离平方的概率，随机选择下一个质心。距离较大的数据点有更大的概率被选为质心。
4. 重复第 2 和第 3 步，直到选出 $ K $ 个质心。</p>
<p>通过这种初始化方法，K-means++ 可以有效避免 K-means
对初始质心的敏感性，减少迭代次数，并提高聚类效果。</p>
<h4 id="常用聚类评估指标">常用聚类评估指标</h4>
<h5 id="内部评估指标">内部评估指标</h5>
<p><strong>1. 轮廓系数（Silhouette Coefficient）</strong></p>
<p><strong>轮廓系数</strong>结合了簇内距离和簇间距离，用来评估每个数据点的聚类效果。其定义为：
<span class="math display">\[
s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
\]</span> 其中： - $ a(i) $：数据点 $ i $
到同簇内其他数据点的平均距离（簇内距离）。 - $ b(i) $：数据点 $ i $
到最近的其他簇的质心的平均距离（簇间距离）。</p>
<p>轮廓系数的取值范围为 <span class="math inline">\([-1, 1]\)</span>： -
$ s(i) $：表示该点聚类效果良好，距离同簇点近，离其他簇远。 - $ s(i)
$：表示该点处于两个簇的边界上。 - $ s(i)
$：表示该点可能被错误分类到其他簇。</p>
<p>通过计算所有数据点的平均轮廓系数来评估整个聚类模型的效果，轮廓系数越大越好。</p>
<p><strong>2. SSE（Sum of Squared Errors，簇内误差平方和）</strong></p>
<p>SSE 是 K-means
等聚类算法中常用的评估指标，表示簇内所有数据点与其质心的距离平方和。公式为：
<span class="math display">\[
SSE = \sum_{j=1}^{K} \sum_{x \in C_j} ||x - \mu_j||^2
\]</span> SSE 越小，表示数据点与质心越接近，聚类效果越好。SSE 随着 $ K $
值的增加通常会减小，因此不能单独依赖 SSE 来选择最优 $ K $。</p>
<p><strong>3. Calinski-Harabasz 指数（方差比准则）</strong></p>
<p><strong>Calinski-Harabasz 指数</strong>衡量簇的分离度和紧密度之比：
<span class="math display">\[
CH = \frac{\text{簇间方差}}{\text{簇内方差}} \times \frac{n - K}{K - 1}.
\]</span> 其中，$ n $ 是数据点总数，$ K $
是簇的数量。簇间方差越大、簇内方差越小，表示聚类效果越好。Calinski-Harabasz
指数越大，聚类效果越好。</p>
<p><strong>4. Davies-Bouldin 指数</strong></p>
<p><strong>Davies-Bouldin
指数</strong>衡量的是簇间相似性和簇内相似性的比值： <span class="math display">\[
DB = \frac{1}{K} \sum_{i=1}^{K} \max_{j \neq i} \left( \frac{\sigma_i +
\sigma_j}{d(\mu_i, \mu_j)} \right)
\]</span> 其中： - $ _i $ 是簇 $ i $ 的簇内数据点与质心的平均距离。 - $
d(_i, _j) $ 是簇 $ i $ 和 $ j $ 质心之间的距离。</p>
<p>Davies-Bouldin
指数越小，表示簇内距离较小且簇间距离较大，聚类效果越好。</p>
<p><strong>5. 轮廓系数图（Elbow Method）</strong></p>
<p>轮廓系数图或肘部法（Elbow Method）是一种用于确定最优 $ K $
值的方法。绘制不同 $ K $ 值对应的 SSE
曲线，曲线通常是先快速下降，然后变得平缓。最优的 $ K $
通常位于曲线的“肘部”位置，即 SSE 开始平缓下降的点。</p>
<h5 id="外部评估指标">外部评估指标</h5>
<p>外部评估指标用于在有真实标签的情况下评估聚类结果的效果。它通过将聚类结果与真实的类别标签进行对比，计算聚类效果的准确性。这类指标适用于有标注的数据集，常见的外部评估指标有：</p>
<p><strong>1. 调整兰德指数（Adjusted Rand Index, ARI）</strong></p>
<p><strong>调整兰德指数</strong>是基于<strong>兰德指数（Rand
Index）</strong>的一种改进，用来衡量聚类结果与真实标签之间的一致性。其计算依据是聚类结果中的点对是否被正确地分配到同一簇或不同簇。</p>
<p><strong>Rand
Index</strong>计算所有点对之间的组合，统计两点是否被正确地分配到同一簇或不同簇：
<span class="math display">\[
  RI = \frac{a + b}{a + b + c + d}
  \]</span> 其中： - $ a $：同属于一个簇，且真实标签也相同的点对数。 - $
b $：属于不同簇，且真实标签也不同的点对数。 - $ c
$：属于同一个簇，但真实标签不同的点对数。 - $ d
$：属于不同簇，但真实标签相同的点对数。</p>
<p>兰德指数的取值范围是<span class="math inline">\([0,1]\)</span>。兰德指数的一个主要问题是，即使聚类结果是随机的，RI
也往往会得到一个较高的值，而不是真正反映聚类效果。</p>
<p>由于 Rand Index
没有考虑随机聚类可能带来的效果，<strong>调整兰德指数（ARI）</strong>引入了随机化校正：
<span class="math display">\[
ARI = \frac{RI - E[RI]}{\max(RI) - E[RI]}
\]</span></p>
<p><strong>2. 互信息（Mutual Information, MI）与归一化互信息（Normalized
Mutual Information, NMI）</strong></p>
<p><strong>互信息（Mutual Information, MI）</strong>
用于衡量聚类结果与真实标签之间的信息共享程度。它基于信息论，反映了一个聚类结果中有多少信息可以解释真实的标签分布。</p>
<p>互信息的公式为： <span class="math display">\[
MI(U, V) = \sum_{i=1}^{|U|} \sum_{j=1}^{|V|} P(U_i, V_j) \log
\frac{P(U_i, V_j)}{P(U_i) P(V_j)}
\]</span> 其中： - $ U $ 是聚类结果的簇分布，$ V $ 是真实标签的分布。 -
$ P(U_i) $ 是聚类簇 $ U_i $ 的概率。 - $ P(V_j) $ 是真实标签 $ V_j $
的概率。 - $ P(U_i, V_j) $ 是数据同时属于簇 $ U_i $ 和真实标签 $ V_j $
的联合概率。</p>
<p>互信息的取值越高，说明聚类结果与真实标签之间的关联性越强。</p>
<p>为了消除样本数量对互信息的影响，可以对 MI
进行归一化，得到<strong>归一化互信息（NMI）</strong>，其定义为： <span class="math display">\[
NMI(U, V) = \frac{MI(U, V)}{\sqrt{H(U) H(V)}}
\]</span> 其中，$ H(U) $ 和 $ H(V) $
分别是聚类结果和真实标签的熵，表示其不确定性。 NMI 的取值范围是 <span class="math inline">\([0, 1]\)</span>，$ 1 $
表示聚类结果与真实标签完全匹配。$ 0 $
表示聚类结果与真实标签没有相关性。</p>
<p><strong>3. 同质性、完整性和 V-measure</strong></p>
<p>这三者是相互关联的聚类评估指标，分别用于衡量聚类结果与真实标签之间的不同特性。</p>
<p><strong>同质性</strong>表示每个簇内部的所有数据点都属于同一个真实类别。若每个聚类的簇仅包含单一类别的数据点，则该聚类是同质的。公式为：
<span class="math display">\[
H = 1 - \frac{H(C|K)}{H(C)}
\]</span> 其中，$ H(C|K) $ 是给定聚类结果 $ K $ 后的真实标签 $ C $
的条件熵。$ H(C) $ 是真实标签 $ C $ 的熵。</p>
<p>同质性越高，表示同簇数据点的真实类别越统一，理想情况下，应该接近
1。</p>
<p><strong>完整性</strong>表示真实类别的所有数据点都被划分到同一个簇中。若每个真实类别的所有数据点都集中在某个簇中，则聚类具有完整性。公式为：
<span class="math display">\[
C = 1 - \frac{H(K|C)}{H(K)}
\]</span> 其中： - $ H(K|C) $ 是给定真实标签 $ C $ 后的聚类结果 $ K $
的条件熵。 - $ H(K) $ 是聚类结果 $ K $ 的熵。</p>
<p>完整性越高，表示聚类结果能更好地包含每个真实类别的数据点。</p>
<p><strong>V-measure</strong>是同质性和完整性的调和平均数，用来综合衡量聚类的整体效果。公式为：
<span class="math display">\[
V = 2 \times \frac{H \times C}{H + C}
\]</span> V-measure 的取值范围是 <span class="math inline">\([0,
1]\)</span>，其含义与同质性和完整性相似，越接近
1，表示聚类效果越好。V-measure
兼顾了同质性和完整性，因此是一个较为平衡的评估指标。</p>
<p><strong>4. 纯度</strong>（Purity）</p>
<p>把每个簇中最多的类作为这个簇所代表的类，然后计算正确分配的类的数量，然后除以
<span class="math inline">\(N\)</span> 。 <span class="math display">\[
  (\Omega, \mathbb{C})=\frac{1}{N} \sum_{k} \max _{j}\left|\omega_{k}
\cap c_{j}\right|
  \]</span> 其中 <span class="math inline">\(\Omega=\left\{\omega_{1},
\omega_{2}, \ldots, \omega_{K}\right\}\)</span> 是聚类结果的集合 <span class="math inline">\(\omega_{k}\)</span>表示第k个聚类的集合；<span class="math inline">\(\mathbb{C}=\left\{c_{1}, c_{2}, \ldots,
c_{J}\right\}\)</span> 是原始分类的集合，<span class="math inline">\(c_j\)</span>表示第j个分类的集合。</p>
<p><img src="/2024/10/08/statistic/pure.png"></p>
<p>purity优点是方便计算，值在0~1之间；缺点：当簇的数量很多的时候，容易达到较高的纯度——特别是，如果每个文档都被分到独立的一个簇中，那么计算得到的纯度就会是1。因此，不能简单用纯度来衡量聚类质量与聚类数量之间的关系。</p>
<h4 id="选择评估指标的依据">选择评估指标的依据</h4>
<ol type="1">
<li><strong>无监督聚类</strong>：如果没有真实标签，推荐使用<strong>轮廓系数</strong>、<strong>Calinski-Harabasz
指数</strong>和<strong>Davies-Bouldin 指数</strong>等内部评估指标。</li>
<li><strong>有监督聚类</strong>：如果有真实标签，可以使用<strong>ARI</strong>、<strong>NMI</strong>、<strong>V-measure</strong>等外部评估指标。</li>
<li><strong>最优簇数量</strong>：使用<strong>肘部法</strong>和<strong>轮廓系数图</strong>来帮助选择最优簇数量
$ K $。</li>
</ol>
<h4 id="常见的聚类算法">常见的聚类算法</h4>
<ul>
<li>基于划分的算法：如
K-means，简单高效，但对簇形状和初始条件敏感。</li>
<li>基于层次的算法：如层次聚类，自上而下或者自下而上。能构建簇的层次结构，但计算复杂度较高。</li>
<li>基于密度的算法：如
DBSCAN，高密度区域找到簇，适合发现任意形状的簇并处理噪声，但对参数敏感。</li>
<li>基于网格的算法：如
STING，适合大规模数据集，速度快，但依赖网格划分方式。</li>
<li>基于模型的算法：如高斯混合模型
GMM，假设数据来自多个高斯分布的混合，每个簇对应一个高斯分布。通过<strong>期望最大化算法（EM算法）</strong>来估计簇的参数和分布。但对模型假设和参数选择敏感。</li>
<li>谱聚类。基于图论，通过构造相似度矩阵并对其进行谱分解，从而将数据映射到低维空间，在低维空间中进行聚类。</li>
</ul>
<h3 id="主成分分析-pca">2.9. 主成分分析 PCA</h3>
<p><strong>主成分分析（PCA, Principal Component Analysis）</strong>
是一种常用的<strong>降维</strong>和<strong>数据分析</strong>技术。它的主要目标是通过线性变换，将原始的高维数据映射到较低维度的空间中，同时尽可能保持数据的<strong>方差</strong>或信息量。这种方法在高维数据集中的应用非常广泛，可以帮助减少特征数量、可视化数据结构，或是去除噪声等。</p>
<p>PCA
的核心思想是通过构建一组新的<strong>正交基向量</strong>，即<strong>主成分（Principal
Components）</strong>，这些主成分是数据集中特征方差最大的方向。在降维的过程中，PCA
会根据数据的方差信息，选取前几个主成分来表示数据，从而达到降维的目的。</p>
<h4 id="pca的步骤">PCA的步骤</h4>
<p>PCA 的计算过程大致可以分为以下几个步骤：</p>
<p><strong>1. 标准化数据。</strong> 在使用 PCA
之前，通常需要将每个特征进行标准化处理，即将数据归一化为均值为 0、方差为
1 的形式。这是因为 PCA
依赖于特征的方差，而不同尺度的特征（如米和千克）会对结果产生不公平的影响。</p>
<p><strong>2. 计算协方差矩阵。</strong> PCA
的核心是对数据进行线性变换，因此需要计算数据的<strong>协方差矩阵</strong>，以了解各特征之间的线性关系。协方差矩阵的元素描述了两个特征间的协方差，即它们的联合变化情况。</p>
<p><strong>3. 计算特征值和特征向量。</strong>
对协方差矩阵进行<strong>特征值分解</strong>，得到特征值和特征向量。特征向量代表主成分的方向，而特征值表示沿着该方向的方差大小。特征值越大，说明主成分捕捉到的方差越多。
<span class="math display">\[
\text{Cov}(X) v = \lambda v
\]</span> 其中，$ v $ 是特征向量，$ $ 是特征值。</p>
<p><strong>4. 选择主成分。</strong>
根据特征值的大小对特征向量排序，选择其中最大的 $ k $
个特征向量作为主成分。这些主成分构成新的低维空间，数据将被投影到这些主成分上，从而实现降维。</p>
<p><strong>5. 将数据投影到主成分空间。</strong>
通过选取的主成分矩阵，将原始数据投影到新空间中。假设我们选择了前 $ k $
个主成分，则数据 $ X $ 被投影后的新数据表示为： <span class="math display">\[
Z = X W,
\]</span> 其中， <span class="math inline">\(W\)</span>
是主成分向量矩阵。</p>
<h4 id="pca的几何解释">PCA的几何解释</h4>
<p>PCA
的几何解释是，它通过找到新的坐标轴（即主成分），使得这些新坐标轴是原始数据的最佳线性组合。在新的坐标系下，数据沿着第一个主成分（最大方差方向）投影最多的方差，第二个主成分与第一个正交，捕捉剩余的最大方差，依此类推。</p>
<ul>
<li><strong>第一主成分</strong>：方差最大的方向。</li>
<li><strong>第二主成分</strong>：与第一主成分正交且方差次大的方向。</li>
<li>以此类推。</li>
</ul>
<h4 id="pca的性质">PCA的性质</h4>
<ul>
<li><strong>正交性</strong>：各主成分之间是相互正交的，即彼此独立不相关。</li>
<li><strong>方差解释率</strong>：每个主成分解释了原始数据的方差总量的某一比例。通过特征值的比率可以衡量主成分的重要性。通常会选择能解释大部分方差的前几个主成分，达到降维的效果。</li>
<li><strong>最大方差方向</strong>：PCA
总是试图在数据中找到方差最大的方向作为新的坐标轴，从而保证保留最多的信息。</li>
</ul>
<h4 id="优缺点-6">优缺点</h4>
<p><strong>优点</strong></p>
<ol type="1">
<li><strong>降维效果好</strong>：可以有效减少数据维度，保留尽可能多的有用信息。</li>
<li><strong>特征解耦</strong>：主成分是线性不相关的，有助于去除多重共线性。</li>
<li><strong>可视化</strong>：将高维数据映射到低维空间，方便进行可视化分析。</li>
</ol>
<p><strong>缺点</strong></p>
<ol type="1">
<li><strong>线性假设</strong>：PCA
假设主成分是数据的线性组合，不能捕捉到非线性结构。</li>
<li><strong>信息损失</strong>：降维过程中可能会丢失部分信息，特别是方差较小的主成分对应的信息。</li>
<li><strong>解释性差</strong>：PCA
转换后的主成分没有原始特征的具体意义，难以解释。</li>
</ol>
<h4 id="线性判别分析和主成分分析有何区别和联系">线性判别分析和主成分分析有何区别和联系？</h4>
<ul>
<li><p>PCA 是无监督的。PCA
忽略类别信息，专注于保持数据的总方差，寻找能捕捉最多信息的方向。选择的是投影后数据方差最大的方向。由于PCA是无监督的，因此假设方差越大，信息量越多，用主成分来表示原始数据可以去除冗余的维度，达到降维。</p></li>
<li><p>LDA 是有监督的。LDA
利用类别标签信息，目标是找到一个投影向量w，使得数据投影后，类间距离最大化，同时类内距离最小化。</p></li>
</ul>
<h1 id="二数理统计和优化">二、数理统计和优化</h1>
<h2 id="常见的分布">1. 常见的分布</h2>
<p>伯努利分布（0-1分布），Beta分布，二项分布，泊松分布，t分布，多项式分布。详见教材
## 2. 参数估计有哪些方法？</p>
<p><strong>极大似然估计MLE</strong></p>
<p>在统计学中，常常使用极大似然估计法来估计参数。即找到一组参数，使得在这组参数下，我们数据的似然度（概率）最大。<strong>(极大似然估计：就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值，即‘模型已定，参数未知’</strong>)</p>
<p><strong>极大似然估计的前提一定是要假设数据总体的分布，如果不知道数据分布，是无法使用极大似然估计的</strong></p>
<p>求极大似然估计的步骤</p>
<p>（1）写出似然函数；</p>
<p>（2）对似然函数取对数，并整理；</p>
<p>（3）求导数，令导数为 0，得到似然方程；</p>
<p>（4）解似然方程，得到的参数。</p>
<p><strong>最大后验概率估计MAP</strong></p>
<p><strong>极大似然估计中采样需满足一个重要的假设，就是所有的采样都是独立同分布的。</strong></p>
<p>那么我们就知道了极大似然估计的核心关键就是对于一些情况，样本太多，无法得出分布的参数值，可以采样小样本后，利用极大似然估计获取假设中分布的参数。</p>
<p>极大似然估计就是经验风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计。</p>
<p>最大后验概率是计算给定数据条件下模型的条件概率，即后验概率。使用模型的先验分布是贝叶斯学习的特点。</p>
<p><strong>期望极大化EM</strong></p>
<p>EM
算法解决这个的思路是使用启发式的迭代方法，既然我们无法直接求出模型分布参数，那么我们可以先猜想隐含参数（EM
算法的 E
步），接着基于观察数据和猜测的隐含参数一起来极大化对数似然，求解我们的模型参数（EM算法的M步)。由于我们之前的隐含参数是猜测的，所以此时得到的模型参数一般还不是我们想要的结果。我们基于当前得到的模型参数，继续猜测隐含参数（EM算法的
E
步），然后继续极大化对数似然，求解我们的模型参数（EM算法的M步)。以此类推，不断的迭代下去，直到模型分布参数基本无变化，算法收敛，找到合适的模型参数。</p>
<p>一个最直观了解 EM 算法思路的是 K-Means 算法。在 K-Means
聚类时，每个聚类簇的质心是隐含数据。我们会假设 K 个初始化质心，即 EM
算法的 E
步；然后计算得到每个样本最近的质心，并把样本聚类到最近的这个质心，即 EM
算法的 M 步。重复这个 E 步和 M 步，直到质心不再变化为止，这样就完成了
K-Means 聚类。</p>
<p>EM算法和极大似然估计的前提是一样的，都要假设数据总体的分布，如果不知道数据分布，是无法使用EM算法的。</p>
<p>EM算法是通过不断求解下界的极大化逼近求解对数似然函数极大化的算法</p>
<h2 id="频率学派和贝叶斯学派什么区别">3.
频率学派和贝叶斯学派什么区别？</h2>
<p><strong>频率学派</strong></p>
<p>频率学派是上帝视角，认为频率是固定的，事件在多次重复实验中趋于一个稳定的值p，那么这个值就是该事件的概率。</p>
<p>他们认为模型参数是个定值，希望通过类似解方程组的方式从数据中求得该未知数。这就是频率学派使用的参数估计方法-<strong>极大似然估计（MLE）</strong>，这种方法往往在<u>大数据量的情况</u>下可以很好的还原模型的真实情况。</p>
<p><strong>贝叶斯派</strong></p>
<p>他们认为世界是不确定的，因获取的信息不同而异。假设对世界先有一个预先的估计，然后通过获取的信息来不断调整之前的预估计。他们认为模型参数源自某种潜在分布，希望从数据中推知该分布。对于数据的观测方式不同或者假设不同，那么推知的该参数也会因此而存在差异。这就是贝叶斯派视角下用来估计参数的常用方法-<strong>最大后验概率估计（MAP）</strong></p>
<p>这种方法在先验假设比较靠谱的情况下效果显著，随着数据量的增加，先验假设对于模型参数的主导作用会逐渐削弱，相反真实的数据样例会大大占据有利地位。极端情况下，比如把先验假设去掉，或者假设先验满足均匀分布的话，那她和极大似然估计就如出一辙了。</p>
<h2 id="大数定理和中心极限定理">4. 大数定理和中心极限定理</h2>
<h2 id="假设检验">5. 假设检验</h2>
<h2 id="最优化问题">6. 最优化问题</h2>
<p>详见教材 &lt;&lt;数据科学优化方法&gt;&gt;
孙怡帆，中国人民大学出版社，2024.</p>
<h2 id="优化器总结">7. 优化器总结</h2>
<h4 id="梯度下降-gradient-descent-gd">1. 梯度下降 (Gradient Descent,
GD)</h4>
<p>梯度下降是一种基于梯度信息来更新参数的优化方法。假设损失函数为 <span class="math inline">\(J(\theta)\)</span>，对于每次迭代，更新权重的方式为：
<span class="math display">\[
\theta_{t+1} = \theta_t - \eta \nabla J(\theta_t),
\]</span> 其中，$ _t $ 是第 $ t $ 次迭代时的参数，$ $ 是学习率，<span class="math inline">\(\nabla J(\theta_t)\)</span>
是损失函数对参数的梯度。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：在凸问题中，只要学习率 $$
选得合适，梯度下降可以收敛到全局最优解。但对于<strong>非凸问题</strong>，它可能会收敛到局部最优解。</li>
<li><strong>优点</strong>：简单且易于实现。</li>
<li><strong>缺点</strong>：对于批量梯度下降，计算梯度会涉及整个训练集，计算成本高。</li>
</ul>
<h4 id="随机梯度下降-stochastic-gradient-descent-sgd">2. 随机梯度下降
(Stochastic Gradient Descent, SGD)</h4>
<p>SGD
是梯度下降的一个变种，它在每次更新时仅使用一个样本的梯度，而不是整个训练集的梯度：
<span class="math display">\[
\theta_{t+1} = \theta_t - \eta \nabla J(\theta_t; x_i, y_i)
\]</span> 其中 $ (x_i, y_i) $ 是随机选择的训练样本。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：在凸问题中，SGD
在学习率逐渐衰减的情况下可以收敛到全局最优值，但波动较大。在非凸问题中，SGD
可能会陷入局部最优，但随机性有时会帮助跳出局部最优。</li>
<li><strong>优点</strong>：计算开销低，每次迭代只计算一个样本的梯度。</li>
<li><strong>缺点</strong>：更新频繁，带有随机性，会造成损失函数在收敛过程中严重震荡。收敛较慢，更新过程存在噪声。</li>
</ul>
<h4 id="小批量梯度下降法mini-batch-gradient-descent-mbgd">3.
<strong>小批量梯度下降法（Mini-batch Gradient Descent,
MBGD）</strong></h4>
<p>小批量梯度下降是批量梯度下降和随机梯度下降的折中，使用一部分数据计算梯度，然后更新参数。这种方式可以降低参数更新时的方差，使得收敛更加稳定。但是对于非凸问题，依旧无法保证得到全局最优解。</p>
<p><strong>在梯度下降公式中，可以从两个角度进行改进。一是自适应选择学习率；二是梯度（动量）。</strong></p>
<p>首先，在修正梯度方面，主要有momentum动量法和nesterov 加速法。</p>
<h4 id="动量梯度下降-momentum-gd-和-nagnesterov-accelerated-gradient">4.
<strong>动量梯度下降 (Momentum GD) 和 NAG（Nesterov accelerated
gradient）</strong></h4>
<p>动量法：参数更新时在一定程度上保留之前更新的方向，同时又利用当前batch的梯度微调最终的更新方向，简言之就是通过积累之前的动量来
(previous_sum_of_gradient)
加速当前的梯度，可能更加稳定、更有利于跳出局部最优。</p>
<p>动量法的更新公式为： <span class="math display">\[
v_{t+1} = \gamma v_t + \eta \nabla J(\theta_t), \\
\theta_{t+1} = \theta_t - v_{t+1}
\]</span> 其中， $ $ 是动量因子（通常取值接近于 1），$ v_t $
是动量向量。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：在凸问题中，动量法可以比标准梯度下降更快收敛。在非凸问题中，它同样可能收敛到局部最优，但动量项可能有助于避免一些局部最优点。</li>
<li><strong>优点</strong>：加快收敛速度，减少震荡。</li>
<li><strong>缺点</strong>：动量项的选取较为敏感。</li>
</ul>
<p>NAG 进一步引入了nesterov
动量，先在计算梯度更新前做一个矫正，更新公式为： <span class="math display">\[
v_{t+1} = \gamma v_t + \eta \nabla J(\theta_t - \gamma v_t), \\
\theta_{t+1} = \theta_t - v_{t+1}.
\]</span></p>
<p>传统的优化算法要么将学习率设置为常数要么根据训练次数调节学习率。往往忽视了学习率其他变化的可能性。然而，学习率对模型的性能有着显著的影响，因此需要采取一些策略来想办法更新学习率，从而提高训练速度。如果学习率太小，则梯度很大的参数会有一个很慢的收敛速度；
如果学习率太大，则已经优化得差不多的参数可能会出现不稳定的情况。</p>
<p><strong>自适应学习率算法主要有：AdaGrad算法，RMSProp算法，Adam算法以及AdaDelta算法等。</strong></p>
<h4 id="adagrad-adaptive-gradient-algorithm">5. <strong>AdaGrad
(Adaptive Gradient Algorithm)</strong></h4>
<p>AdaGrad
根据历史梯度信息来调整学习率，能够自动缩放每个参数反比于其所有梯度历史总和的平方根。更新公式为：
<span class="math display">\[
\theta_{t+1, i} = \theta_{t,i}- \frac{\eta}{\sqrt{G_{t,ii} + \epsilon}}
g_{t,i}.
\]</span> 其中，<span class="math inline">\(g_{t,i}\)</span> 为 <span class="math inline">\(t\)</span>时刻，参数 <span class="math inline">\(\theta_{t,i}\)</span> 的梯度。<span class="math inline">\(G_t\)</span> 是对角矩阵，<span class="math inline">\((i,i)\)</span>元素为到第$ t $次迭代为止，参数
<span class="math inline">\(\theta_{t,i}\)</span> 的累积梯度平方和。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：AdaGrad
在凸问题中可以收敛到最优解，但在非凸问题中，学习率可能会变得非常小，导致无法继续有效更新。</li>
<li><strong>优点</strong>：具有损失函数最大梯度的参数相应地有个快速下降的学习率，而具有小梯度的参数在学习率上有相对较小的下降。</li>
<li><strong>缺点</strong>：中后期，分母上梯度累加的平方和会越来越大，学习率会逐渐减小到接近
0，使得训练提前结束，无法学习。</li>
</ul>
<h4 id="rmsprop-root-mean-square-propagation">6. <strong>RMSProp (Root
Mean Square Propagation)</strong></h4>
<p>RMSProp
通过调整每个参数的学习率来解决梯度震荡问题。其核心思想是对每个参数的梯度平方值进行指数加权平均，并使用这个平均值来调整每个参数的更新步长：
<span class="math display">\[
E[g^2]_t = \beta E[g^2]_{t-1} + (1 - \beta) g_t^2, \qquad
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t
\]</span> 其中，$ g_t $ 是梯度，$ E[g^2]_t $ 是梯度平方的移动平均，<span class="math inline">\(\beta\)</span>是衰减因子，<span class="math inline">\(\epsilon\)</span> 是防止除零的小量。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：RMSProp
能够在一定程度上控制学习率的大小，使得在深度学习中的表现较好。在非凸问题中，它能够有较好的局部收敛表现。</li>
<li><strong>优点</strong>：能够动态调整学习率，对稀疏数据有较好的处理能力。</li>
<li><strong>缺点</strong>：可能会在学习率过小的情况下导致收敛变慢。</li>
</ul>
<h4 id="adadelta">7. <strong>Adadelta</strong></h4>
<p>Adadelta 是 <strong>AdaGrad</strong> 的改进版，旨在解决 AdaGrad
中学习率逐渐衰减至过小的问题。</p>
<p>Adadelta
的主要思想是通过使用<strong>指数加权移动平均</strong>（Exponential
Moving Average, EMA）来代替 AdaGrad
中的累积平方梯度和累计学习率。通过这种方式，它能够更稳定地调整学习率，同时避免学习率在训练过程中过度减小。</p>
<p>Adadelta
不仅对梯度平方进行加权平均，还对参数更新的量进行加权平均，因此它不依赖于预设的全局学习率。</p>
<p>(1). <strong>梯度平方的指数加权移动平均</strong>： <span class="math display">\[
   E[g^2]_t = \rho E[g^2]_{t-1} + (1 - \rho) g_t^2
   \]</span></p>
<p>其中，$ g_t $ 是在第 $ t $ 次迭代中计算的梯度，<span class="math inline">\(\rho\)</span> 是衰减率（通常取值在 0.9 左右），$
E[g^2]_t $ 是梯度平方的移动平均值。</p>
<p>(2). <strong>参数更新的移动平均</strong>： <span class="math display">\[
   \Delta \theta_t = - \frac{\sqrt{E[\Delta \theta^2]_{t-1} +
\epsilon}}{\sqrt{E[g^2]_t + \epsilon}} g_t
   \]</span> 其中，$ E[^2]_{t-1} $ 是之前参数更新量的移动平均值，$ $
是一个用于防止除零的小量（通常取 $ 10^{-6} $）。</p>
<p>(3). <strong>更新移动平均</strong>： <span class="math display">\[
   E[\Delta \theta^2]_t = \rho E[\Delta \theta^2]_{t-1} + (1 - \rho)
(\Delta \theta_t)^2
  \]</span></p>
<p>(4). <strong>参数更新</strong>： <span class="math display">\[
   \theta_{t+1} = \theta_t + \Delta \theta_t
  \]</span></p>
<ul>
<li><p><strong>是否收敛到最优值</strong>：在凸优化问题中，Adadelta
可以收敛到全局最优解。在非凸问题中，它的表现依然较好，能够避免陷入局部最优点。不过，类似于其他基于梯度的优化方法，Adadelta
在非凸问题中并不能保证一定收敛到全局最优解。</p></li>
<li><p><strong>AdaGrad</strong>
使用的是累积平方梯度求和来更新学习率，导致学习率在训练过程中逐渐趋近于零，尤其是在处理长时间训练或大量数据时。这会使得
AdaGrad 训练过程后期的学习率非常小，进而导致参数几乎无法更新。</p></li>
<li><p><strong>Adadelta</strong> 通过引入指数加权移动平均（EMA）代替了
AdaGrad 中的累积平方梯度求和，避免了学习率过早衰减的现象。同时，Adadelta
不再需要预设学习率，因为它会自动调整学习率。</p></li>
<li><p><strong>依赖于衰减率的选择</strong>：虽然不需要手动设置学习率，但衰减率
$ $
的选择依然是影响模型收敛速度的一个关键因素。对于不同的数据集和任务，可能需要针对衰减率进行调优。</p></li>
</ul>
<h4 id="adam-adaptive-moment-estimation">8. <strong>Adam (Adaptive
Moment Estimation)</strong></h4>
<p>Adam 是 RMSProp
和动量法的结合，通过同时计算梯度的一阶和二阶矩的指数加权平均来调整学习率：
<span class="math display">\[
m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t, \\
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2.
\]</span> <span class="math display">\[
\hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1 -
\beta_2^t}.
\]</span> <span class="math display">\[
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon}
\hat{m}_t
\]</span> 其中，$ m_t $ 和 $ v_t $ 分别是梯度的一阶和二阶矩，$ _1 $ 和 $
_2 $ 是超参数。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：Adam
在许多实际问题中表现优越，但在某些情况下，Adam
可能会收敛到次优解。理论上，它能收敛到局部最优，但是否能达到全局最优取决于问题的性质。</li>
<li><strong>优点</strong>：能够动态调整学习率，对稀疏数据和噪声鲁棒性强。</li>
<li><strong>缺点</strong>：较为复杂，依赖超参数的设置。</li>
</ul>
<h4 id="adamw-adaptive-moment-estimation">9. <strong>AdamW (Adaptive
Moment Estimation)</strong></h4>
<p><strong>AdamW</strong> 是 <strong>Adam</strong>
优化算法的改进版本，它的主要改进是在 Adam
的基础上引入了<strong>权重衰减（Weight
Decay）</strong>的正确实现。这种权重衰减是通过将 L2
正则化直接应用于<strong>参数更新公式</strong>，而不是像 Adam
那样对梯度进行修正。这种改进旨在提高模型的泛化能力，尤其是避免深度学习模型中过拟合的问题。</p>
<ul>
<li><p><strong>Adam 中的错误正则化实现</strong>：在原版的 Adam
中，权重衰减实际上是通过将梯度中的 L2 惩罚项添加到更新公式中。这种做法在
Adam 中并不完全等同于对参数的惩罚，因为 Adam
依赖于动量和梯度的调整，它使得实际的正则化效果被稀释或扭曲，导致权重衰减效果不理想。</p></li>
<li><p><strong>AdamW 的提出</strong>：为了解决这个问题，AdamW
提出了更正的权重衰减实现。AdamW
将权重衰减项直接应用到参数本身的更新步骤，而不是施加在梯度上。这种做法能够更加有效地抑制模型的过拟合，提高泛化能力。</p></li>
</ul>
<p>AdamW 基本上继承了 Adam
的大部分更新过程，但在参数更新时引入了独立的权重衰减项。</p>
<p>(1). <strong>梯度的移动平均</strong>（一阶矩估计）： <span class="math display">\[
   m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
   \]</span> 其中，$g_t $是在第 $ t $ 次迭代中计算的梯度，$ m_t <span class="math inline">\(是梯度的移动平均，\)</span>_1 $
是动量衰减因子（通常取 0.9）。</p>
<p>(2). <strong>梯度平方的移动平均</strong>（二阶矩估计）： <span class="math display">\[
   v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
  \]</span> 其中，$ v_t $ 是梯度平方的移动平均，$ _2 $
是衰减因子（通常取 0.999）。</p>
<p>(3). <strong>偏差修正</strong>：
为了消除初期时矩估计的偏差，需要进行偏差校正： <span class="math display">\[
   \hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1
- \beta_2^t}
   \]</span></p>
<p>(4). <strong>参数更新</strong>（AdamW 核心改进部分）： AdamW
的更新步骤不仅包含 Adam
的参数更新公式，还直接在参数更新时引入了权重衰减项： <span class="math display">\[
   \theta_{t+1} = \theta_t - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} +
\epsilon} - \eta \lambda \theta_t
   \]</span> 其中，$ $ 是权重衰减系数（即 L2 正则化系数），$ $
是学习率。</p>
<p>AdamW 的关键在于第二个项 $_t
$，它直接将权重衰减施加在参数更新上，而不是施加在梯度上。这种方式与传统
SGD 中的权重衰减更一致。</p>
<ul>
<li><strong>Adam</strong>：权重衰减通过 L2
正则化实现，并作用在梯度上。这种实现可能会导致正则化效果受到 Adam
的梯度调整机制的干扰，导致模型参数更新不充分，特别是在学习率较小时。</li>
<li><strong>AdamW</strong>：权重衰减直接作用于参数本身，即在每次参数更新时独立加入一个基于参数的衰减项。这样可以保证权重衰减的效果更加直接和有效，避免了
Adam
对梯度的干扰。此外，这种权重衰减更加显式地对模型参数产生作用，从而能够更好地抑制模型过拟合，提高泛化性能。</li>
<li><strong>需要调优的超参数增加</strong>：相比 Adam，AdamW
多了一个权重衰减系数 $ $，这增加了模型调优的复杂性。</li>
</ul>
<h1 id="三-llm-and-vlm">三、 LLM and VLM</h1>
<h2 id="大模型常用微调方法lora和ptuning的原理">1.
大模型常用微调方法LORA和Ptuning的原理</h2>
<ul>
<li><p>LORA: Low-Rank Adaptation.
核心是在大型语言模型上对指定参数增加额外的低秩矩阵，也就是在原始pre-trained
LM
旁边增加一个旁路，做一个降维再升维的操作。假设模型中有一个需要更新的权重矩阵
<span class="math inline">\(W \in \mathbb{R}^{d \times
k}\)</span>，LORA的思想是修改为： <span class="math inline">\(W' = W
+ \delta W\)</span>，其中 <span class="math inline">\(\Delta W = A
\times B\)</span>, <span class="math inline">\(A \in \mathbb{R}^{d
\times r}\)</span>, <span class="math inline">\(B \in \mathbb{R}^{r
\times k}\)</span>, 且 <span class="math inline">\(r &lt;&lt; \min\{d,
k\}\)</span>。在模型训练过程中，固定PLM的参数，只训练降维矩阵 <span class="math inline">\(A\)</span> 与升维矩阵 <span class="math inline">\(B\)</span>。</p></li>
<li><p>Ptuning: Prompt Tuning.</p></li>
</ul>
<h2 id="diffusion-models-and-stable-diffusion">2. Diffusion models and
Stable diffusion</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#prog-distll">What
are Diffusion Models?</a></li>
<li><h2 id="diffusion-models-for-video-generation"><a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2024-04-12-diffusion-video/">Diffusion
Models for Video Generation</a></h2></li>
</ul>
<h2 id="llm的幻觉的问题">3. LLM的幻觉的问题</h2>
<p>Great thanks to this blog: <a target="_blank" rel="noopener" href="https://aman.ai/primers/ai/hallucination/">NLP • Hallucination
Mitigation</a></p>
<p>AI文本生成中的<strong>幻觉</strong>现象指的是模型生成的文本虽然在语法上可能是正确的，并且看起来合理，但与输入内容并不一致，甚至可能是事实错误的。这种问题在像GPT-3这样的系统中尤为常见，生成的细节可能会偏离甚至与输入内容相矛盾。</p>
<h3 id="幻觉产生的原因">幻觉产生的原因</h3>
<p>造成幻觉的原因可以归结为以下几个方面：</p>
<p><strong>1.
训练数据不足</strong>：如果模型在训练中没有接触到多样化的数据，它可能无法准确地建立输入与合适输出之间的关联，从而导致幻觉内容的产生。</p>
<p><strong>2.
模型过拟合</strong>：过拟合于训练数据会导致模型生成的输出过于依赖训练集，但在面对新的或不同的输入时与实际不符。</p>
<p><strong>3.
监督不足</strong>：如果没有充分的指导，模型可能会过度依赖其内部逻辑，导致生成的内容出现“幻觉”。</p>
<p><strong>4.
知识截止</strong>：像ChatGPT这样的语言模型有知识截止日期，因此对于截止日期之后的信息一无所知。在这种情况下，它可能在不知情的情况下提供过时或不再相关的回答。</p>
<h3 id="如何解决幻觉">如何解决幻觉</h3>
<h4 id="训练阶段">训练阶段</h4>
<p><strong>Reinforcement Learning from Human Feedback
(RLHF)</strong>。使用RLHF来减少幻觉的核心思想是让人类提供有关模型响应准确性和相关性的反馈。通过将这些反馈融入训练过程，模型可以逐步学习区分准确信息和不准确信息，从而降低产生幻觉的可能性。此外，RLHF还能帮助模型理解其输出带来的影响，进而提高生成相关且符合事实的回应能力。</p>
<h4 id="训练之后">训练之后</h4>
<p>在对 LLM 进行训练之后，可以使用 <strong>Prompting</strong>
减轻幻觉。</p>
<p><strong>1. Retrieval Augmented Generation（RAG）</strong>。
通过在生成过程中提供额外的上下文信息，有助于消除大语言模型中的幻觉问题。幻觉现象通常发生在LLM基于训练数据中的模式生成响应，而不是依赖真实知识时，尤其当模型缺乏特定领域的信息或难以识别其知识边界时更容易出现。RAG通过将外部知识源整合到生成过程中来解决这一问题。它使LLM能够在生成响应时访问来自外部数据库的最新或特定上下文的数据。这种方法为模型注入了更多的上下文信息，帮助其更好地理解主题，降低幻觉出现的概率。例如，在设计用于提供汽车信息的聊天机器人中，RAG可以从外部数据库中检索产品的具体细节和上下文信息，以补充用户的输入。这样，LLM可以接收到更全面和详细的提示，从而生成更准确和相关的响应。</p>
<p><strong>2. Contextual
Prompting</strong>。旨在通过为模型提供明确的上下文或背景信息来改善其生成的输出。这种方法通过在提示（prompt）中包含相关的上下文信息，帮助模型更好地理解任务，并生成更准确、相关性更高的回答或内容。在给大语言模型（LLM）提供问题和上下文时，附加的上下文段落通常是来自维基百科文章、书籍章节等的摘要。这些上下文片段通过在句末插入唯一标识符进行标记，例如“(source
1234)”或“(source 4567)”。例如：</p>
<ul>
<li><p>“巴黎是法国的首都。(source 1234)”</p></li>
<li><p>“法国位于西欧。(source 4567)”</p>
<p>这些来源标签是与原始上下文片段中的特定句子相对应的唯一编号。具体来说，Contextual
Prompting
涉及将一段上下文或背景知识与问题或任务一起输入模型。这段上下文可以是来自外部知识库的文本、前面对话中的信息、或任何与当前任务相关的数据。上下文为模型提供了额外的信息，使其能够更好地理解用户的意图，并在生成内容时参考这些背景知识。在使用这些带标签的上下文提示LLM时，研究方法还会在问题后附加指令，例如“提供细节并在答案中包含来源。”
通过这种方式，LLM在生成响应时被引导引用这些标记的来源。这些标签为验证LLM的响应是否基于提供的上下文信息提供了参考。如果响应中包含匹配的来源标签，就表明LLM依赖于提供的上下文，而不是凭空生成（幻觉）的内容。</p></li>
</ul>
<p><strong>3. Chain of Verification
（CoVe）</strong>。CoVe方法让大语言模型（LLM）在生成初始回答后，经过多个步骤来提升准确性：(1).
生成初始回答，可能包含不准确或幻觉。(2).
规划验证问题——模型生成一系列验证问题以自我查证。(3).
执行验证——模型独立回答这些验证问题 (Verification questions are often
answered more accurately than facts stated in long passages)。(4).
基于验证结果修正初始回答，生成最终答案。 <img src="/2024/10/08/statistic/cove.png"></p>
<h2 id="llm-alignment">4. LLM Alignment</h2>
<p>Great thanks to this blog: <a target="_blank" rel="noopener" href="https://aman.ai/primers/ai/llm-alignment/">LLM Alignment</a></p>
<h3 id="overview">Overview</h3>
<ul>
<li>2017 年，OpenAI 在其论文 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03741">Deep reinforcement learning from
human preferences</a> 中提出了一种开创性的机器学习方法，称为
"从人类反馈出发的强化学习"
(RLHF)，特别关注人类偏好。这一创新概念自此激发了该领域的进一步研究和发展。</li>
<li>RLHF 概念:
使用一个预先训练好的语言模型，由人类评估员对其输出进行排序。然后，这种排序会让模型对某些类型的回答产生偏好，从而产生更可靠、更安全的输出。</li>
<li>RLHF
可以有效利用人类反馈来提高语言模型的性能。它将强化学习算法的优势与对人类输入的细微理解相结合，促进了模型的持续学习和改进。结合人类反馈，RLHF
不仅能提高模型的自然语言理解和生成能力，还能提高其在文本分类或翻译等特定任务中的效率。此外，RLHF
在解决语言模型中的偏差方面也发挥着至关重要的作用。通过允许人工输入来指导和纠正模型的语言使用，它可以促进更加公平和包容的交流。不过，在这一过程中，必须注意人为因素可能导致的偏差。</li>
</ul>
<h3 id="reinforcement-learning-强化学习基础概念">Reinforcement Learning
强化学习基础概念</h3>
<p><img src="/2024/10/08/statistic/rl.png"></p>
<p>如图所示，agent 采取一定的 action，对于当前的
action，环境会反馈其状态 state 以及 给出
reward。其中，reward是要优化的目标，state是环境当前的状态，policy用于根据state选择
action.</p>
<h3 id="reinforcement-learning-from-human-feedback-rlhf">Reinforcement
Learning from Human Feedback (RLHF)</h3>
<p>LLM
的最初目标是准确地预测下一个token。但是，这种方式无法保证输出的结果是有用、无害且诚实的，有可能产生不符合人类道德或安全标准的内容。为解决这一问题，需要有一种方式来引导模型输出符合人类价值观的结果。</p>
<p><img src="/2024/10/08/statistic/rlhf.png"></p>
<p>图中给出了使用RLHF训练LM的三个步骤，具体来说，</p>
<ol type="1">
<li><p>Collect Demonstration Data, and Train a Supervised Policy.
首先，从 prompts 中选择一个
prompt；然后人类标注者给出希望得到的输出；最后这些经过标注后的数据用于对LM进行
supervised fine-tune.</p></li>
<li><p>Collect Comparison Data, and Train a Reward Model.
首先，选取一个prompt，模型给出几个可能的输出结果；标注者根据有用性、准确性等准则对结果进行从好到差的排序；这些排序后的数据用来训练一个
reward model. Reward model用来评估模型输出结果的质量。</p></li>
<li><p>Optimize a Policy Against the Reward Model Using Reinforcement
Learning. 产生新的prompt, 基于当前的policy, model 得到新的输出 response;
Reward model 评估 response，然后得到 reward；基于得到的 reward
以及一些强化学习算法，比如PPO，对 policy 进行更新。调整 policy
是为了增加未来产生 higher-reward outputs 的可能性。</p></li>
</ol>
<p>Chip Huyen provides a zoomed out view of how the overall process
works in her flowchart below:</p>
<p><img src="/2024/10/08/statistic/rlhf1.jpeg"></p>
<h4 id="reward-model">REWARD MODEL</h4>
<p>Reward model 的主要功能是评估给定的输入（如文本序列）并产生scalar
reward。这种reward 量化了输出与人类偏好或期望行为的一致程度。</p>
<p><img src="/2024/10/08/statistic/rlhf2.png"></p>
<p>Reward 模型的结构包括 - LM 分类器：一个二元分类器微调的
LLM，可对哪种反应更符合人类偏好进行评分。 - value
networks：一个回归模型，根据输入预测人类偏好评分。 -
评论生成器：经过训练的
LM，可生成评价性评论，解释哪种回答更好以及原因。该评论可用于指令调整。</p>
<h4 id="optimizing-the-policy">Optimizing the Policy</h4>
<p><strong>策略（policy）</strong>：在强化学习中，策略是一组规则或决策机制，指导智能体（agent）根据它所处的环境状态或观察结果来选择行动。也就是说，策略定义了智能体如何在不同的情境下采取什么样的行为。</p>
<p><strong>PPO（Proximal Policy
Optimization，邻近策略优化）</strong>：是一种常用的强化学习算法。在PPO中，策略是通过反复迭代来优化的。其目标是最大化奖励，即让智能体的行为逐步改善，获得更高的回报。
但是，PPO会确保策略的更新不会发生剧烈变化。这是通过引入一种约束，使更新后的策略保持与之前的策略相似性，以避免不稳定性或训练失败的情况。</p>
<p><strong>DPO（Direct Preference
Optimization，直接偏好优化）</strong>：是一种不同的策略优化方法。在DPO中，策略直接基于人类偏好进行优化。具体来说，它通过二元交叉熵损失函数（binary
cross entropy
loss），增加模型生成的优选输出的相对对数概率，而减少非优选输出的概率。这种方法直接根据人类的反馈进行优化，旨在使模型生成更符合人类期望的输出。
与此同时，DPO也通过KL散度约束来保持平衡，防止策略发生过大的偏离。</p>
<h4 id="training-llama-2">Training Llama 2</h4>
<p><img src="/2024/10/08/statistic/llama.jpeg"></p>
<p>以下是Llama 2 的主要训练阶段的介绍：</p>
<ol type="1">
<li><strong>预训练阶段</strong>（Pretraining）：
<ul>
<li>在最初的预训练阶段，Llama 2
使用大量数据通过<strong>自监督学习</strong>进行训练。这一阶段让模型学习语言模式和上下文的基本结构，使其能够理解语言的基本规则和含义。</li>
<li>自监督学习的方式通常是通过预测文本中隐藏的部分（如下一句话或遮盖的单词）来训练模型，帮助它积累广泛的语言知识。</li>
</ul></li>
<li><strong>有监督微调阶段</strong>（Supervised Fine-Tuning）：
<ul>
<li>在此阶段，模型进一步通过<strong>指令数据</strong>进行有监督微调。具体来说，模型会根据特定的指令进行训练，学习如何对不同的提示做出合适的响应。</li>
<li>这个过程使模型能够在实际应用中根据明确的要求或任务生成准确、相关的回答。</li>
</ul></li>
<li><strong>奖励模型创建（RLHF步骤1）</strong>（Reward Models Creation -
RLHF Step 1）：
<ul>
<li>为了进一步优化模型输出的质量，Llama 2
创建了两个<strong>奖励模型</strong>，一个针对<strong>帮助性（helpfulness）</strong>，另一个针对<strong>安全性（safety）</strong>。</li>
<li>这些奖励模型通过<strong>人类偏好数据</strong>训练，预测在两种不同的输出中哪一个更符合人类的判断。此阶段基于二元比较，模型通过评估每对输出的优劣来学习。</li>
</ul></li>
<li><strong>边际损失与排名</strong>（Margin Loss and Ranking）：
<ul>
<li>Llama 2
使用二元比较数据集来优化排名。在每次比较中，标注者只需要选择两种响应中的一个，并通过<strong>边际标签</strong>来表示偏好的强度。这种边际标签可以用于进一步计算<strong>排名损失</strong>，提高模型对不同偏好的敏感性。</li>
</ul></li>
<li><strong>拒绝采样与PPO对齐（RLHF步骤2）</strong>（Rejection Sampling
and PPO - RLHF Step 2）：
<ul>
<li>在最后一步，Llama 2
使用<strong>拒绝采样</strong>和<strong>邻近策略优化（PPO）</strong>来进一步优化模型。</li>
<li>拒绝采样是指从模型生成的多个输出中，选择<strong>奖励最高</strong>的输出用于更新梯度，从而增强模型生成高质量输出的能力。</li>
<li>之后通过PPO算法对模型进行进一步对齐，使其生成的回答更加安全且有帮助，同时确保优化过程中策略更新的稳定性。</li>
</ul></li>
</ol>
<p>总的来说，Llama 2
的训练流程结合了大规模的自监督学习、基于指令的有监督微调，以及基于人类偏好的强化学习，通过一系列精细的步骤来提升模型的语言理解、输出的帮助性和安全性。</p>
<h4 id="proximal-policy-optimization-ppo">Proximal Policy Optimization
(PPO)</h4>
<p>建议先阅读以下两篇优秀博客： - <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xingzheai/p/15826847.html">详解策略梯度算法</a>
- <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xingzheai/p/15931681.html">详解近端策略优化</a></p>
<p><strong>PPO-clip</strong>:
在PPO（邻近策略优化）中，代理损失函数（surrogate loss）
是通过当前策略和参考策略下执行同一动作的概率比率来定义的。这一比率用于引导策略向那些能够获得更高奖励的动作倾斜，同时确保策略更新的幅度不会过大，从而保持训练的稳定性。为防止策略的更新幅度过大，PPO引入了剪裁，限制比率在一定范围内。通过在一定阈值外“剪裁”比率的变化，模型可以避免发生过大的更新，从而保证训练过程的稳定性。</p>
<p>定义 <span class="math inline">\(\pi_{\theta}\)</span>为当前策略（参数为 <span class="math inline">\(\theta\)</span> 的一个网络），<span class="math inline">\(\pi_{ref}\)</span>
是实际的、可参考的策略空间。<span class="math inline">\(A(s_t,
a_t)\)</span>为在状态 <span class="math inline">\(s_t\)</span>
下采取行为 <span class="math inline">\(a_t\)</span>
时得到的奖励。近端策略优化裁剪函数为： <span class="math display">\[
L(\theta) = E_{(s_t, a_t) \sim \pi_{ref}} \min{(\frac{p_{\theta}(a_t |
s_t)}{p_{\pi_{ref}}(a_t|s_t)} A(s_t, a_t), clip(\frac{p_{\theta}(a_t |
s_t)}{p_{\pi_{ref}}(a_t|s_t)}, 1-\epsilon, 1+\epsilon)A(s_t, a_t))},
\]</span> <span class="math inline">\(\epsilon\)</span>
是一个超参数，要需要我们调整的，一般设置为0.1或0.2。</p>
<p><strong>PPO-penalty</strong>: 在PPO中，除了使用剪裁目标函数（clipped
objective）外，另一种常见的方法是直接在目标函数中加入KL散度惩罚项。这意味着算法会根据新策略与参考策略的偏离程度对目标函数进行惩罚。具体损失函数为：
<span class="math display">\[
L(\theta) = E_{(s_t, a_t) \sim \pi_{ref}} \frac{p_{\theta}(a_t |
s_t)}{p_{\pi_{ref}}(a_t|s_t)} A(s_t, a_t) - \beta
KL(\pi_{ref}||\pi_{\theta}),
\]</span></p>
<p>通过<strong>最大化目标函数</strong>得到最优策略。对于大规模语言模型（LLM）来说，这个目标函数反映了模型对齐的目标，比如生成<strong>有帮助</strong>、<strong>真实</strong>、<strong>无害</strong>的回答。</p>
<p><strong>参考策略 (Reference
Policy)</strong>：参考策略是训练过程中用作<strong>基准</strong>或<strong>对照</strong>的一套策略。它通常是一个<strong>稳定的策略</strong>，模型可以从这个基准出发，或者在训练过程中参考该策略来指导学习。它确保最优策略的更新不会偏离初始策略太远，防止训练过程中产生剧烈变化或不稳定的行为。</p>
<h3 id="reinforcement-learning-with-ai-feedback-rlaif">Reinforcement
Learning with AI Feedback (RLAIF)</h3>
<p>RLAIF
使用AI生成的偏好（而不是人工标注的偏好）来训练大规模语言模型（LLMs）。这种方法通过利用强大的预训练模型（如GPT-4）生成反馈，为训练其他LLM提供高效、成本更低的替代方案。在RLAIF中，反馈生成的语言模型相当于充当了“虚拟人工标注者”的角色。它评估训练中的模型生成的多个输出，选择优选响应或提供改进建议。</p>
<h4 id="direct-preference-optimization-dpo">Direct Preference
Optimization (DPO)</h4>
<p>本文前面讨论的 RLHF
主要包括两个阶段：根据人类偏好标签训练奖励模型，然后使用强化学习（RL）对
LM 进行微调，使其与这些偏好保持一致。然而，RLHF
存在复杂性和不稳定性问题，它需要拟合一个奖励模型，然后训练一个策略来优化该奖励，这就容易产生稳定性问题。</p>
<p>DPO算法摆脱了传统RL方法中的两个阶段。通过定义新的损失函数来训练LLM，以避免不稳定性问题。
DPO使用一种特殊格式的数据集，形式为：&lt;prompt, worse completion,
better
completion&gt;（即“提示，较差的完成，较好的完成”）。在训练过程中，DPO的损失函数鼓励模型增加较好完成的概率，同时降低较差完成的概率。这个过程是通过加权实现的，权重基于隐含的奖励模型。这里的关键在于，LLM本身充当了奖励模型，因此不再需要一个显式的奖励模型。下图给出了DPO和RLHF的区别。</p>
<p><img src="/2024/10/08/statistic/DPO.jpg"></p>
<p><strong>Binary Cross-Entropy Loss</strong> DPO
通过使用二元交叉熵（Binary Cross-Entropy,
BCE）损失函数来优化语言模型以更好地与人类偏好对齐的训练方法。对于每个输入，模型会生成两个响应，并由人类标注者指明他们的偏好（哪个响应更好）。DPO通过比较模型生成的响应对（即优选响应和不优选响应）与人类偏好进行训练。</p>
<p>损失定义如下： <span class="math display">\[
L_{DPO}(\theta) = -E_{(x, y_w, y_l) \sim D} [\log \sigma (\beta
\log\frac{\pi_{\theta}(y_w| x)}{\pi_{ref}(y_w|x)} - \beta \beta
\log\frac{\pi_{\theta}(y_l| x)}{\pi_{ref}(y_l|x)})],
\]</span> 其中，<span class="math inline">\(\pi_{\theta}\)</span>
为要训练的策略模型， <span class="math inline">\(\pi_{ref}\)</span>
是参考的策略模型；<span class="math inline">\(y_w\)</span> 和 <span class="math inline">\(y_l\)</span> 分别表示优选response 和 不优选的
response. <span class="math inline">\(\beta\)</span>
控制待训练模型与参考策略模型的接近程度。<span class="math inline">\(\sigma\)</span> 为 logistic 函数。</p>
<ul>
<li>DPO标志着语言模型训练方法的转变，通过将强化学习与人类反馈（RLHF）过程整合为<strong>单个的端到端</strong>优化步骤，简化了模型的训练。</li>
</ul>
<p><strong>DPO 的训练过程</strong> -
选择一个已经经过基础指令调优的语言模型作为参考模型，这个模型提供了良好的基础。
-
使用不同的采样/解码方法（例如不同的温度设置）对同一提示生成成对输出，并让人类选择他们喜欢的哪一个。这一过程将产生一个人类偏好/反馈的数据集。
-
在LLM上添加一个线性层，使得模型能够输出一个标量值。这一层将帮助模型在训练过程中产生更具体的数值输出。
-
使用DPO损失，该损失函数基于二元交叉熵损失。计算参考模型和正在调优模型的标量输出的对数比率，并乘以一个散度参数，以调整模型的输出。
-
在训练完成后，去掉最后的线性层，这样就得到了一个基于人类反馈微调的LLM。</p>
<p>通过以上步骤，DPO方法通过简化RLHF过程，去掉了复杂的强化学习步骤和专门的奖励模型，使得模型训练更为高效和直接。这样，最终得到的模型能够更好地反映人类的偏好，提供更优质的输出</p>
<h4 id="kahneman-tversky-optimization-kto">Kahneman-Tversky Optimization
(KTO)</h4>
<p>人类在面对不确定事件时，由于‘厌恶损失’，往往会做出无法最大化期望值的决策。直接以人的偏好指导大模型的训练，其训练的数据中包含了大量的人类偏好，往往无法做出期望最大的决策。KTO是一种对齐手段，将重点从传统训练目标（如下一个标记预测或拟合配对偏好数据）转向直接优化被<strong>认为有价值或可取</strong>的输出。</p>
<p>KTO消除了对配对偏好排名或比较数据的需求，显著简化了数据要求。它只需要二元标签，指示某个LLM输出是可取的还是不可取的。这种二元偏好数据的需求使KTO在现实场景中更为实用，因为收集详细的偏好数据往往比较困难。</p>
<p><strong>前景理论 (prospect theory)</strong></p>
<p>KTO 的灵感来自 Daniel Kahneman 和 Amos Tversky
提出的决策行为模型，特别是他们的前景理论 (prospect theory)。KTO
将这些概念调整为损失函数，通过捕捉人类的偏差（如损失规避和风险敏感性），使
LLM 与人类反馈保持一致。</p>
<p>在前景理论中，人类在不确定性下的决策行为偏离了预期效用最大化的原则，主要是因为一些心理偏差，如损失厌恶（loss
aversion）和非线性概率加权（nonlinear probability
weighting）。这些概念是KTO损失函数的基础。</p>
<p><strong>1. 价值函数 (Value
Function)</strong>：前景理论中的价值函数用于描述人们如何看待收益和损失的差异。它具有以下特征：</p>
<ul>
<li><p><strong>对收益的凹性</strong>：当收益增加时，价值函数是凹的，这意味着人们在获得相同金额的收益时，所感受到的价值增加会逐渐减小。这反映了人们在面对收益时的风险厌恶（risk
aversion）。</p></li>
<li><p><strong>对损失的凸性</strong>：当面临损失时，价值函数是凸的，这意味着在损失相同金额时，所感受到的损失会逐渐增大，反映了人们在面对损失时的风险寻求（risk-seeking）行为。</p></li>
<li><p><strong>损失的影响大于收益</strong>：损失对人们的情感影响通常大于收益，这一点通过损失厌恶参数
<span class="math inline">\(\lambda\)</span>
来建模。该参数通常大于1，意味着人们在面对损失时的感受强于获得相同金额收益时的感受。</p></li>
</ul>
<p><strong>2. 数学表达式</strong>. 价值函数 <span class="math inline">\(v(x)\)</span> 可以用以下公式表示： <span class="math display">\[
v(x) = \begin{cases}
x^\alpha &amp; \text{if } x \geq 0 \\
-\lambda (-x)^\beta &amp; \text{if } x &lt; 0
\end{cases}
\]</span> 其中：</p>
<ul>
<li>$ (0,1)$ 和 <span class="math inline">\(\beta \in (0,1)\)</span>
控制对收益和损失的减敏感性（diminishing
sensitivity）。这意味着随着收益或损失的增加，人们的感知效应会逐渐减弱。</li>
<li>$ $
是损失厌恶因子，通常大于1，这表示人们对损失的反应比对收益更为强烈。</li>
</ul>
<p><strong>3. 概率加权函数 (Probability Weighting Function)</strong>:
人们在判断概率时，往往会倾向于高估小概率事件和低估大概率事件。尽管这一元素并非KTO的核心部分，但它强调了主观不确定性感知如何影响决策。这种加权使得人们在面对不确定性时的决策并不是完全理性的，而是受到了心理因素的影响。</p>
<p>Kahneman-Tversky Optimization (KTO)
的损失函数是基于前景理论构建的，其设计目标是直接最大化语言模型生成输出的效用。以下是
KTO 损失函数的关键要素及其解释：</p>
<p><strong>KTO‘s loss function</strong></p>
<ul>
<li><p>KTO 使用了一个 <strong>逻辑函数 <span class="math inline">\(\sigma\)</span></strong>，而不是经典前景理论中的分段价值函数。这种逻辑函数保持了对收益的<strong>凹性</strong>和对损失的<strong>凸性</strong>，反映了人类对风险的感知。</p></li>
<li><p><strong>风险厌恶参数 <span class="math inline">\(\beta\)</span></strong>
被纳入模型中，用于控制风险厌恶程度。这一参数影响价值函数饱和的陡峭程度，进而影响模型如何感知收益和损失。</p></li>
<li><p>在 KTO 中，传统的损失厌恶参数 <span class="math inline">\(\lambda\)</span>
被替换为两个独立的超参数：<strong><span class="math inline">\(\lambda_D\)</span></strong>（用于积极反馈的输出）和
<strong><span class="math inline">\(\lambda_U\)</span></strong>（用于消极反馈的输出）。允许模型根据输出类型的不同（积极或消极），以更细致的控制方式来处理反馈，从而更好地反映人类的风险厌恶特性。</p></li>
<li><p>模型的参考点通过 <strong>KL 散度</strong>
来定义，表示当前模型策略 <span class="math inline">\(\pi_\theta\)</span>
与参考策略 <span class="math inline">\(\pi_{\text{ref}}\)</span>
之间的差异。KL
散度项控制当前模型输出与预训练参考模型的偏离程度，并作为优化中评估收益和损失的参考点
<span class="math inline">\(z_0\)</span>。</p></li>
</ul>
<p>KTO（Kahneman-Tversky Optimization）损失函数的数学公式如下： <span class="math display">\[
L_{KTO}(\pi_\theta, \pi_{\text{ref}}) = \mathbb{E}_{x,y \sim
D}[\lambda_y - v(x,y)], \\
\quad \\
v(x,y) =
   \begin{cases}
   \lambda_D \sigma(\beta(r_\theta(x,y) - z_0)), &amp; \text{if } y \sim
\text{desirable} \\
   \lambda_U \sigma(\beta(z_0 - r_\theta(x,y))), &amp; \text{if } y \sim
\text{undesirable}
   \end{cases}
\]</span></p>
<p>其中：</p>
<ul>
<li><p><strong><span class="math inline">\(\mathbb{E}_{x,y \sim
D}\)</span></strong>：表示对数据集 <span class="math inline">\(D\)</span> 中的样本进行期望计算，其中 <span class="math inline">\(x\)</span> 是输入，<span class="math inline">\(y\)</span> 是模型生成的输出。</p></li>
<li><p><strong><span class="math inline">\(\lambda_y\)</span></strong>：代表与输出 <span class="math inline">\(y\)</span> 相关的损失厌恶参数，可以是
<strong><span class="math inline">\(\lambda_D\)</span></strong>（用于积极输出）或
<strong><span class="math inline">\(\lambda_U\)</span></strong>（用于消极输出），用于表示人类对损失的厌恶程度。</p></li>
<li><p><strong><span class="math inline">\(r_\theta(x,y)\)</span></strong>： $ r_(x,y) = . $
该函数表示在当前策略 <span class="math inline">\(\pi_\theta\)</span>
下生成输出 <span class="math inline">\(y\)</span> 的对数概率与参考策略
<span class="math inline">\(\pi_{\text{ref}}\)</span>
下生成同一输出的对数概率之比。它衡量了当前模型与参考模型在生成特定输出时的相对表现。</p></li>
<li><p><strong><span class="math inline">\(z_0\)</span></strong>： <span class="math inline">\(z_0 = KL(\pi_\theta(y'|x) \|
\pi_{\text{ref}}(y'|x))\)</span>. 这里量化当前策略 <span class="math inline">\(\pi_\theta\)</span> 和参考策略 <span class="math inline">\(\pi_{\text{ref}}\)</span>
之间的差异。它作为评估当前策略与参考策略偏离程度的参考点。</p></li>
<li><p><strong><span class="math inline">\(v(x,y)\)</span></strong>：价值函数，依赖于输出
<span class="math inline">\(y\)</span> 的性质. <strong><span class="math inline">\(\sigma\)</span></strong>：逻辑函数，用于对价值函数进行调整，使其保持凹性（对于收益）和凸性（对于损失），模型就会在收益时更加规避风险，在损失时更加追求风险。<strong><span class="math inline">\(\beta\)</span></strong>：风险厌恶参数，控制风险厌恶的程度。增加
<span class="math inline">\(\beta\)</span>会增加收益时的风险规避行为和损失时的风险追求行为。</p></li>
</ul>
<h3 id="ppo-dpo-以及-kto-的对比">PPO, DPO 以及 KTO 的对比</h3>
<table>
<colgroup>
<col style="width: 11%">
<col style="width: 29%">
<col style="width: 29%">
<col style="width: 29%">
</colgroup>
<thead>
<tr>
<th>Aspect</th>
<th>PPO</th>
<th>DPO</th>
<th>KTO</th>
</tr>
</thead>
<tbody>
<tr>
<td>目标</td>
<td>最大化预期奖励，同时防止策略更新过大（目标函数clip）。</td>
<td>根据人类偏好直接优化策略，使用二元分类目标（使用 KL
散度约束）。</td>
<td>通过最大化 LLM
生成的效用对齐模型，基于前景理论，不需要详细的偏好对。</td>
</tr>
<tr>
<td>输入</td>
<td>来自环境的状态和奖励。</td>
<td>来自环境的状态和人类偏好反馈。</td>
<td>带有二元标签（可取或不可取结果）的 LLM 输出。</td>
</tr>
<tr>
<td>输出</td>
<td>在环境中采取的行动。</td>
<td>在环境中采取的行动，与人类偏好对齐。</td>
<td>与简化人类效用函数对齐的 LLM 生成结果。</td>
</tr>
<tr>
<td>学习机制</td>
<td>使用clip替代目标的策略梯度来更新策略和价值网络。</td>
<td>在人类偏好数据上进行二元交叉熵优化，更新单个策略网络。</td>
<td>基于 LLM 输出与二元反馈的对齐进行优化，无需复杂的偏好模型。</td>
</tr>
<tr>
<td>网络结构</td>
<td>独立的策略网络和价值网络。</td>
<td>单个策略网络。</td>
<td>针对 KTO 方法学调整的 LLM 框架。</td>
</tr>
<tr>
<td>反馈机制</td>
<td>使用来自环境的奖励作为学习的反馈。</td>
<td>使用人类偏好数据作为直接反馈进行学习。</td>
<td>利用对 LLM 输出的二元反馈来指导对齐，无需复杂的偏好数据。</td>
</tr>
<tr>
<td>稳定性</td>
<td>目标函数中的剪辑机制保持策略更新的稳定性。</td>
<td>通过直接优化偏好，利用动态逐例重要性加权实现内在稳定性。</td>
<td>通过简化反馈机制和聚焦于效用最大化来实现稳定的对齐。</td>
</tr>
<tr>
<td>复杂性</td>
<td>由于双网络结构和奖励最大化与策略更新稳定性之间的平衡，较复杂。</td>
<td>更简单，因为它绕过显式的奖励建模，直接从人类偏好优化政策。</td>
<td>通过消除对详细偏好建模的需求，专注于二元效用优化，降低复杂性。</td>
</tr>
<tr>
<td>适用性</td>
<td>适用于各种 RL 环境，其中奖励信号可用。</td>
<td>在与人类偏好对齐至关重要的场景中特别有效。</td>
<td>在快速和简化对齐人类反馈的场景中尤为有用。</td>
</tr>
</tbody>
</table>
<h3 id="对齐可能引入的偏差以及解决策略">对齐可能引入的偏差以及解决策略</h3>
<p>在讨论 <strong>强化学习人类反馈（RLHF）</strong> 和
<strong>强化学习人工反馈（RLAIF）</strong>
时，一个重要的问题是：这些方法是否会给模型引入偏见？答案是肯定的，正如任何依赖人类输入的机器学习方法，RLHF
也有引入偏见的潜力。</p>
<p><strong>可能引入的不同形式的偏见</strong></p>
<ol type="1">
<li><p><strong>选择偏见</strong>：RLHF
依赖于人类评估者的反馈，这些评估者可能会有自己的偏见和偏好，因此他们的反馈可能局限于他们能够关联的主题或情境。这可能导致模型没有接触到其在现实世界中将遇到的行为和结果的真实范围。</p></li>
<li><p><strong>确认偏见</strong>：人类评估者可能更倾向于提供确认他们已有信念或预期的反馈，而不是根据代理的表现提供客观反馈。这可能导致模型在某些行为或结果上受到强化，而这些行为或结果在长远来看可能并不理想或可取。</p></li>
<li><p><strong>评分者间的差异</strong>：不同的人类评估者可能对代理表现的质量有不同的看法或判断，导致agent收到的反馈不一致。这使得有效训练agent变得困难，并可能导致次优表现。</p></li>
<li><p><strong>反馈有限</strong>：人类评估者可能无法对agent表现的所有方面提供反馈，导致
agent 学习的缺口，可能在某些情况下表现不佳。</p></li>
</ol>
<p><strong>缓解策略</strong></p>
<ol type="1">
<li><p><strong>多样化评估者选择</strong>：选择具有不同背景和视角的评估者可以帮助减少反馈中的偏见，就像在工作场所中一样。这可以通过从不同的人口群体、地区或行业招募评估者来实现。</p></li>
<li><p><strong>共识评估</strong>：使用共识评估，即多个评估者对同一任务提供反馈，可以减少个体偏见的影响，提高反馈的可靠性。这几乎就像是对评估进行“归一化”。</p></li>
<li><p><strong>评估者的校准</strong>：通过提供培训和指导来校准评估者，帮助提高反馈的质量和一致性。</p></li>
<li><p><strong>反馈过程的评估</strong>：定期评估反馈过程，包括反馈质量和培训过程的有效性，可以帮助识别和解决可能存在的偏见。</p></li>
<li><p><strong>agent 表现的评估</strong>：定期评估 agent
在各种任务和不同环境中的表现，可以确保其没有过拟合于特定示例，并且能够推广到新的情境。</p></li>
<li><p><strong>平衡反馈</strong>：将人类评估者的反馈与其他反馈来源（如自我对话或专家演示）进行平衡，有助于减少反馈中的偏见影响，提高训练数据的整体质量。</p></li>
</ol>
<h3 id="trl---transformer-reinforcement-learning">TRL - Transformer
Reinforcement Learning</h3>
<p><strong>TRL</strong>（Transformer Reinforcement
Learning）库可用于通过
<strong>监督微调（SFT）</strong>、<strong>奖励建模（RM）</strong>、<strong>近端策略优化（PPO）</strong>
以及 <strong>直接偏好优化（DPO）</strong>
等方法，对转换器语言模型和扩散模型进行微调和对齐。</p>
<h2 id="mixture-of-experts">5. Mixture of Experts</h2>
<p><a target="_blank" rel="noopener" href="https://aman.ai/primers/ai/mixture-of-experts/">Mixture of
Experts</a></p>
<h2 id="encoder-vs.-decoder-vs.-encoder-decoder">6. Encoder vs. Decoder
vs. Encoder-Decoder？</h2>
<p><a target="_blank" rel="noopener" href="https://discuss.huggingface.co/t/suggestions-and-guidance-finetuning-bert-models-for-next-word-prediction/14043">模型总结</a>
<img src="/2024/10/08/statistic/enc_dec.jpeg"></p>
<h3 id="编码器模型">编码器模型</h3>
<p>基于编码器的模型专注于理解输入文本。它们通过在包含重建损坏输入任务的预训练（如掩码部门tokens）中，捕获丰富的上下文信息。<strong>BERT</strong>（双向编码器表示的变换器）是编码器模型的一个重要例子。在
BERT 中，部分输入标记会被特殊的 [MASK]
标记替代，模型通过周围的上下文预测这些被掩蔽的标记。这使得 BERT
能够学习双向表示，从而捕捉标记左侧和右侧的上下文。编码器模型在自然语言理解（NLU）任务中尤其有效，例如文本分类、情感分析和抽取式问答。这些任务受益于模型深刻理解和表示输入文本的能力。</p>
<p>BERT 可以利用双向语境进行预测 masked
tokens，相较于自回归模型，使用双向信息可以提高性能。然而，BERT
在预训练时使用的 [MASK]
等人工符号在微调时并不存在于真实数据中，这就造成了预训练数据与微调数据分布之间的异质性。此外，由于预测的tokens在输入中被mask，BERT
无法像自回归那样使用乘积规则建立联合概率模型。换句话说，<strong>BERT
assumes the predicted tokens are independent of each other given the
unmasked tokens, which is oversimplified as high-order, long-range
dependency is prevalent in natural language.
（在给定其他未被掩码的tokens时，BERT
对每个被掩盖的单词独立地进行预测，所有需要预测的token之间被假设是相互独立的）</strong></p>
<p>BERT（及其所有变体，如 RoBERTa、DistilBERT、ALBERT 等）和 XLM
就是编码器模型的例子。</p>
<p><img src="/2024/10/08/statistic/bert.jpg"></p>
<p><strong>优点：</strong></p>
<ol type="1">
<li><strong>上下文依赖性：</strong>
在BERT等Encoder模型中，模型可以同时获取左右两侧的上下文信息（双向上下文）。相比之下，像GPT这样的自回归模型只能访问当前位置之前的内容（单向上下文）。双向上下文对于理解文本中的复杂依赖关系和语义结构至关重要，因此Encoder模型在许多自然语言处理任务上表现优异。</li>
<li><strong>丰富的上下文理解：</strong>
Encoder模型擅长捕捉输入数据中的复杂模式和关系，尤其适合需要深入理解和分析的任务，比如命名实体识别、文本分类、阅读理解等。这使得模型能够更好地理解句子的语义和结构，从而在相关任务中表现出色。</li>
</ol>
<p><strong>缺点：</strong></p>
<ol type="1">
<li><strong>输入噪声：</strong>
BERT在预训练阶段使用了人工符号（如[MASK]）来掩盖部分输入单词，但这些符号在实际应用和微调时并不存在。这种差异导致了预训练和微调之间数据分布的异质性，影响模型的迁移能力。</li>
<li><strong>独立性假设：</strong>
BERT在预测被掩盖的单词时，假设每个掩盖的单词是独立于其他掩盖词的，只与未被掩盖的单词相关。例如，在句子“it
shows that the housing crisis was turned into a banking
crisis”中，如果掩盖了“banking”和“crisis”两个词，模型会分别预测它们，而不考虑二者之间的隐含关系。这种独立性假设限制了模型对掩盖词之间复杂依赖关系的捕捉，影响了在需要更精细理解的任务中的表现。</li>
</ol>
<h3 id="解码器模型">解码器模型</h3>
<p>基于解码器的模型（自回归模型）旨在执行文本生成任务。这些模型一次生成一个token，并使用之前生成的token作为上下文来预测下一个token。<strong>GPT</strong>（生成式预训练变换器）、GPT-2
和 GPT-3
是解码器模型的典型例子。这些模型在大规模语料库上进行预训练，以预测句子中的下一个词，从而能够生成连贯且语境相关的文本。解码器模型在自然语言生成（NLG）任务中表现出色，例如语言翻译、文本摘要和对话生成。它们生成流利且上下文适当的文本的能力使其成为从头生成内容任务的理想选择。</p>
<p>自回归语言模型利用上下文中的词来预测下一个词，通过估计文本语料库的概率分布来实现。具体来说，给定一个文本序列
$ x = (x_1, , x_T) <span class="math inline">\(，自回归语言建模将似然分解为前向积：\)</span>$
p(x) = <em>{t=1}^{T} p(x_t | x</em>{&lt;t}) $$</p>
<p>或者反向的形式： <span class="math display">\[
p(x) = \prod_{t=1}^{T} p(x_t | x_{&gt;t})
\]</span></p>
<p>通常使用<strong>多项式分布</strong>（Multinomial
Distribution）来建模下一个词的生成过程。这是因为语言模型的目标是根据先前的词预测当前词的概率，而语言中词汇的生成通常是一个离散事件。因此，给定上下文
$x_{&lt;t} $，下一个词 $ x_t $ 的条件概率可以表示为： <span class="math display">\[
p(x_t \mid x_{&lt;t}) = \text{softmax}(z_t),
\]</span> 其中，$ z_t $
是通过神经网络计算得到的未归一化的得分，通常代表每个词在词汇表中的相对可能性。通过使用
softmax
函数，这些得分被转换为一个有效的概率分布，保证所有可能词的概率和为
1。</p>
<p>在这种情况下，模型会学习每个条件分布的参数模型（例如神经网络）。由于自回归语言模型只训练编码单向上下文（要么是前向的，要么是后向的），因此它在建模深层双向上下文方面并不有效。下面的图示展示了前向和后向的方向性。</p>
<p><img src="/2024/10/08/statistic/auto1.jpg"></p>
<p><img src="/2024/10/08/statistic/auto2.jpg"></p>
<p><strong>优点：</strong></p>
<ol type="1">
<li><strong>生成能力强</strong>：自回归语言模型非常适合生成式自然语言处理（NLP）任务。由于它们采用因果注意力机制来预测下一个标记，因此在内容生成方面自然适用。它们能够生成流畅且与上下文相关的文本，这使得它们在需要自然语言生成的任务中表现出色。</li>
<li><strong>训练数据生成简单</strong>：训练这些模型的数据生成相对简单，因为目标只是预测给定序列中的下一个标记。这利用了语言数据的固有结构，使得数据准备过程更加高效。</li>
</ol>
<p><strong>缺点：</strong></p>
<ol type="1">
<li><strong>上下文限制</strong>：自回归语言模型只能使用前向上下文或后向上下文，这意味着它们不能同时利用双向上下文。这种限制可能会影响它们在需要深刻理解双向上下文的任务中的表现。例如，在处理复杂句子结构或含义依赖时，缺乏双向上下文可能导致理解不够准确。</li>
</ol>
<h4 id="编码器-解码器模型">编码器-解码器模型</h4>
<p>编码器-解码器模型（也称为seq2seq
模型）结合了编码器和解码器架构的优势。这些模型使用编码器处理和理解输入序列，使用解码器生成输出序列。这种架构在输入和输出都是序列的任务中特别有效，这些序列可能具有不同的长度或格式，甚至是不同的语言。
编码器将输入序列转换为固定长度的上下文向量或中间表示，捕捉输入的含义和上下文。解码器然后接收这个上下文向量，逐个标记地生成输出序列，通常采用类似于解码器模型中的自回归技术。</p>
<ul>
<li><strong>T5 (Text-To-Text Transfer
Transformer)</strong>（文本到文本的迁移变换器）是编码器-解码器模型的一个显著例子。T5
将每个自然语言处理问题都视为一个文本到文本的问题，其中输入和输出都是文本序列。这种方法使
T5 能够应用于广泛的任务，包括翻译、摘要和问答。<br>
</li>
<li><strong>BART (Bidirectional and Auto-Regressive
Transformers)</strong>（双向自回归变换器）是另一个强大的编码器-解码器模型。BART
通过使用任意噪声函数破坏文本并学习重建原始文本进行预训练。这使得它在需要基于对输入的理解生成文本的任务（如摘要和对话生成）中非常有效。<br>
</li>
<li><strong>BigBird</strong>
使用稀疏注意力机制来处理较长的序列。这使得它适合处理长文档的任务，如文档分类和长篇问答。</li>
</ul>
<p><strong>优点：</strong></p>
<p>编码器-解码器模型能够同时处理输入的理解和输出的生成，使它们在以下任务中特别有效：</p>
<ul>
<li><p>机器翻译：将一种语言翻译成另一种语言。</p></li>
<li><p>文本摘要：生成文本的简要概述。</p></li>
<li><p>对话生成：在对话系统中生成合适的回应。</p></li>
</ul>
<p><strong>缺点：</strong></p>
<ol type="1">
<li><p><strong>计算资源需求高</strong>：编码器-解码器模型通常参数量庞大，尤其是在处理复杂任务时。它们需要大量的计算资源和内存，训练和推理速度可能较慢。</p></li>
<li><p><strong>长序列处理能力有限</strong>：虽然一些模型（如BigBird）专门针对长序列进行了优化，但传统的编码器-解码器模型在处理非常长的输入时仍然面临挑战，因为它们的输入长度受限。</p></li>
<li><p><strong>依赖于大量标注数据</strong>：这些模型通常需要大量的高质量标注数据进行训练，这在某些领域可能难以获得。此外，训练过程中数据的多样性和质量直接影响模型的性能。</p></li>
<li><p><strong>对输入输出长度不匹配的敏感性</strong>：编码器-解码器模型在处理输入和输出长度差异较大的任务时，可能会表现不佳。例如，当输入很长而输出很短时，模型可能难以有效地提取和生成信息。</p></li>
</ol>
<h3 id="总结">总结</h3>
<ul>
<li>编码器模型在需要理解和解释文本的任务中表现出色。由于其能够捕捉双向上下文，这使得它们适用于理解整个句子或文档上下文至关重要的任务。例如，命名实体识别、情感分析和文本分类等任务都依赖于模型对输入文本的深刻理解。</li>
<li>解码器模型则非常擅长生成文本，因此非常适合创意任务，如故事生成、聊天机器人回复和文本补全等。它们通过利用先前生成的内容作为上下文来预测下一个词，从而能够生成流畅且与上下文相关的文本。</li>
<li>编码器-解码器模型提供了一种灵活的架构，可以处理广泛的任务，从机器翻译、文本摘要到复杂的问题回答和文档生成。这种模型能够同时理解和生成文本，使其在需要深刻理解和流利文本生成的任务中非常有效。</li>
</ul>
<p>例如，在机器翻译中，编码器处理源语言的输入句子，生成一个上下文向量，而解码器则利用这个上下文向量生成目标语言的翻译。类似地，在文本摘要中，编码器阅读并理解原始文本，而解码器则生成一个简洁的摘要。这种架构的优势在于它能够结合理解和生成的能力，适用于多种自然语言处理任务。</p>
<h2 id="目标检测的常用评估指标">7. 目标检测的常用评估指标</h2>
<h3 id="intersection-over-union-iou">Intersection Over Union (IoU)</h3>
<p><img src="/2024/10/08/statistic/iou.png"> Image credits to <a target="_blank" rel="noopener" href="https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a31173">source</a></p>
<p>IoU 越高，拟合效果越好。IoU
对任何大小和形状的物体都很有效。这一针对每个物体的指标与精确度和召回率共同构成了完整的物体检测指标--平均精确度
(mAP) 的基础。</p>
<h3 id="average-precision-ap">Average Precision (AP)</h3>
<p>目标检测器会生成多个预测结果：每张图片可能包含多个被预测的目标，而需要进行推理的图片也很多。每个预测目标都会被赋予一个置信度，表示检测器对该预测的信心程度。我们可以选择不同的<strong>置信度阈值</strong>，以决定接受哪些预测结果。例如，若将阈值设置为
0.7，那么只接受置信度大于 0.7
的预测，低置信度的预测将被舍弃。由于可以选择的阈值很多，使用精确率-召回率曲线进行评估。</p>
<p>模型越好，其的精确度和召回率就越高：这会将曲线的边界推向顶部和右侧。可以用曲线下的面积来概括模型的性能。这样就得到了一个介于
0 和 1 之间的数值，数值越大越好。这个指标通常称为平均精度 (AP)。</p>
<h3 id="mean-average-precision-map">Mean Average Precision (mAP)</h3>
<p>mAP
用来衡量模型的整体检测性能。它结合了精确率（precision）和召回率（recall），并对不同类别和不同阈值下的检测结果进行综合评价。这里的类别指的是目标检测任务中模型需要识别的不同目标种类或类型。例如，在物体检测任务中，每个目标物体都属于某个特定类别（如“人”、“车”、“猫”、“狗”等），这些类别就是检测任务中模型需要识别和区分的对象。</p>
<h4 id="计算过程">计算过程</h4>
<p>首先，我们只考虑单张图片和单个类别。假设网络在一张图片中预测了 10
个属于某一类别的目标：每个预测包含一个bounding
boxes、预测的类别以及预测的置信度（即网络对其预测的信心）。</p>
<ol type="1">
<li><p>使用IoU来决定每个预测是否正确。对于每个真实目标和相应的预测，如果同时满足：（1）预测的类别与真实类别匹配；（2）IoU
大于某个阈值。那么认为该预测是正确的（True
Positive）。否则，该预测被认为是错误的（False Positive）。</p></li>
<li><p>将所有的预测按置信度从高到低排序。在表格中，按置信度从高到低排列预测结果，右侧显示累积的精确率和召回率。</p></li>
</ol>
<p><img src="/2024/10/08/statistic/table1.png"></p>
<ol start="3" type="1">
<li><p>根据这张表格，对于每个置信度（从最大到最小），计算出截至该点的精确度和召回率。将其绘制成图，然后得到该图像和类别的原始精确度-召回率曲线：
<img src="/2024/10/08/statistic/graph1.png"></p></li>
<li><p>将该曲线锯齿平滑化，从而绘制出网络针对该图像和类别的最终精确度-召回曲线。根据平滑后的精确度-召回率曲线计算平均精确度（曲线下的面积）：
<img src="/2024/10/08/statistic/graph2.png"> (Images credits to <a target="_blank" rel="noopener" href="https://cs230.stanford.edu/section/8/">source</a>)</p></li>
<li><p>对每张图像和每个类别的 AP
进行平均，从而得出模型在整个数据集的平均精度 mAP.</p></li>
</ol>
<h2 id="文本生成模型的常用评估指标">8. 文本生成模型的常用评估指标</h2>
<h3 id="困惑度-perplexity">困惑度 Perplexity</h3>
<p>Perplexity
衡量语言模型生成文本流畅性和质量的一个常见指标，反映模型对词序预测的准确性。它本质上是模型对给定文本的“不确定性”的度量。困惑度得分越低，说明语言模型在计算给定序列中可能出现的下一个单词时越自信，而困惑度得分越高，说明模型对词的预测较为不确定，生成的文本可能不流畅，或者不符合语言结构。</p>
<p>熵是随关于机变量的不可预测性或随机性的度量。对于一个离散随机变量
<span class="math inline">\(x\)</span>，概率分布为 <span class="math inline">\(p(x)\)</span>，其熵定义为 <span class="math display">\[
H(x) = -\sum_x p(x) \log_2 p(x).
\]</span>
基于此，困惑度定义为一个序列的负对数似然的指数平均。具体来说，假设模型为一段文本
$ (w_1, w_2, ..., w_N)$ 生成概率，困惑度定义为： <span class="math display">\[
\begin{aligned}
\text{Perplexity} &amp;= 2^{-\frac{1}{N} \sum_{i=1}^{N} \log_2 P( w_1,
w_2, ..., w_{i-1}, w_i)} \\
&amp;= P(w_1, w_2, ..., w_{i-1}, w_i)^{-\frac{1}{N}} = \prod_{i=1}^{N}
P(w_i | w_1, w_2, ..., w_{i-1})^{-\frac{1}{N}}.
\end{aligned}
\]</span> 其中，$ P(w_i | w_1, w_2, ..., w_{i-1}) $ 是模型在前面 <span class="math inline">\(i-1\)</span> 个词的条件下预测第 $ i $
个词的概率。</p>
<h3 id="突发性-burstiness">突发性 Burstiness</h3>
<p>突发性意味着如果一个词在文档中使用了一次，那么它很可能会再次出现。这种现象称为突发性，它表明第二次及之后出现的词的重要性低于第一次出现的词。值得注意的是，词语的突发性与其语义内容呈正相关性：信息量更大的词也往往更加突发。突发性基本上衡量了一段内容的可预测性，体现在句子长度和结构的均一性上。</p>
<p>通过收集句子长度，将文本中的每个句子按照其包含的单词数计算长度。计算均值（句子长度的平均值）和方差（句子长度的波动程度）。突发性
<strong>b</strong> 的数学计算公式为：<br>
<span class="math display">\[
b = \left( \frac{\sigma_{\tau}}{m_{\tau}} - 1 \right) \left(
\frac{\sigma_{\tau}}{m_{\tau}} + 1 \right)^{-1}
\]</span> 其中，<strong>b</strong> 的取值范围在 <span class="math inline">\([-1, 1]\)</span> 之间。</p>
<p>一般来说，人工智能具有统一有规律的特点。因此可以假设人类作者的突发性高于
AI 的突发性: <span class="math display">\[
b_H - b_{AI} \geq 0
\]</span> 其中，<strong>b_H</strong>
表示人类作者的平均突发性，<strong>b_{AI}</strong> 表示
AI（如某个特定的大型语言模型）的平均突发性。</p>
<p>总之：</p>
<ul>
<li><p>Perplexity
主要用于评估模型的语言流畅性，适合衡量语言模型在生成或预测下一个词时的能力。它衡量的是整个文本的语言建模性能。</p></li>
<li><p>Burstiness
则侧重于文本中词语分布的不均匀性，尤其关注某些词或话题在文本中突然集中出现的现象。它更多地用于分析文本结构中的局部特征。</p></li>
</ul>
<h3 id="bleu">BLEU</h3>
<p>BLEU 是双语评估研究（Bilingual Evaluation
Understudy）的缩写，<strong>主要用于机器翻译</strong>。它通过与一组参考译文进行比较来量化机器翻译文本的质量。BLEU
分数计算的关键是机器翻译文本中 n-grams （给定文本样本中 n
个单词的连续序列）的精确度。不过，为了防止因句子较短而高估精确度，BLEU
包含一个简短度惩罚因子。尽管 BLEU
被广泛使用，但值得注意的是，<strong>BLEU
主要关注的是精确度，缺少召回率部分。</strong></p>
<p>对于 unigram (single word)，精度计算公式为 <span class="math display">\[
\text{precision} = \frac{Number of correct words in machine
translation}{Total words in machine translation}.
\]</span> <strong>Unigram matches tend to measure adequacy while longer
n-grams matches account for fluency.</strong> 为避免夸大精度，BLEU
采用修正的精度计算方法。计算方式如下：</p>
<ol type="1">
<li><p>对于 n-gram，计算预测序列中所有匹配的 n-gram
与该序列中所有n-gram的商。 <span class="math display">\[
p_n = \frac{\sum_{n-gram \in \text{hypothesis}}
\text{count}_{\text{match}}(n-gram)}{\sum_{n-gram \in \text{hypothesis}}
\text{count}(n-gram)}.
\]</span> 示例： <img src="/2024/10/08/statistic/bleu-unigrams.png">
Image credits to <a target="_blank" rel="noopener" href="https://aman.ai/primers/ai/evaluation-metrics/#example-1">source</a>.
如图所示，对于unigram，计算得到的 <span class="math inline">\(p_n =
7/9\)</span>.</p></li>
<li><p>计算得到不同 n-grams 的精度，然后对其对数进行加权平均： <span class="math display">\[
\text{BLUE}_N = \text{BP} \exp(\sum_{n=1}^{N}w_n \log p_n).
\]</span></p></li>
</ol>
<ul>
<li>为了防止机器翻译生成的翻译过于简短，增加了简洁性惩罚 BP，BP
是参考序列和预测训练长度的函数。 <span class="math display">\[
\text{BP} = \begin{cases}
1 &amp; \text{if } l_{hyp} &gt; l_{ref} \\
e^{(1 - \frac{l_{ref}}{l_{hyp}})} &amp; \text{if } l_{hyp} \geq l_{ref}
\end{cases}
\]</span> BLEU 分数是一个介于 0 和 1 之间的标量值，0.6 或 0.7
分是当前可以达到的较好的分数。</li>
</ul>
<h3 id="rouge">ROUGE</h3>
<p>ROUGE 分数代表 <strong>Recall-Oriented Understudy for Gisting
Evaluation</strong>，最早在《ROUGE: A Package for Automatic Evaluation
of
Summaries》中提出，主要用于自动总结的评估，有时也用于机器翻译的评估。</p>
<p>ROUGE 的关键特征是其对召回率的重视，测量系统生成的摘要中有多少参考
n-gram 被找出。这使得 ROUGE 尤其适用于需要覆盖关键点的任务。ROUGE
的变体中，<strong>ROUGE-N</strong> 计算 n-gram
的重叠情况，<strong>ROUGE-L</strong>
使用最长公共子序列来衡量句子层级的结构相似性，<strong>ROUGE-S</strong>
则包含跳跃双字组的统计信息。</p>
<p><strong>ROUGE-N</strong>: <span class="math display">\[
\text{ROUGE-N} = \frac{\text{Number of N-grams in both system and
reference summary}}{\text{Total number of N-grams in reference summary}}
\]</span></p>
<p><strong>ROUGE-L</strong>: 或称 <strong>ROUGE-LCS</strong>。
基于最长公共子序列（LCS）的长度进行评估。为了弥补纯召回率指标（如
ROUGE-N）的不足，ROUGE-L 通过计算 <span class="math inline">\(F_{\beta}\)</span>
分数，结合了精确率和召回率。</p>
<p>ROUGE-LCS的优势在于，它不仅仅关注 n-gram
的连续词汇重叠，还考虑了序列匹配（即重叠的词不一定需要按照相同顺序出现）。另一个更大的优势是，它自动包含最长的序列内的公共
n-gram，因此不需要预先定义 n-gram 的长度。 <span class="math display">\[
\text{ROUGE-LCS} = \frac{(1 + \beta^2) R_{LCS} P_{LCS}}{R_{LCS} +
\beta^2 P_{LCS}}
\]</span> 其中： - <strong>LCS(reference,
hypothesis)</strong>：表示参考文本和生成文本的最长公共子序列。 - <span class="math inline">\(R_{LCS}\)</span>：表示基于参考文本的 LCS
召回率，公式为 $ $。 - <span class="math inline">\(P_{LCS}\)</span>：表示基于生成文本的 LCS
精确率，公式为 $ $。</p>
<p>示例： <img src="/2024/10/08/statistic/rouge-l.png"> Image credits
to <a target="_blank" rel="noopener" href="https://aman.ai/primers/ai/evaluation-metrics/#example-1">source</a>。在该例子中，
可以计算得到 <span class="math inline">\(R_{LCS} = 7/10\)</span>, <span class="math inline">\(P_{LCS} = 7/9\)</span>, <span class="math inline">\(\text{ROUGE-LCS} = \frac{(1 + \beta^2) 49}{70 +
\beta^2 63}\)</span></p>
<h3 id="bertscore">BERTScore</h3>
<p><strong>BERTScore</strong> 和 <strong>MoverScore</strong>
是两个用于评估文本生成任务（如机器翻译、文本摘要等）质量的指标，它们基于语义相似性，弥补了传统
n-gram 匹配方法（如
BLEU、ROUGE）的不足。这两者通过引入深度学习模型（特别是
BERT）来捕捉文本的语义信息，更加注重内容的语义一致性。</p>
<p>BERTScore是一种基于 BERT
预训练模型的文本评估方法。它通过计算生成文本和参考文本在语义上的相似性，避免了传统
n-gram 方法忽略语义匹配的不足。BERTScore
主要是通过比较句子的词嵌入（word embeddings）来衡量语义相似度。</p>
<h4 id="关键步骤">关键步骤</h4>
<ol type="1">
<li><strong>词嵌入表示</strong>：使用 BERT
模型将生成文本和参考文本中的单词转换为高维的向量表示（嵌入表示）。</li>
<li><strong>相似性计算</strong>：计算生成文本和参考文本中每个词的嵌入表示的余弦相似度（cosine
similarity）。</li>
<li><strong>匹配</strong>：为每个生成文本中的词找到参考文本中最相似的词，并基于余弦相似度进行匹配。对于候选句子中的每个token，选择与参考句子中任何token的余弦相似度得分最高的token，反之亦然。这些得分用于计算精确度、召回率和
F1 score。</li>
<li><strong>平均相似度</strong>：基于这些匹配，对整个数据集的精确度、召回率和
F1 分数进行汇总，计算生成文本和参考文本之间的整体相似度分数。</li>
</ol>
<h4 id="bertscore-的优势">BERTScore 的优势</h4>
<ul>
<li>能够捕捉到词汇和语义之间的细微差别，特别适合于语义相似但词汇不完全相同的场景。</li>
<li>相比于 BLEU 和 ROUGE 等基于 n-gram
的方法，它更加关注语义层面的匹配，而不仅仅是词汇层面的匹配。</li>
</ul>
<h3 id="moverscore">MoverScore</h3>
<p><strong>MoverScore</strong>
是一种改进的文本相似度评估指标，它将<strong>词移动距离（Word Mover's
Distance, WMD）</strong>与<strong>BERT
嵌入</strong>相结合，用来衡量生成文本和参考文本之间的语义差异。MoverScore
不仅考虑了词汇的相似性，还考虑了将生成文本中的词映射到参考文本中的最小代价。</p>
<h4 id="关键步骤-1">关键步骤</h4>
<ol type="1">
<li><strong>词嵌入表示</strong>：与 BERTScore 类似，使用 BERT
模型将文本中的每个词转换为向量表示。</li>
<li><strong>计算词移动距离</strong>：计算生成文本和参考文本之间的词嵌入的最小移动代价，即参考文本中的词映射到生成文本中的词需要“移动”多少距离。</li>
<li><strong>匹配得分</strong>：基于词移动距离计算生成文本和参考文本的相似度分数，得分越高表示两者的语义越接近。</li>
</ol>
<h4 id="moverscore-的优势">MoverScore 的优势</h4>
<ul>
<li>结合了词嵌入的语义相似度和词移动距离，能有效捕捉句子层次的结构信息和语义变化。</li>
<li>对词序、句子结构、语义信息具有更高的鲁棒性，特别适用于更复杂的语言生成任务评估。</li>
</ul>
<h3 id="对比总结">对比总结</h3>
<ul>
<li>语义匹配与标记相似性：MoverScore 使用单词移动距离（Word Mover's
Distance）和预训练嵌入来衡量整体句子级语义相似性。相比之下，BERTScore
则侧重于使用上下文嵌入的标记级相似性。</li>
<li>评估目标：MoverScore
通过测量词嵌入之间的距离来提供精细的语义评估，而 BERTScore
则评估标记嵌入的精确度、召回率和 F1 分数。</li>
<li>对同义词的鲁棒性：MoverScore
依赖于嵌入距离，因此对同义词和意译具有固有的鲁棒性，而 BERTScore
通过上下文嵌入也能很好地处理同义词和意译。</li>
</ul>
<p>总之，MoverScore 提供了一种sentence-level
语义相似性测量方法，可以捕捉句子的整体含义和结构，而 BERTScore
则提供了一种详细的token-level相似性评估方法，重点关注精确度、召回率和 F1
分数。</p>
<h2 id="国内外基座大模型">9. 国内外基座大模型</h2>
<h3 id="国内">国内</h3>
<ul>
<li><p>百度文心一言，2023年3月。具有强大的自然语言理解和生成能力，在搜索、信息流推荐、广告投放、智能写作、对话系统等场景中实现智能化升级。
<img src="/2024/10/08/statistic/wenxin.jpg"> (image credits to <a target="_blank" rel="noopener" href="https://wenxin.baidu.com">source</a>)</p></li>
<li><p>阿里通义千文，2023年4月。通义千问-Max（通义千问系列效果最好的模型，适合复杂、多步骤的任务），
通义千问-Plus（能力均衡，推理效果、成本和速度介于通义千问-Max和通义千问-Turbo之间，适合中等复杂任务），通义千问-Turbo（通义千问系列速度最快、成本很低的模型，适合简单任务）。2024年8月推出通义千问-72B（Qwen-72B）。通义千问-72B（Qwen-72B）是阿里云研发的通义千问大模型系列的720亿参数规模模型，它的预训练数据类型多样、覆盖广泛，包括大量网络文本、专业书籍、代码等。Qwen-72B-Chat是在Qwen-72B的基础上，使用对齐机制打造的基于大语言模型的AI助手。</p></li>
</ul>
<p><img src="/2024/10/08/statistic/ali.jpg"> (image credits to <a target="_blank" rel="noopener" href="https://help.aliyun.com/zh/model-studio/getting-started/models?spm=a2c4g.11186623.0.0.41f9253aof0b1F">source</a>)</p>
<ul>
<li><p>上海人工智能实验室等联合推出的书生·视觉大模型（InternVL）。书生浦语，书生万象，书生风乌，书生翼飞，书生天际，书生济世。InternVL2-Llama3-76B.
[github]（https://github.com/OpenGVLab/InternVL）</p></li>
<li><p>科大讯飞星火大模型，2023年5月。星火大模型在教育、医疗、政务、司法等行业应用场景中广泛使用，尤其是在智能语音合成、语音识别、语义理解和知识图谱构建等方面表现突出。</p></li>
<li><p>百川智能-百川大模型，2023年6月。</p></li>
<li><p>华为盘古大模型，2023年7月。</p></li>
<li><p>腾讯混元大模型，2023年9月。</p></li>
<li><p>商汤日日新，2024年4月。<a target="_blank" rel="noopener" href="https://platform.sensenova.cn/doc?path=/model/llm/GeneralLLM.md">doc</a></p></li>
<li><p>字节豆包，2024年9月。</p></li>
<li><p>清华-ChatGLM</p></li>
<li><p>智谱AI，GLM-4。</p></li>
<li><p>Minimax系列模型</p></li>
<li><p>京东言犀大模型。专为其电商平台定制的人工智能模型，尤其擅长在智能客服、智能营销和智能供应链管理等方面发挥作用</p></li>
<li><p>360GPT大模型。</p></li>
</ul>
<h3 id="国外">国外</h3>
<ul>
<li>Meta：LLaMA系列。2023年2月LLaMA1（7B、13B、33B、65B（650
亿）），2023年7月LLaMA2（7B、13B、34B和70B），2024年4月LLaMA3（8B和70B）。</li>
</ul>
<p>相比于Llama 1，Llama
2将预训练的语料token数量扩充到了2T（万亿），同时将模型的上下文长度从2048翻倍到了4096，并引入了分组查询注意力机制（grouped-query
attention, GQA）技术，GQA可以在最佳性能(multi-query
attention，MQA)和最佳模型质量(multi-head
attention，MHA)之间做到很好的权衡。</p>
<p>相比Llama 2，Llama
3支持8K长文本，并采用了编码效率更高的tokenizer，词表的大小为128K。在预训练数据方面，Llama
3使用了超过15T token的语料，这比Llama 2的7倍还多。Llama
3在性能上取得了巨大飞跃，并在相同规模的大模型中取得了最优异的性能。 -
ref:<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/694072728">万字长文详解LlaMA
3的前世今生</a> - ref:<a target="_blank" rel="noopener" href="http://arthurchiao.art/blog/llama-paper-zh/">LLaMA：开放和高效的基础语言模型集</a></p>
<ul>
<li>谷歌：Gemini系列。</li>
<li>微软：Bing.</li>
<li>亚马逊：拥有自己的大模型技术，并在电商、云服务、智能音响等领域有所应用。</li>
<li>苹果：在Siri、Face ID等方面已有所应用。</li>
</ul>
<h2 id="deepspeed-框架">6. Deepspeed 框架</h2>
<h2 id="智能体和多模态模型的区别">7. 智能体和多模态模型的区别</h2>
<h3 id="智能体agent">1. <strong>智能体（Agent）</strong></h3>
<p>智能体（Agent）是一种能够自主感知环境、做出决策并执行行动的系统，广泛应用于不同领域，如机器人、自动化系统、游戏角色、虚拟助理等。</p>
<h4 id="主要特点">主要特点：</h4>
<ul>
<li><strong>自主性</strong>：智能体能够根据感知到的环境信息，独立进行决策和行动，而不需要外部持续的控制。</li>
<li><strong>感知-决策-行动循环</strong>：智能体能够感知外部环境（通过传感器或输入），根据某种规则或策略进行决策，并在环境中执行相应的行为。这是智能体的核心特性。</li>
<li><strong>持续性</strong>：智能体通常在持续的时间框架中工作，不断与环境互动。</li>
<li><strong>适应性与学习</strong>：有些智能体可以通过学习（如强化学习）在复杂的环境中不断优化其行为。</li>
</ul>
<h4 id="举例">举例：</h4>
<ul>
<li>机器人智能体通过传感器感知周围环境，规划路径并自主导航。</li>
<li>自动驾驶汽车智能体根据道路情况实时调整驾驶策略。</li>
<li>游戏中的 AI 角色根据玩家行为做出回应并采取行动。</li>
</ul>
<h3 id="多模态-gpt">2. <strong>多模态 GPT</strong></h3>
<p>多模态 GPT 是基于 <strong>Transformer</strong>
架构的预训练语言模型（GPT），它能够处理和生成多种模态的数据，如文本、图像、音频等。传统
GPT 模型专注于自然语言处理，而多模态 GPT
可以跨越多种模态，将它们结合在一起进行任务处理，如从文本生成图像、理解图文组合等。</p>
<h4 id="主要特点-1">主要特点：</h4>
<ul>
<li><strong>多模态输入与输出</strong>：多模态 GPT
可以处理多种类型的数据。例如，它可以接收图像和文本作为输入，然后生成文本描述，或根据文本输入生成相关图像。</li>
<li><strong>基于 Transformer 架构</strong>：多模态 GPT 继承了 GPT 的
Transformer
架构，通过大规模的预训练进行自监督学习，从而具备强大的生成和理解能力。</li>
<li><strong>生成能力</strong>：多模态 GPT
强调生成能力，尤其在需要跨模态任务时表现出色，如生成图像、音频或视频，或通过对话生成文本内容。</li>
<li><strong>推理与回答</strong>：它可以通过整合不同模态的数据进行复杂的推理和回答，适用于许多生成和理解任务，如图文理解、文本生成等。</li>
</ul>
<h4 id="举例-1">举例：</h4>
<ul>
<li><strong>DALL·E</strong>：OpenAI 的 DALL·E 是多模态 GPT
的一个典型例子，能够根据文字描述生成高质量的图像。</li>
<li><strong>CLIP</strong>：CLIP
是一个多模态模型，可以理解图像和文本之间的关系，通过文本找到相关图像，或通过图像生成对应的文本描述。</li>
</ul>
<h3 id="智能体-vs-多模态-gpt区别与联系">3. <strong>智能体 vs 多模态
GPT：区别与联系</strong></h3>
<h4 id="区别"><strong>区别</strong></h4>
<ul>
<li><strong>核心功能</strong>：
<ul>
<li><strong>智能体</strong>：侧重于感知环境、决策与行动的闭环循环。智能体可以是物理的（如机器人），也可以是虚拟的（如自动化软件），并且通常需要与动态的环境进行交互。</li>
<li><strong>多模态
GPT</strong>：主要用于处理和生成多种模态的数据（如图像、文本），侧重于模态间的数据理解和生成。它并不具备自主的决策和行动能力。</li>
</ul></li>
<li><strong>任务性质</strong>：
<ul>
<li><strong>智能体</strong>：通常任务是交互性的，智能体在动态环境中持续工作，例如自动驾驶、游戏角色
AI、机器人执行任务等。智能体不仅需要感知，还需要执行行动。</li>
<li><strong>多模态
GPT</strong>：主要任务是生成式或理解式的。例如，生成图像、生成文本回答问题、或理解图文关系。它在一个静态输入的任务上更为强大，但并不在环境中主动采取行动。</li>
</ul></li>
<li><strong>学习机制</strong>：
<ul>
<li><strong>智能体</strong>：可能采用强化学习、进化算法等方法来在与环境的互动中学习最优策略。</li>
<li><strong>多模态
GPT</strong>：使用大规模预训练进行自监督学习，主要依赖于大量的跨模态数据进行学习。</li>
</ul></li>
</ul>
<h4 id="联系"><strong>联系</strong></h4>
<ul>
<li><p><strong>感知能力</strong>：虽然智能体和多模态 GPT
的主要目标不同，但两者都涉及感知能力。智能体可以使用多模态感知（如视觉、听觉），而多模态
GPT 直接处理多种模态的数据输入。未来的智能体可能会集成多模态 GPT
模型，使其在处理复杂多模态数据（如图像、文本）时更加智能。</p></li>
<li><p><strong>跨模态理解</strong>：多模态 GPT
可以为智能体提供更强大的理解和生成能力。例如，一个多模态 GPT
模型可以嵌入到智能体中，使其能够通过文本描述生成视觉信息（如在机器人视觉系统中辅助感知）或根据视觉信息生成文本描述（如在自动驾驶中生成自然语言报告）。</p></li>
<li><p><strong>语言生成</strong>：某些智能体，例如聊天机器人，可以使用多模态
GPT 的生成能力来与用户进行自然语言交互，提供图像或文本回答。</p></li>
</ul>
<h3 id="总结-1">总结</h3>
<ul>
<li><strong>智能体</strong>
是一个自主的实体，能够感知环境、决策和执行行动，强调的是行动循环和与环境的持续交互。</li>
<li><strong>多模态 GPT</strong>
是一个生成和理解多模态数据的语言模型，强调的是跨模态数据的处理和生成能力。</li>
</ul>
<p>设计一个 AI
智能体（Agent）是一个系统化的过程，涉及多个阶段，包括任务定义、感知环境、决策机制、行动执行和学习改进等。以下是详细的步骤来帮助设计一个
AI 智能体：</p>
<ul>
<li><strong>明确任务与目标</strong>：清楚智能体的作用和目标。</li>
<li><strong>感知模块</strong>：设计感知环境的方式，获取数据。</li>
<li><strong>决策模块</strong>：设计如何根据感知的数据做出决策，可以基于规则、规划、机器学习或强化学习。</li>
<li><strong>行为执行模块</strong>：设计如何执行智能体的决策。</li>
<li><strong>学习与优化</strong>：引入学习机制，让智能体能够根据经验或新数据不断改进。</li>
<li><strong>反馈与评估</strong>：持续评估智能体的表现，优化其任务执行效果。</li>
</ul>
<h2 id="为什么视觉上使用bntransformer上使用ln-几种-normalization-介绍">8.
为什么视觉上使用BN，transformer上使用LN ？几种 normalization 介绍。</h2>
<h2 id="overview-of-vision-language-models">9. Overview of
Vision-Language Models</h2>
<p>https://aman.ai/primers/ai/interview/</p>
<hr>
<h1 id="reference">Reference</h1>
<p><a target="_blank" rel="noopener" href="https://github.com/315386775/DeepLearing-Interview-Awesome-2024?tab=readme-ov-file">DeepLearing-Interview-Awesome-2024</a></p>
<p><a target="_blank" rel="noopener" href="https://oi-wiki.org/basic/radix-sort/">几种排序算法</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/zhengjingwei/machine-learning-interview?tab=readme-ov-file#1-1">machine-learning-interview</a></p>
<p><a target="_blank" rel="noopener" href="https://aman.ai/primers/ai/">Distilled AI</a></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://xueyu-ubc.github.io/2024/10/08/statistic/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/2024/09/12/multi_modalv2/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Blip, Blip2 (Q-former), InstructBlip, CONCH, PULSE</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "",
    app_key: "",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021-2024
        <i class="ri-heart-fill heart_icon"></i> Xue Yu
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Welcome to XueYu&#39;s Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2021/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i></p>
  <div class="reward-box">
    
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>
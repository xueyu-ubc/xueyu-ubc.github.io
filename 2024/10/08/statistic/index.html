<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="I am a second PhD student at Renmin University of China. My research interests include federated learning, high dimensional data, machine learning, and optimization. I am currently working on latent graph learning in Prof.Renjie Liao&#39;s group." />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Machine Learning |  Welcome to XueYu&#39;s Blog
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

<link rel="alternate" href="/atom.xml" title="Welcome to XueYu's Blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>

</html>
<script src="/js/hexo_resize_image.js"></script>
<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-statistic"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Machine Learning
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2024/10/08/statistic/" class="article-date">
  <time datetime="2024-10-08T02:10:10.000Z" itemprop="datePublished">2024-10-08</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">42.3k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">158 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="一机器学习相关">一、机器学习相关</h1>
<h2 id="基本概念">1、基本概念</h2>
<h3 id="排序"><a href="">1.1. 排序</a></h3>
<p><a href="">1. Why does sorting a collection have (at least) <span class="math inline">\(O(n log n)\)</span> complexity? n is the length of
the collection.</a></p>
<ul>
<li><span class="math inline">\(O(n log n)\)</span> is the optimal value
for a comparison sort.
[https://theartofmachinery.com/2019/01/05/sorting_is_nlogn.html].</li>
</ul>
<p><a href="">2. 几种排序算法介绍以及复杂度分析。</a></p>
<ul>
<li><p>排序有内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。</p></li>
<li><p>排序的稳定性是指：若待排序的序列中，存在多个具有相同元素，经过排序，
这些元素的相对次序保持不变，则称该算法是稳定的；若经排序后，元素的相对次序发生了改变，则称该算法是不稳定的。</p></li>
<li><p>常见的八种排序方法都属于内部排序，交换排序（冒泡排序、快速排序）、选择排序（简单选择排序、堆排序）、插入排序（直接插入排序、希尔排序）、归并排序、基数排序。
<img src="/2024/10/08/statistic/sort.jpg"></p></li>
<li><p>冒泡排序：两两比较待排序数据元素的大小，如果两个数据元素的次序相反时则进行交换，直到没有反序的数据元素未知。<strong>平均时间复杂度为
<span class="math inline">\(O(n^2)\)</span>，空间复杂度为 <span class="math inline">\(O(1)\)</span>，属于稳定排序。</strong></p></li>
<li><p>快速排序：
在当前无序区任取一个元素作为待比较的基准，用此基准将当前无序区划分为左右两个较小的无序区，其中左边无序子区的数据元素均小于等于基准元素，右边无序子区中的元素均大于等于基准元素，而基准则始终位于最终排序位置上。依次再对左右两个无序子区进行上述划分过程，直到所有无序子区中的元素都已排序为止。<strong>平均时间复杂度为
<span class="math inline">\(O(n \log_2 n)\)</span>，空间复杂度为 <span class="math inline">\(O(\log_2 n) - O(n)\)</span>
（可能退化为冒泡排序），属于不稳定算法。</strong></p></li>
<li><p>简单选择排序：每一趟从待排序的数据元素中选出最小（或最大）的一个元素，顺序放在已排好序的数列最后，直到全部待排序的数据元素排完。<strong>平均时间复杂度为
<span class="math inline">\(O(n^2)\)</span>，空间复杂度为<span class="math inline">\(O(1)\)</span>，属于稳定排序。</strong></p></li>
<li><p>堆排序：将数组看成是一棵完全二叉树的顺序存储结构，利用完全二叉树中的双亲结点和孩子结点之间的内在关系来选择最小的元素。小根堆：树中任一非叶子结点的值均小于等于其孩子结点的值（堆顶最小）；大根堆：树中任一非叶子结点的值均大于等于其孩子结点的值（堆顶最大）。<strong>平均时间复杂度为
<span class="math inline">\(O(n \log_2 n)\)</span>，空间复杂度为 <span class="math inline">\(O(1)\)</span>，属于不稳定排序。</strong></p></li>
<li><p>直接插入排序：每次将一个待排序的数据元素，插入到前面已经排好序的数列中的适当位置，使数列依然有序；直到待排序数据元素全部插入完为止。<strong>平均时间复杂度为
<span class="math inline">\(O(n^2)\)</span>，空间复杂度为 <span class="math inline">\(O(1)\)</span>，属于稳定排序。</strong></p></li>
<li><p>希尔排序：先取一个小于 n 的整数 <span class="math inline">\(d_1\)</span>
作为第一个增量，把所有元素分为若干组，所有下标距离为 <span class="math inline">\(d_1\)</span>
的倍数的元素放在同一组中。先在各组内进行直接插入排序。然后取第二个增量
<span class="math inline">\(d_2 &lt;
d_1\)</span>，按照原始位置下标，重复上述分组和排序，直到所取的增量 <span class="math inline">\(d_t =
1\)</span>，即所有元素都放在同一组中进行直接插入排序为止。<strong>平均时间复杂度为
<span class="math inline">\(O(n^{1.3}
)\)</span>，空间复杂度为O(1)，不稳排序。</strong></p></li>
<li><p>归并排序：归并排序最核心的部分是合并（merge）过程，将两个有序的数组
a 和 b 合并为一个有序数组 c。从左往右枚举 a[i] 和
b[j]，找出最小的值并放入数组 c[k]；重复上述过程直到 a 和 b
有一个为空时，将另一个数组剩下的元素放入
c。为保证排序的稳定性，前段首元素小于或等于后段首元素时（a[i] &lt;=
b[j]）而非小于时（a[i] &lt; b[j]）就要作为最小值放入
c[k]。<strong>平均时间复杂度为 <span class="math inline">\(O(n \log
n)\)</span>，空间复杂度为 <span class="math inline">\(O(1)\)</span>，稳定排序。</strong></p></li>
<li><p>基数排序：将待排序的元素拆分为 <span class="math inline">\(k\)</span> 个关键字，先对第 <span class="math inline">\(1\)</span>
关键字进行稳定排序，然后对于每组具有相同关键字的元素 再对第 <span class="math inline">\(2\)</span>
关键字进行稳定排序（递归执行）。最后对于每组 具有相同关键字的元素 再对第
<span class="math inline">\(k\)</span>
关键字进行稳定排序。如果对自然数进行比较，将自然数按个位对齐后往高位补齐
<span class="math inline">\(0\)</span>，则一个数字从左往右数第 <span class="math inline">\(i\)</span> 位数就可以作为第 <span class="math inline">\(i\)</span> 关键字。<strong>设数据量为<span class="math inline">\(n\)</span>, 数据为<span class="math inline">\(d\)</span>进制, 最大位数为 <span class="math inline">\(k\)</span>, 则对某一位执行计数排序使用<span class="math inline">\(O(n+d)\)</span>时间，排序所有 <span class="math inline">\(k\)</span> 位使用<span class="math inline">\(O((n
+ d) \times k)\)</span> 时间。空间复杂度为 <span class="math inline">\(O(n + d)\)</span>,
非原地排序。如果对内层关键字的排序是稳定的，则基数排序是稳定的排序算法。</strong></p></li>
</ul>
<h3 id="二分查找"><a href="">1.2. 二分查找</a></h3>
<p>以在一个升序数组中查找一个数为例。它每次考察数组当前部分的中间元素，如果中间元素刚好是要找的，就结束搜索过程；如果中间元素小于所查找的值，那么左侧的只会更小，不会有所查找的元素，只需到右侧查找；如果中间元素大于所查找的值同理，只需到左侧查找。</p>
<p>二分查找的最优时间复杂度为 <span class="math inline">\(O(1)\)</span>。二分查找的平均时间复杂度和最坏时间复杂度均为
<span class="math inline">\(O(\log
n)\)</span>。因为在二分搜索过程中，算法每次都把查询的区间减半，所以对于一个长度为
<span class="math inline">\(n\)</span> 的数组，至多会进行 <span class="math inline">\(O(\log n)\)</span> 次查找。</p>
<p>迭代版本的二分查找的空间复杂度为 <span class="math inline">\(O(1)\)</span>。</p>
<h3 id="回归模型和分类模型常用损失函数有哪些"><a href="">1.3.
回归模型和分类模型常用损失函数有哪些？</a></h3>
<p><strong>回归模型常用的损失函数</strong></p>
<ol type="1">
<li><p>0-1损失函数： <span class="math display">\[
L(\hat{y},y) =
\begin{cases}
  1,
&amp;
y \neq \hat{y} \\
0,
&amp;
y = \hat{y}
\end{cases}
  \]</span></p></li>
<li><p>平均绝对误差MAE：异常点多的情况下鲁棒性更强，不像MSE那样过度惩罚大误差；但不方便求导
<span class="math display">\[
L(\hat{y}, y) = \frac{1}{n} \sum_{i=1}^{n}|y_i - \hat{y}_i|.
\]</span></p></li>
<li><p>均方误差MSE：求导方便，能够用梯度下降法优化；对异常值敏感，异常值的存在会导致MSE值急剧增大，从而影响模型效果。
<span class="math display">\[
L(\hat{y},y) = \frac{1}{n} \sum_{i=1}^{n}(y_i - \hat{y}_i)^2.
\]</span></p></li>
<li><p>对数损失函数/对数似然损失函数： <span class="math display">\[
L(P(Y|X),Y) = -{\rm log} P(Y|X)
\]</span></p></li>
<li><p>Huber
损失函数：结合了MAE和MSE的优点，对异常值更加鲁棒，比MSE对大的误差的惩罚更加温和；在误差较小时仍然能够提供与MSE类似的梯度更新；缺点是需要调整超参数
<span class="math inline">\(\delta\)</span> <span class="math display">\[
L_{Huber}(\hat{y}, y) =
\begin{cases}
(\hat{y}-y)^2
&amp;
|\hat{y}-y| \leq \delta
\\
2 \delta |\hat{y}-y| - \delta^2
&amp;
|\hat{y}-y| &gt; \delta
\end{cases}
\]</span></p></li>
<li><p>对数余弦 Log-Cosh
损失函数：近似于MSE，但对大误差的惩罚更温和，兼顾了MSE和MAE的优点。同时二阶处处可微（牛顿法要求二阶可微），更加平滑且容易优化。但是，不如MSE那样简单直观，在某些应用中表现不如MSE。
<span class="math display">\[
L(\hat{y},y) = \log \cosh(\hat{y}-y)
\]</span></p></li>
</ol>
<p><strong>分类模型中常用的损失函数</strong> 1.
交叉熵损失。对于二元分类，公式为如下。其中，<span class="math inline">\(y\)</span>是真实标签，<span class="math inline">\(p\)</span>是模型预测的概率。 <span class="math display">\[
  L(p,y) = -[y \log p + (1-y) \log (1-p)].
  \]</span></p>
<ul>
<li>优点：直接衡量模型预测的概率与真实分类标签之间的差异，适合分类任务。对概率差异敏感，能够较好地区分高概率和低概率的预测。</li>
<li>缺点：当预测的概率非常接近0或1时，交叉熵的梯度可能变得极端，导致训练不稳定。对于不平衡数据，模型倾向于偏向多数类，需要配合其他技术如加权损失函数或欠采样来处理。</li>
</ul>
<ol start="2" type="1">
<li>Hinge loss。通常用于支持向量机，公式如下。<span class="math inline">\(y \in {-1,1}\)</span>是真实标签，<span class="math inline">\(f(x)\)</span>是模型输出。 <span class="math display">\[
  L(f(x),y) = \max(0, 1 - y \times f(x))
  \]</span></li>
</ol>
<ul>
<li>优点：强调分类边界的最大化，适用于SVM；对小的误差不敏感，能够防止过拟合。</li>
<li>缺点：不适用于概率输出的分类模型。仅适用于二分类问题，多分类任务中扩展性较差。</li>
</ul>
<ol start="3" type="1">
<li>Kullback-Leibler 散度。假设<span class="math inline">\(p(x)\)</span>是真实分布，<span class="math inline">\(q\)</span>是模型预测的概率分布，公式如下： <span class="math display">\[
  D_{\text{KL}}(p||q) = \sum p(x) \log(\frac{p(x)}{q(x)}),
  \]</span></li>
</ol>
<ul>
<li>优点：可以量化两个分布之间的差异，适合概率模型；</li>
<li>缺点：对极端概率值（接近于1或0）的预测非常敏感，可能导致数值不稳定。</li>
</ul>
<h3 id="什么是结构误差和经验误差"><a href="">1.4.
什么是结构误差和经验误差？</a></h3>
<p>经验风险（经验损失）：模型 <span class="math inline">\(f(X)\)</span>关于训练数据集的平均损失 <span class="math display">\[
R_{\rm emp}(f) = \frac{1}{N} \sum_{i=1}^N L(y_i,f(x_i)).
\]</span></p>
<p>结构风险：是在经验风险上加上表示模型复杂度的正则化项 <span class="math display">\[
R_{\rm srm}(f) = \frac{1}{N} \sum_{i=1}^{N}L(y_i,f(x_i))+\lambda J(f).
\]</span></p>
<p>经验风险最小化的策略认为，经验风险最小的模型是最优的模型。</p>
<p>结构风险最小化是为了防止过拟合而提出的，结构风险最小化等价于正则化。结构风险最小化的策略认为结构风险最小的模型是最优的模型。</p>
<h3 id="如何选择合适的模型评估指标rocauc精准度召回率f1值"><a href="#1-6">1.5.
如何选择合适的模型评估指标？ROC、AUC、精准度、召回率、F1值</a></h3>
<p>模型评估指标用于衡量机器学习模型在测试集或验证集上的表现，帮助评估其性能。</p>
<p>混淆矩阵，又称误差矩阵，就是分别统计分类模型归错类，归对类的观测值个数，然后把结果放在一个表里展示出来。这个表就是混淆矩阵。</p>
<p>混淆矩阵是ROC曲线绘制的基础，同时它也是衡量分类型模型准确度中最基本，最直观，计算最简单的方法。</p>
<table>
<thead>
<tr>
<th style="text-align: center;">混淆矩阵</th>
<th style="text-align: center;">预测结果</th>
<th style="text-align: center;">预测结果</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">真实情况</td>
<td style="text-align: center;">反例</td>
<td style="text-align: center;">正例</td>
</tr>
<tr>
<td style="text-align: center;">反例</td>
<td style="text-align: center;">TN（真反例）</td>
<td style="text-align: center;">FP（假正例）</td>
</tr>
<tr>
<td style="text-align: center;">正例</td>
<td style="text-align: center;">FN（假反例）</td>
<td style="text-align: center;">TP（真正例）</td>
</tr>
</tbody>
</table>
<ul>
<li>TN：True Negative，将样本中的负类样本预测为负类的数量</li>
<li>FP：False Positive，将样本中的负类样本预测为正类的数量</li>
<li>FN：False Negative，将样本中的正类样本预测为负类的数量</li>
<li>TP：True Positive，将样本中的正类样本预测为正类的数量</li>
</ul>
<p><strong>分类任务指标</strong></p>
<p><strong>Accuracy</strong>（准确率）：分类正确的样本占总样本个数的比例
<span class="math display">\[
Accuracy = \frac{n_{correct}}{n_{total}}
\]</span> -
缺点：不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。比如，当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。
-
解决：可以使用每个类别下的样本准确率的算术平均（平均准确率）作为模型评估的指标。</p>
<p><strong>Precision</strong>（精确率）：分类正确的正样本个数占分类器判定为正样本的样本个数的比例
<span class="math display">\[
Precision = \frac{TP}{TP+FP}
\]</span>
<strong>Recall</strong>（召回率）：分类正确的正样本数占真正的正样本个数的比例
<span class="math display">\[
Recall = \frac{TP}{TP+FN}
\]</span>
<strong>F1-score</strong>：precision和recall的调和平均值；当精确率和召回率都高时，F1值也会高；特别适用于类别不平衡的数据集。
<span class="math display">\[
{\rm F1} = \frac{2 \times precision \times recall}{precision + recall}
\]</span></p>
<p>在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用Top
N返回结果的Precision和Recall值来衡量排序模型的性能。即认为模型返回的Top
N结果就是模型判定的正样本，计算前N个位置的Precision@N和Recall<span class="citation" data-cites="N">@N</span>。为了综合评估一个排序模型的好坏，不仅要看模型在不同Top
N下的Precision@N和Recall<span class="citation" data-cites="N">@N</span>，而且最好画出模型的P-R曲线。P-R曲线的横轴是Recall，纵轴是Precision。</p>
<p><strong>ROC</strong>：横坐标为假阳性率（False Positive
Rate，FPR）；纵坐标为真阳性率（True Positive Rate，TPR） <span class="math display">\[
FPR = \frac{FP}{N}, \quad
TPR = \frac{TP}{P},
\]</span>
其中，P是真实的正样本的数量，N是真实的负样本的数量，TP是P个正样本中被分类器预测为正样本的个数，FP是N个负样本中被预测为正样本的个数。</p>
<p><strong>如何绘制ROC曲线</strong></p>
<p>通过不断移动分类器的“截断点”来生成曲线上的一组关键点。在二分类问题中，模型输出一般是预测样本为正例的概率，在输出最终的正例负例之前，我们需要制定一个阈值。大于该阈值的样本判定为正例，小于该阈值的样本判定为负例。通过动态调整截断点，绘制每个截断点对应位置，再连接所有点得到最终的ROC曲线。
比如，阈值为0时，此时所有样本被预测为负例，TPR = 0, FPR =
0；当阈值增加为1时，此时所有样本被预测为正例，TPR = 1, FPR = 1.</p>
<p><strong>一般情况下，PR曲线易受样本数量的影响，样本数量不均衡情况下PR曲线会有明显变化，故一般使用ROC曲线。</strong></p>
<p><strong>AUC</strong>：ROC曲线下的面积大小。计算AUC值只要沿着ROC横轴做积分就可以。AUC取值在0.0~1之间。AUC越大，分类性能越好。AUC表示预测的正例排在负例前面的概率。</p>
<p>指标想表达的含义，简单来说其实就是随机抽出一对样本（一个正样本，一个负样本），然后用训练得到的分类器来对这两个样本进行预测，预测得到正样本的概率大于负样本概率的概率。AUC为0.5表明对正例和负例没有区分能力，对于不论真实类别是1还是0，分类器预测为1的概率是相等的。</p>
<p>我们希望分类器达到的效果：对于真实类别为1的样本，分类器预测为1的概率（TPR）要大于真实类别为0而预测类别为1的概率（FPR），即y&gt;x</p>
<p>AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。</p>
<p><strong>回归任务指标</strong></p>
<p><strong>均方根误差RMSE</strong>：计算预测值和实际值的平均误差 <span class="math display">\[
{\rm RMSE} = \sqrt{\frac{\sum_{i=1}^n (y_i-\hat{y}_i)^2}{n}}
\]</span> <strong>均方误差MSE</strong></p>
<p><strong>平均绝对误差MAE</strong></p>
<p><strong>决定系数 <span class="math inline">\(R^2\)</span></strong>：表示模型解释变量总方差的比例，反映了模型拟合的好坏。</p>
<p>SST: sum of squares total，总的偏差平方和，表示变量<span class="math inline">\(y\)</span>相对于中心<span class="math inline">\(\bar{y}\)</span>的异动。 <span class="math display">\[
SST = \sum_{i=1}^n (y_i - \bar{y}_i)^2.
\]</span></p>
<p>SSR: sum of squares regression, 回归平方和，表示估计值 <span class="math inline">\(\hat{y}\)</span>相对于中心 <span class="math inline">\(\bar{y}\)</span>的异动。</p>
<p><span class="math display">\[
SSR = \sum_{i=1}^{n} (\hat{y}_i - \bar{y}_i)^2.
\]</span></p>
<p>SSE: sum of squares error,
残差平方和，表示拟合数据和原始数据之间的误差的平方和。 <span class="math display">\[
SSE = \sum_{i=1}^n(y_i - \hat{y}_i)^2.
\]</span></p>
<p><span class="math display">\[
R^2 = 1 - \frac{\sum_{i=1}^n(y_i - \hat{y}_i)^2}{\sum_{i=1}^n(y_i -
\bar{y})^2} = 1 - \frac{SSE}{SSR}.
\]</span></p>
<p>决定系数<span class="math inline">\(R^2\)</span>的取值范围为<span class="math inline">\([0,1]\)</span>，0表示没有线性关系，1表示拟合模型可以解释所有变异y。</p>
<p><strong>调整的决定系数 <span class="math inline">\(\bar{R}^2\)</span></strong>：对于决定系数 <span class="math inline">\(R^2\)</span>，当解释变量个数增加（即模型复杂度提高，偏差降低）时，<span class="math inline">\(R^2\)</span>
会不断增加。但是，随着模型复杂度的提高，方差可能会越来越大。因此，引入了调整的决定系数<span class="math inline">\(\bar{R}^2\)</span>： <span class="math display">\[
\bar{R}^2 = 1 - \frac{SSE/df_{err}}{SSR/df_{tot}} = 1 - （1 - R^2)
\times \frac{n-1}{n-p-1},
\]</span> 其中，df_{err} 表示残差平方和的自由度，为<span class="math inline">\(n-p-1\)</span>，df_{tot}
表示关于总平方和的自由度，为 <span class="math inline">\(n-1\)</span>。</p>
<p>调整后的 <span class="math inline">\(\bar{R}^2\)</span>
可以是负值，其值总是小于或等于 <span class="math inline">\({R}^2\)</span>。当引入更多解释变量时，决定系数<span class="math inline">\({R}^2\)</span>会增加，导致<span class="math inline">\(\bar{R}^2\)</span>的增加。但是后面的分数项会降低<span class="math inline">\(\bar{R}^2\)</span>。只有当减少的偏差大于引入的方差时，<span class="math inline">\(\bar{R}^2\)</span>才会增加。因此，<span class="math inline">\(\bar{R}^2\)</span> 可以看作是对
bias-variance间的tradeoff.</p>
<p><strong>平均绝对百分比误差</strong>：（Mean Absolute Percentage
Error, MAPE），MAPE表示预测误差相对于真实值的百分比。 <span class="math display">\[
MAPE = \frac{1}{n}\sum_{1}^{n} |\frac{y_i - \hat{y}_i}{y_i}| \times
100\%.
\]</span>
优点：易于解释，特别适用于需要对误差进行相对度量的场景。缺点：当真实值接近0时，MAPE会变得不稳定。</p>
<h3 id="bias-variance-trade-off模型过拟合欠拟合"><a href="">1.6.
Bias-variance trade-off，模型过拟合、欠拟合</a></h3>
<p><img src="/2024/10/08/statistic/bias_variance.jpg"></p>
<p><strong>误差分析</strong>：通过训练误差和测试误差来分析模型是否存在高方差、高偏差。</p>
<ul>
<li>如果训练误差较高：说明模型的偏差较大，模型出现了欠拟合。</li>
<li>如果训练误差较低，而测试误差较高：说明模型的方差较大，出现了过拟合。</li>
<li>如果训练误差较低，测试误差也较低：说明模型的方差和偏差都适中，是一个比较理想的模型。</li>
<li>如果训练误差较高，且测试误差更高：说明模型的方差和偏差都较大。</li>
</ul>
<p>上述分析的前提是：训练集、测试集的数据来自于同一个分布，且最优误差较小。否则讨论更复杂。</p>
<p><strong>欠拟合</strong>：模型过于简单，没有很好地学习到数据间的关系，训练集效果差。<strong>模型复杂度低，此时模型预测的方差较小，表示预测较稳定。但是模型预测的偏差会较大，表示预测不准确。。</strong></p>
<p><strong>过拟合</strong>：指学习时选择的模型所包含的参数过多，以至出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。训练集效果好，测试集效果差。
<strong>模型复杂度高，此时模型预测的方差大，偏差小。</strong></p>
<p><strong>欠拟合解决方法：</strong> 1. 增加特征 2.
提高模型复杂度：神经网络提高神经元数、增加层数；SVM使用核函数； 3.
减小正则项的系数</p>
<p><strong>过拟合解决方法：</strong> 1. 提高样本数量。神经网络：Data
Augmentation（数据增强） 2. 简化模型。神经网络使用 Dropout、Early
Stopping；决策树剪枝、限制树的深度。 3.
加入正则化项（L1或L2）或提高惩罚系数 4. 使用集成学习 5.
神经网络中使用dropout机制 6. early stopping</p>
<h3 id="奥卡姆剃刀定律是什么对机器学习模型优化有何启发"><a href="">1.7.
奥卡姆剃刀定律是什么？对机器学习模型优化有何启发？</a></h3>
<p>奥卡姆剃刀定律：若有多个假设与观察一致，则选最简单的那个。</p>
<p>奥卡姆剃刀原理应用于模型选择时变为以下想法：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的，也就是应该选择的模型。</p>
<p>从贝叶斯估计的角度来看，正则化项对应于模型的先验概率。可以假设复杂的模型有较小的先验概率，简单的模型有较大的先验概率。</p>
<h3 id="线性模型-vs.-非线性模型-生成式模型-vs.-判别式模型-概率模型-vs.-非概率模型-参数化模型-vs.-非参数化模型"><a href="">1.8. 线性模型 vs. 非线性模型， 生成式模型 vs. 判别式模型，
概率模型 vs. 非概率模型， 参数化模型 vs. 非参数化模型</a></h3>
<p><strong>线性模型 vs. 非线性模型</strong></p>
<p>非概率模型可以分为线性模型和非线性模型。如果函数 <span class="math inline">\(y=f(x)\)</span> 或 <span class="math inline">\(z =
g(x)\)</span>
是线性函数，则称模型是线性模型，否则成模型为非线性模型。</p>
<p>线性模型：感知机、线性支持向量机、k近邻、k均值、潜在语义分析</p>
<p>非线性模型：核函数支持向量机、AdaBoost，神经网络</p>
<p><strong>生成式模型 vs. 判别式模型</strong></p>
<p>监督学习方法分为生成方法（generative
approach）和判别方法（discriminative
approach）。所学习到的模型分别称为生成模型和判别模型。监督学习的模型一般形式为决策函数：<span class="math inline">\(Y = f(X)\)</span> 或者条件概率分布 <span class="math inline">\(P(Y|X)\)</span>。</p>
<p>生成方法：由数据学习联合概率分布 <span class="math inline">\(P(X,Y)\)</span>，然后求出条件概率分布 <span class="math inline">\(P(Y|X)\)</span>作为预测模型： <span class="math display">\[
P(Y|X) = \frac{P(X,Y)}{P(X)}
\]</span> 之所以叫做生成方法，是因为模型表示了给定输入 <span class="math inline">\(X\)</span> 产生输出 <span class="math inline">\(Y\)</span>的生成关系。典型的生成模型：朴素贝叶斯法、隐马尔可夫模型。</p>
<p>判别方法：由数据直接学习决策函数 <span class="math inline">\(f(X)\)</span> 或者条件概率分布 <span class="math inline">\(P(X,Y)\)</span>作为预测的模型，关心的是对给定的输入
<span class="math inline">\(X\)</span>，应该预测什么样的输出 <span class="math inline">\(Y\)</span>。典型的判别模型：k近邻、感知机、决策树、逻辑斯蒂回归、最大熵模型、支持向量机、提升方法、条件随机场。</p>
<p><strong>概率模型 vs. 非概率模型</strong></p>
<p>概率模型与非概率模型的区别在于模型的内在结构。<strong>概率模型一定可以表示为联合概率分布的形式</strong>，其中的变量表示输入、输出、因变量甚至参数。而针对非概率模型则不一定存在这样的联合概率分布。</p>
<p>统计学习的模型可以分为概率模型（probabilistic
model）和非概率模型（non-probabilistic
model）或者确定性模型（deterministic
model）。在监督学习中，概率模型取条件概率分布形式 <span class="math inline">\(p(y|x)\)</span>，非概率模型取函数形式 <span class="math inline">\(y=f(x)\)</span>，其中<span class="math inline">\(x\)</span>是输入，<span class="math inline">\(y\)</span>是输出。在无监督学习中，概率模型取条件概率分布形式
<span class="math inline">\(p(z|x)\)</span>或 <span class="math inline">\(p(x|z)\)</span>，其中<span class="math inline">\(x\)</span>是输入，<span class="math inline">\(z\)</span>是输出。在监督学习中，概率模型是生成模型，非概率模型是判别模型。</p>
<p>概率模型：决策树、朴素贝叶斯、隐马尔可夫模型、条件随机场、概率潜在语义分析、潜在狄利克雷分布、高斯混合模型</p>
<p>非概率模型：感知机、支持向量机、k近邻、AdaBoost、k均值、潜在语义分析、神经网络</p>
<p>逻辑斯蒂回归即可看做概率模型，又可看做非概率模型。</p>
<p><strong>参数化模型 vs. 非参数化模型</strong></p>
<p>统计学习模型又可以分为参数化模型（parametric
model）和非参数化模型（non-parametric
model）。参数化模型假设模型参数的维度固定，模型可以由有限维参数完全刻画；非参数模型假设模型参数的维度不固定或者说无穷大，随着训练数据量的增加而不断增大。</p>
<p>参数化模型：感知机、朴素贝叶斯、逻辑斯蒂回归、k均值、高斯混合模型</p>
<p>非参数化模型：决策树、支持向量机、AdaBoost、k近邻、潜在语义分析、概率潜在语义分析、潜在狄利克雷分配</p>
<h3 id="缺失值如何处理"><a href="">1.9. 缺失值如何处理？</a></h3>
<ol type="1">
<li>缺失值较多.直接将该特征舍弃掉，否则可能反倒会带入较大的噪声，对结果造成不良影响。</li>
<li>缺失值较少,其余的特征缺失值都在10%以内，我们可以采取很多的方式来处理:（1）把NaN直接作为一个特征，假设用0表示；（离散特征取值k维扩充到k+1维）（2）用均值填充；（连续特征-均值，离散特征-特征取值的众数）（3）用随机森林等算法预测填充。</li>
</ol>
<h3 id="标准化归一化介绍"><a href="#2-2">1.10.
标准化、归一化介绍</a></h3>
<p>为了消除数据特征之间的量纲影响，我们需要对特征进行归一化/标准化处理，使得不同指标之间具有可比性。以梯度下降过程为例，如果不做归一化/标准化处理，在学习速率相同的情况下，大量纲变量的更新速度会大于小量纲，需要较多迭代才能找到最优解。如果将其变换到相同的数值区间后，更新速度变得更为一致，容易更快地通过梯度下降找到最优解。</p>
<p><strong>1. 归一化（Min-Max
Scaling）</strong>：将数据缩放到一个特定的范围（通常是 [0, 1] 或 [-1,
1]）。它的核心思想是通过线性变换，将数据映射到指定区间中。 <span class="math display">\[
  X_{norm} = \frac{X-X_{min}}{X_{max}-X_{min}}
\]</span>
用于输入范围已知的模型（如神经网络），或者需要对距离敏感的算法（如
KNN）。不适用于有异常值的数据，例如有异常大的数值，其他数据会被压缩到很小的数值。</p>
<p><strong>2. 标准化（Z-score
Normalization）</strong>：是将数据进行中心化和缩放处理，使得数据的均值为
0，标准差为
1。这是通过减去数据的均值再除以数据的标准差来实现的，也叫Z-score
标准化。假设原始特征的均值为 <span class="math inline">\(\mu\)</span>，方差为 <span class="math inline">\(\sigma\)</span> ，那么标准化公式定义为 <span class="math display">\[
  z = \frac{x-\mu}{\sigma}.
  \]</span>
适用于数据服从高斯分布（正态分布）或在模型中需要假设数据是标准正态分布的情况，尤其在一些线性模型（如线性回归、逻辑回归、支持向量机）和PCA等算法中较为常用。</p>
<p><strong>3.
对比分析</strong>：归一化可以保持原数据的形状和分布，仅改变其取值范围，因此不会改变数据的分布类型（例如正态分布仍是正态分布）。标准化会改变了数据的中心和尺度，将数据转化为标准正态分布，因此数据的分布会被改变。</p>
<h3 id="l1和l2正则为什么l1比l2更容易产生稀疏解"><a href="">1.11.
L1和L2正则，为什么L1比L2更容易产生稀疏解</a></h3>
<p>L1和L2正则，都可以防止过拟合，增强模型的泛化能力；区别在于L1使参数更稀疏，达到特征选取的作用；L2使参数更接近于0.</p>
<p><img src="/2024/10/08/statistic/l1_l2.jpeg"></p>
<p><strong>从解空间的形状来看：</strong>
L1正则项约束后的解空间是多边形，而L2正则项约束后的解空间是圆形。而多边形的解空间更容易在尖角处与等高线碰撞出稀疏解。图中红色等高线表示不同正则参数下的残差平方和，椭圆中心点为最小二乘估计。绿色区域分别表示使用
<span class="math inline">\(l_1\)</span> 正则函数和<span class="math inline">\(l_2\)</span>正则函数对应的约束域。等高线与约束域的切点表示目标函数的最优解。从图中可以看出，当使用<span class="math inline">\(l_1\)</span>
正则函数时，最优解有可能为稀疏解。</p>
<p><strong>从函数叠加的观点：</strong>
L2正则化使得权重衰减，降低模型复杂度，避免模型过拟合问题。（1）通过限制权重的大小，L2
正则化可以让模型更为“平滑”，即更关注输入特征的整体趋势而不是单个特征的微小变化。这降低了模型过度拟合训练数据中的噪声。（2）权重较小的模型通常更具泛化性，因为它们对数据中偶然的扰动（噪声）不太敏感。权重减小后，模型在验证集或测试集上也会有更好的表现。</p>
<h2 id="经典机器学习算法">2、经典机器学习算法</h2>
<h3 id="线性回归和逻辑回归">线性回归和逻辑回归</h3>
<h4 id="线性回归">线性回归</h4>
<p>线性回归的五个基本假设条件： 1.
自变量（解释变量）与因变量（响应变量）之间为线性关系。 2.
自变量之间相互独立，无多重共线性。如果存在多重共线性，就很难确定每个预测因子的单独影响。可以通过计算皮尔逊相关系数，或者方差膨胀因子系数（VIF)进行检验。
3.
误差项之间相互独立，不存在自相关性。尤其是对时间序列数据尤为重要。可以使用DW检验。如果存在自相关性，可以采取自回归模型。
4.
误差项与自变量之间相互独立，无内生性。这一假设可确保自变量真正独立于误差项，且不会产生遗漏变量偏差。可以使用工具变量法等进行检验和处理。
5.
误差项应该呈正态分布，期望为0，方差为定值。这两个假设是为了保证回归模型在小样本下能够顺利进行假设检验，在进行假设检验（如计算
p
值或置信区间）时尤为重要。可以使用Q-Q图可视化来检验是否满足正态分布，Q-Q图趋近于落在一条直线上，说明残差满足正态分布。如果误差项的方差不是恒值（可以通过可视化残差观察到），那么存在异方差性，可以使用加权回归、稳健回归等方法解决。</p>
<p><strong>关于内生变量和外生变量</strong>：与干扰项（误差项）相关的变量称为内生变量(endogenous
variable)；与干扰项不相关的变量称为外生变量(exogenous
variable)。对于线性回归模型，自变量会对因变量产生影响，干扰项也会对因变量产生影响，且干扰项与自变量假设无关。那么此时，自变量就是外生变量，因变量是内生变量。但是有时，可能由于某种原因，干扰项也会对因变量产生一定影响，此时干扰项和因变量相关，出现内生性。主要原因有遗漏变量、双向因果和测量误差等导致无法满足第四条假设。</p>
<p>线性回归模型： <span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ...+ \beta_p x_p + \epsilon.
\]</span> 通过最小化残差平方和SSE来进行求解。最小二乘解为： <span class="math display">\[
\hat{\beta} = (X^T X)^{-1}X^T y.
\]</span></p>
<p><strong>模型评估</strong>： MSE 和 决定系数 <span class="math inline">\(R^2\)</span>。二者的具体定义可见section 1.5。</p>
<ul>
<li>线性假设指的是模型参数的线性，而不一定是原始数据的线性。可以引入变换或非线性特征（如交叉项
<span class="math inline">\(x_1 \times x_2\)</span>、多项式项 <span class="math inline">\(x_1^2\)</span>），只要因变量与参数之间的关系保持线性即可。此时加入非线性特征（如交叉特征或多项式项）并不违反线性回归的假设，因为模型的参数仍然是
"线性的"。</li>
</ul>
<p><strong>多重共线性</strong></p>
<p>当线性回归模型中的两个或多个自变量高度相关，导致信息重叠或冗余时，就会产生多重共线性。在这种情况下，模型很难分离出每个自变量对因变量的单独影响，从而导致不可靠的系数估计、标准误差膨胀以及解释上的挑战。</p>
<p>如何检测和解决多重共线性问题？ 1. 方差膨胀因子 (VIF)：VIF
是一种常见的诊断工具，用于衡量回归系数的方差因多重共线性而膨胀的程度。VIF
超过 5 或 10 表示多重共线性很高。 2.
相关矩阵：检查自变量的相关矩阵可以发现高度相关的变量对（相关性接近 1
或-1）。这表明存在潜在的多重共线性。 3.
放弃其中一个相关变量：如果两个或多个变量高度相关，可考虑放弃其中一个变量。这可以简化模型并减少多重共线性。
4. 主成分分析（PCA）：PCA
可以将相关变量转化为一组不相关的成分，用于回归分析。这可以降低数据维度，避免多重共线性。
5.
岭回归或lasso回归：这些正则化技术有助于减轻多重共线性的影响。岭回归会对系数的大小进行惩罚，从而降低系数对多重共线性的敏感性（不具备变量筛选的能力，无法完全解决）。lasso回归则更进一步，可以将某些系数缩减为零，从而有效地选择预测因子的子集。</p>
<h4 id="逻辑回归">逻辑回归</h4>
<p>逻辑回归是一种广泛用于二元分类任务的监督学习算法。在机器学习中，监督学习包括对输入输出对进行模型训练，以学习能够预测未见数据的模式。逻辑回归专门预测基于输入特征的分类结果的概率，其中结果属于两个类别之一。虽然逻辑回归可以扩展到多个类别，但其最常见的应用还是二元分类。</p>
<p>逻辑回归模型： <span class="math display">\[
p(y = 1 | x) = sigmoid(z) = \frac{1}{1 + e^{-z}}, z = {\beta}_0 +
{\beta}_1 x_1 + ...+ {\beta}_k x_k.
\]</span></p>
<p><strong>模型评估</strong></p>
<p>逻辑回归模型使用损失函数进行评估，该函数用于衡量模型预测真实结果的能力。对于二元分类，合适的损失函数是
Log-Loss（也称为二元交叉熵）。对于有 <span class="math inline">\(n\)</span> 个样本的给定数据集，Log-Loss 的定义为:
<span class="math display">\[
Log-loss = - \sum_{i=1}^{n} [y_i \log p_i + (1-y_i)\log (1-p_i)],
\]</span> 其中，<span class="math inline">\(y_i\)</span> 为第<span class="math inline">\(i\)</span>个样本的真实标签，<span class="math inline">\(p_i\)</span> 为第<span class="math inline">\(i\)</span>个样本的输出概率。</p>
<p><strong>系数估计算法</strong></p>
<p>有两种主流的方式去估计模型的参数 <span class="math inline">\({\beta}\)</span>，（1）梯度下降；（2）最大似然估计（MLE).</p>
<p>最大似然估计：对于逻辑回归，定义函数 <span class="math inline">\(h_{\beta}(x) = \frac{1}{1 +
e^{-z}}\)</span>，其似然函数为所有样本观测值出现概率的乘积，可以表示为：
<span class="math display">\[
L(\beta) = \prod_{i=1}^{n} [h_{\beta}(x_i)]^{y_i}[1 -
h_{\beta}(x_i)]^{(1-y_i)}.
\]</span>
最大化该似然函数，通常会转化为最大化其对数似然，然后用梯度下降法求解。对数似然函数为：
<span class="math display">\[
\log L(\beta) = \sum_{i=1}^{n} [y_i \log h_{\beta}(x_i)+(1-y_i)\log(1 -
h_{\beta}(x_i))].
\]</span> 显然，最大化对数似然等价于最小化log-loss。</p>
<p><strong>多标签分类</strong>：假设每个样本属于不同标签的概率服从几何分布，可以使用softmax
regression进行分类： $$ h_= = </p>
<p></p>
<p> $$ 其中 <span class="math inline">\(\theta_1,\theta_2 \dots,\theta_k
\in \mathbb{R}^n\)</span></p>
<p>如果存在样本可能属于多个标签的情况时，可以训练k个二分类的逻辑回归分类器。第i个分类器用以区分每个样本是否可以归为第i类。</p>
<h4 id="二者之间的联系">二者之间的联系</h4>
<p>如果把一个事件的几率（odds）定义为该事件发生的概率与不发生概率的比值
<span class="math inline">\(\frac{p}{1-p}\)</span>
，那么逻辑回归可以看做是对于"y=1|x"这一事件的对数几率的线性回归 <span class="math display">\[
{\rm log} \frac{p}{1-p} = \theta^{T}x ，其中\ p  = P(y=1|x).
\]</span></p>
<h3 id="knn">KNN</h3>
<p><strong>建模流程</strong></p>
<p>（1）根据给定的距离度量，在训练集 <span class="math inline">\(T\)</span> 中找出与 <span class="math inline">\(x\)</span> 最邻近的 <span class="math inline">\(k\)</span>个点，涵盖这 <span class="math inline">\(k\)</span> 个点的邻域记作 <span class="math inline">\(N_k(x)\)</span>；</p>
<p>（2）在<span class="math inline">\(N_k(x)\)</span>中根据分类决策规则（如多数表决）决定
<span class="math inline">\(x\)</span> 的类别 <span class="math inline">\(y\)</span>： <span class="math display">\[
y=\arg \max _{c_{j}} \sum_{x_{i} \in N_{k}(x)}
I\left(y_{i}=c_{j}\right), \quad i=1,2, \cdots, N_{i} \quad j=1,2,
\cdots, K
\]</span> 在上式中，<span class="math inline">\(I\)</span>为指示函数，即当<span class="math inline">\(y_{i}=c_{j}\)</span>时为1，否则为0.</p>
<p><strong>knn优点：</strong></p>
<ol type="1">
<li><p>理论成熟，思想简单，既可以用来做分类又可以做回归</p></li>
<li><p>KNN是一种在线技术，新数据可以直接加入数据集而不必进行重新训练</p></li>
<li><p>可用于非线性分类（数据集不要求线性可分）</p></li>
<li><p>和朴素贝叶斯之类的算法比，对数据没有假设，准确度高，对异常点不敏感</p></li>
</ol>
<p><strong>knn缺点：</strong></p>
<ol type="1">
<li>计算量大，尤其是数据集非常大的时候</li>
<li>样本不平衡的时候，对稀有类别的预测准确率低</li>
<li>KD树，球树之类的模型建立需要大量的内存</li>
<li>k值大小的选择很重要</li>
</ol>
<p>[ ] <a href="#2-2-3">2-2-3 Knn适合什么样的场景和数据类型？</a></p>
<p>通常最近邻分类器使用于特征与目标类之间的关系为比较复杂的数字类型，或者说二者关系难以理解，但是相似类间特征总是相似。</p>
<p>数据要求归一化，统一各个特征的量纲。</p>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="#2-2-4">2-2-4
常用的距离衡量公式都有哪些？具体说明它们的计算流程，以及使用场景？</a></label></p>
<p>特征空间 <span class="math inline">\(\mathcal X\)</span>
是n维实数向量空间 <span class="math inline">\(\mathbf{R}^n\)</span>
，<span class="math inline">\(x_i,x_j\in \mathcal{X}, x_i = (x_i^{(1)},
x_i^{(2)},\cdots x_i^{(n)}  ),  x_j = (x_j^{(1)}, x_j^{(2)}, \cdots,
x_j^{(n)})\)</span> 。则 <span class="math inline">\(x_i,x_j\)</span>的
<span class="math inline">\(L_p\)</span>距离（闵可夫斯基距离）定义为
<span class="math display">\[
L_p(x_i, x_j) = (\sum_{l=1}^n |x_i^{(l)}-x_j^{(l)}|)^{\frac{1}{p}}
\]</span> 这里 $p $。</p>
<p>1.<strong>欧式距离</strong></p>
<p>当 <span class="math inline">\(p=2\)</span>时，称为欧氏距离，强调数值上的绝对误差</p>
<p>是严格定义的距离，满足正定性、对称性、三角不等式 <span class="math display">\[
L_2(x_i, x_j) = (\sum_{l=1}^n |x_i^{(l)}-x_j^{(l)}|)^{\frac{1}{p}}
\]</span> 2.<strong>曼哈顿距离</strong>（p=1） <span class="math display">\[
L_1(x_i, x_j) = \sum_{l=1}^n |x_i^{(l)}-x_j^{(l)}|
\]</span> 3.<strong>切比雪夫距离</strong>（<span class="math inline">\(p
= \infty\)</span>），各个坐标距离数值差的绝对值的最大值 <span class="math display">\[
L_{\infty}(x_i, x_j) = \mathop{\max}_{l} \  |x_i^{(l)}-x_j^{(l)}|
\]</span> 4.<strong>马氏距离</strong></p></li>
</ul>
<p>考虑各个分量（特征）之间的相关性并与各个分量的尺度无关。给定一个样本集合<span class="math inline">\(X\)</span>，<span class="math inline">\(X=(x_{ij})_{m\times
n}\)</span>，其协方差矩阵记为<span class="math inline">\(S\)</span>。样本<span class="math inline">\(x_i\)</span>与样本<span class="math inline">\(x_j\)</span>之间的马氏距离<span class="math inline">\(d_{ij}\)</span>定义为 <span class="math display">\[
d_{ij} = [(x_i - x_j)^TS^{-1}(x_i - x_j)]^{\frac{1}{2}}
\]</span> 当<span class="math inline">\(S\)</span>为单位矩阵时，即样本数据的各个分量互相独立且各个分量的方差为1时，马氏距离就是欧氏距离。</p>
<p><strong>汉明距离</strong></p>
<p>两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数</p>
<p>1011101 与 1001001 之间的汉明距离是 2。</p>
<p>2143896 与 2233796 之间的汉明距离是 3。</p>
<p>"toned" 与 "roses" 之间的汉明距离是 3。</p>
<p>5.<strong>相关系数</strong>（correlation coefficient）</p>
<p>相关系数的绝对值越接近1，表示样本越相似；越接近0，表示样本越不相似。</p>
<p><span class="math inline">\(x_i\)</span>与<span class="math inline">\(x_j\)</span>之间的相关系数定义为 <span class="math display">\[
r_{ij} =
\frac{\sum_{k=1}^{m}\left(x_{k i}-\overline{x}_{i}\right)\left(x_{k
j}-\overline{x}_{j}\right)}{\left[\sum_{k=1}^{m}\left(x_{k
i}-\overline{x}_{i}\right)^{2} \sum_{k=1}^{m}\left(x_{k
j}-\overline{x}_{j}\right)^{2}\right]^{\frac{1}{2}}}
\]</span></p>
<p><span class="math display">\[
\overline{x}_{i}=\frac{1}{m} \sum_{k=1}^{m} x_{k i}, \quad
\overline{x}_{j}=\frac{1}{m} \sum_{k=1}^{m} x_{k j}
\]</span></p>
<p>4.<strong>余弦相似度</strong></p>
<p>强调方向上的相对误差</p>
<p>不是严格定义的距离，满足正定性、对称性，不满足三角不等式 <span class="math display">\[
  cos(A,B) = \frac{A \cdot B}{||A||_2 ||B||_2}
\]</span> 5.<strong>KL散度</strong></p>
<p>计算两个分布的差异性</p>
<p>不是严格定义的距离，满足正定性，不满足对称性、三角不等式</p>
<p><strong>使用场景</strong></p>
<p>欧氏距离：适用于向量各分量的度量标准统一的情况；当某些特征比其他特征取值大很多时，精确度会变差，很多特征值为0，即稀疏矩阵，结果不准，数据点的分布是某个圆心的半径，用欧式距离就不能比较了。</p>
<p>曼哈顿距离：适用于计算类似街区距离这样的实际问题。异常值对分类结果影响比欧式距离小。量纲不同时使用曼哈顿距离比欧式距离好。</p>
<p><strong>总结</strong></p>
<p>用距离度量相似度时，距离越小样本越相似；用相关系数时，相关系数越大样本越相似。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-2-5">2-2-5
超参数K值过大或者过小对结果有什么影响，你是如何选择K值？</a></label></li>
</ul>
<p>如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合；</p>
<p>如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。</p>
<p>K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的累，模型过于简单，忽略了训练实例中大量有用信息。</p>
<p>在实际应用中，K值一般取一个比较小的数值，例如采用交叉验证法（简单来说，就是一部分样本做训练集，一部分做测试集）来选择最优的K值。</p>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="#2-2-6">2-2-6
介绍一下Kd树？如何建树，以及如何搜索最近节点？</a></label></p>
<p>kd树是一种对k维空间中的实例点进行存储，以便对其进行快速检索的树形数据结构。kd树是二叉树，表示对k维空间的一个划分。构造kd树相当于不断地用垂直于坐标轴的超平面将k维空间切分，构成一系列的k维超矩形区域。kd树的每个节点对应于一个k维超矩形区域。</p>
<p><strong>构造平衡kd树过程：</strong></p>
<p>输入：k维空间数据集 <span class="math inline">\(T=\left\{x_{1},
x_{2}, \cdots, x_{N}\right\}\)</span>，其中<span class="math inline">\(x_{i}=\left(x_{i}^{(1)}, x_{i}^{(2)}, \cdots,
x_{i}^{(k)}\right)^{\mathrm{T}}, \quad i=1,2, \cdots,
N_{\mathrm{i}}\)</span></p>
<p>输出：kd树</p>
<p>（1）开始：构造根节点，根节点对应于包含T的k维空间的超矩形区域</p>
<p>​ 选择 $x^{(1)} $ 为坐标轴，以T中所有实例的 $x^{(1)} $
坐标的中位数为切分点，将根节点对应的超矩形区域且分为两个子区域。切分由通过切分点并与坐标轴
<span class="math inline">\(x^{(1)}\)</span>垂直的超平面实现。</p>
<p>​ 由根节点生成深度为1的左、右子节点：左子节点对应坐标 <span class="math inline">\(x^{(1)}\)</span>小于切分点的子区域，右子节点对应于坐标
<span class="math inline">\(x^{(1)}\)</span> 大于切分点的子区域。</p>
<p>​ 将落在切分超平面上的实例点保存在根节点。</p>
<p>（2）重复：对深度为<span class="math inline">\(j\)</span>
的节点，选择 <span class="math inline">\(x^{(l)}\)</span>
为切分的坐标轴，<span class="math inline">\(l = j({\rm mod}\ k) +
1\)</span>，以该节点的区域中所有实例的 <span class="math inline">\(x^{(l)}\)</span>
坐标的中位数为切分点，将该节点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴
<span class="math inline">\(x^{(l)}\)</span>垂直的超平面实现。</p>
<p>​ 由该节点生成深度为 <span class="math inline">\(j+1\)</span>
的左、右子节点：左子节点对应坐标 <span class="math inline">\(x^{(l)}\)</span>小于切分点的子区域，右子节点对应坐标<span class="math inline">\(x^{(l)}\)</span>大于切分点的子区域。</p>
<p>​ 将落在切分超平面上的实例点保存在根节点。</p>
<p>（3）直到两个子区域没有实例存在时停止，从而形成kd树的区域划分</p>
<p><img src="https://raw.githubusercontent.com/zhengjingwei/image-bed/master/kdtree-1.jpg"></p>
<p><img src="https://raw.githubusercontent.com/zhengjingwei/image-bed/master/kdtree-2.jpg"></p>
<p><strong>算法：用kd树的最近邻搜索</strong></p>
<p>输入：已构造的kd树：目标点<span class="math inline">\(x\)</span>；</p>
<p>输出：<span class="math inline">\(x\)</span>的最近邻</p>
<p>（1）在kd树中找出包含目标点<span class="math inline">\(x\)</span>的叶节点：从根节点出发，递归地向下访问kd树。若目标点<span class="math inline">\(x\)</span>当前维的坐标小于切分点的坐标，则移动到左子节点，否则移动到右子节点。直到子节点为叶节点为止。</p>
<p>（2）以此叶节点为“当前最近点”。</p>
<p>（3）递归地向上回退，在每个节点进行以下操作：</p>
<p>​
（a）如果该节点保存的实例点比当前最近点距离目标点更近，则以该实例点作为“当前最近点”</p>
<p>​
（b）当前最近点一定存在于该节点一个子节点对应的区域。检查该子节点的父节点的另一子节点（兄弟节点）对应区域是否有更近的点。具体地，检查另一子节点对应的区域是否与以目标点为球心、以目标点与“当前最近点”间的距离为半径的超球体相交。</p>
<p>​
如果相交，可能在另一个子节点对应的区域内存在距目标点更近的点，移动到另一个子节点。接着递归地进行最近邻搜索；</p>
<p>​ 如果不相交，向上回退</p>
<p>（4）当回退到根节点时，搜索结束。最后的“当前最近点”即为<span class="math inline">\(x\)</span>的最近邻点。</p>
<p>如果实例点是随机分布的，kd树搜索的平均计算复杂度是 <span class="math inline">\(O({\rm log} N)\)</span>，这里 <span class="math inline">\(N\)</span>
是训练实例数。<strong>kd树更适用与训练实例数远大于空间维数时的k近邻搜索。</strong>当空间维数接近训练实例数时，它的效率会迅速下降，几乎接近线性扫描。</p>
<p><img src="https://raw.githubusercontent.com/zhengjingwei/image-bed/master/kdtree-3.jpg"></p></li>
</ul>
<h3 id="支持向量机-svm">支持向量机 SVM</h3>
<p>hinge loss + kernel method</p>
<p><a href="#2-3-1">2-3-1 简单讲解SVM模型原理？</a></p>
<p>支持向量机是是一种二类分类模型，它的基本模型是是定义在特征空间的<strong>间隔最大的线性分类器</strong>，间隔最大，间隔最大使它有别于感知机；支持向量机还包括<strong>核技巧</strong>，这使它成为实质上的非线性分类器。支持向量机的学习策略是<strong>间隔最大化</strong>，可形式化为求解凸二次规划的问题，也<strong>等价于正则化的合页损失函数最小化问题</strong>。</p>
<p>线性可分支持向量机：当训练数据线性可分，通过硬间隔最大化，学习一个线性的分类器</p>
<p>线性支持向量机：当训练数据近似线性可分，通过软间隔最大化，学习一个线性的分类器</p>
<p>非线性支持向量机：当训练数据线性不可分，通过使用核技巧及软间隔最大化，学习非线性分类器</p>
<p><a href="#2-3-2">2-3-2
SVM为什么会对缺失值敏感？实际应用时候你是如何处理？</a></p>
<p>涉及到距离度量(distance
measurement)时，如计算两个点之间的距离，缺失数据就变得比较重要。如果缺失值处理不当就会导致效果很差，如SVM，KNN。</p>
<p>常用的缺失值处理方法：</p>
<p>（1）把数值型变量(numerical
variables)中的缺失值用其所对应的类别中(class)的中位数(median)替换。把描述型变量(categorical
variables)缺失的部分用所对应类别中出现最多的数值替代(most frequent
non-missing
value)。【快速简单但效果差】（平均数、中位数、众数、插值等）</p>
<p>（2）将缺失值当成新的数值，NaN</p>
<p>（3）忽略该项数据（当缺失少时）</p>
<p><a href="#2-3-3">2-3-3 SVM为什么可以分类非线性问题？</a></p>
<p>原输入空间是一个非线性可分问题，能用一个超曲面将正负例正确分开；</p>
<p>通过核技巧的非线性映射，将输入空间的超曲面转化为特征空间的超平面，原空间的非线性可分问题就变成了新空间的的线性可分问题。低维映射到高维。</p>
<p>在核函数 <span class="math inline">\(K(x,z)\)</span>
给定的条件下，可以利用解线性分类问题的方法求解非线性分类问题的支持向量机。学习是隐式地在特征空间进行的，在学习和预测中只定义核函数
<span class="math inline">\(K(x,z)\)</span>，而不需要显式地定义特征空间和映射函数<span class="math inline">\(\phi\)</span>，这样的技巧成为核技巧。通常直接计算<span class="math inline">\(K(x,z)\)</span>比较容易，而通过<span class="math inline">\(\phi(x)\)</span>和<span class="math inline">\(\phi(z)\)</span>计算<span class="math inline">\(K(x,z)\)</span>并不容易。</p>
<p>对于给定核 <span class="math inline">\(K(x,z)\)</span>，特征空间和映射函数的取法并不唯一。</p>
<p><a href="#2-3-4">2-3-4
常用的核函数有哪些？你是如何选择不同的核函数的？</a></p>
<p><strong>核函数定义</strong>：设<span class="math inline">\(\mathcal{X}\)</span>是输入空间，又设<span class="math inline">\(\mathcal{H}\)</span>为特征空间，如果存在一个从<span class="math inline">\(\mathcal{X}\)</span>到<span class="math inline">\(\mathcal{H}\)</span>的映射 <span class="math display">\[
\phi(x) : \mathcal{X} \rightarrow \mathcal{H}
\]</span> 使得对所有<span class="math inline">\(x, z \in
\mathcal{X}\)</span>，函数<span class="math inline">\(K(x,
z)\)</span>满足条件 <span class="math display">\[
K(x, z)=\phi(x) \cdot \phi(z)
\]</span> 则称<span class="math inline">\(K(x,
z)\)</span>为核函数，<span class="math inline">\(\phi(x)\)</span>为映射函数，式中<span class="math inline">\(\phi(x) \cdot \phi(z)\)</span><span class="math inline">\(为\phi(x)\)</span>和<span class="math inline">\(\phi(z)\)</span>的内积</p>
<p><strong>线性核函数</strong> <span class="math display">\[
K(x,z) = x\cdot z
\]</span>
主要用于线性可分的情况。可以看到特征空间到输入空间的维度是一样的，其参数少速度快，对于线性可分数据，其分类效果很理想，因此我们通常首先尝试用线性核函数来做分类，看看效果如何，如果不行再换别的。</p>
<p><strong>多项式核函数</strong>（polynomial kernel function） <span class="math display">\[
K(x, z)=(x \cdot z+1)^{p}
\]</span> 对应的支持向量机是一个p次多项式分类器。分类决策函数为 <span class="math display">\[
f(x)=\operatorname{sign}\left(\sum_{i=1}^{N_{s}} a_{i}^{*}
y_{i}\left(x_{i} \cdot x+1\right)^{p}+b^{*}\right)
\]</span>
多项式核函数可以实现将低维的输入空间映射到高维的特征空间，但是多项式核函数的参数多，当多项式的阶数比较高的时候，核矩阵的元素值将趋于无穷大或者无穷小，计算复杂度会大到无法计算。</p>
<p><strong>高斯核函数</strong>（Gaussian kernel function） <span class="math display">\[
K(x,z) = exp(-\frac{1}{2} \ ||x - z ||_2 ) = \phi(x) \cdot \phi(z)
\]</span> 对应的支持向量机是高斯径向基函数（radial basis
function）分类器，分类决策函数为 <span class="math display">\[
f(x)=\operatorname{sign}\left(\sum_{i=1}^{N_{s}} a_{i}^{*} y_{i} \exp
\left(-\frac{\|x-x_i\|^{2}}{2 \sigma^{2}}\right)+b^{*}\right)
\]</span>
高斯径向基函数是一种局部性强的核函数，其可以将一个样本映射到一个更高维的空间内，该核函数是应用最广的一个，无论大样本还是小样本都有比较好的性能，而且其相对于多项式核函数参数要少，因此大多数情况下在不知道用什么核函数的时候，优先使用高斯核函数。</p>
<p><strong>Sigmod核函数</strong> <span class="math display">\[
K\left(x, z\right)=\tanh \left(\eta \ x \cdot z +\theta\right)
\]</span> 总结</p>
<ul>
<li>如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM；
<ul>
<li>（特征维度高，往往线性可分，SVM解决非线性分类问题的思路就是将样本映射到更高维的特征空间中）</li>
</ul></li>
<li>如果样本数量很多，由于求解最优化问题的时候，目标函数涉及两两样本计算内积，使用高斯核明显计算量会大于线性核，所以手动添加一些特征，使得线性可分，然后可以用LR或者线性核的SVM</li>
<li>如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数；</li>
</ul>
<p><a href="#2-3-5">2-3-5 RBF核函数一定线性可分么？为什么</a></p>
<p>根据Cover定理，从低维度映射到高维度后，线性可分的可能性比较大。</p>
<p>而RBF核函数将原始空间映射到无穷维的特征空间，基本线性可分（也有线性不可分的情况，如加入噪声：同一样本不同标签）。如果忽略噪声，同时允许一定限度的误差，可以说升到足够高的维度，几乎所有数据集都是线性可分了。</p>
<p>同时，维度特别高，几乎一定线性可分，也以为这模型特别复杂，几乎一定会碰到过拟合问题。</p>
<p><a href="#2-3-6">2-3-6
SVM属于线性模型还是非线性模型？为什么？</a></p>
<p>基本模型是一个线性分类器；而通过使用核函数可以学习非线性支持向量机</p>
<p><a href="#2-3-7">2-3-7
训练误差为0的SVM分类器一定存在吗？说明原因？</a></p>
<p>对于训练一个不加入松弛变量的SVM模型时，一定存在。百面p55</p>
<p>对于加入松弛变量的SVM的训练误差不一定能达到0</p>
<p><a href="#2-3-7">2-3-8
当用支持向量机进行分类时，支持向量越多越好还是越少越好</a></p>
<p>结论：在n维特征空间中，线性SVM一般会产生n+1个支持向量（不考虑退化情况）</p>
<p>通常的SVM的使用会伴随着核技巧（kernel），这用于将低维空间映射到一个更高维的空间，使得原本不线性可分的数据点变得在高维空间中线性可分。虽然这种映射是隐式的，我们通常并不知道映射到的空间是什么样子。但是根据之前的结论，我们可以认为如果训练出来的SVM有d+1个支持向量，这个kernel在这个任务里就讲原来的数据映射到了一个d维的空间中，并使得其线性可分。</p>
<p>更高的维度通常意味着更高的模型复杂度，所以支持向量越多，表示着训练得到的模型越复杂。根据泛化理论，这意味着更有过拟合的风险。</p>
<p>如果在性能一致的情况下，更少的支持向量可能是更好的。但是这一点其实不绝对，因为泛化理论仅仅是误差的上界，实际的泛化情况的决定因素比较复杂，也可能取决于kernel的性质。所以还是自己做cross
validation比较好。</p>
<p>[ ] <a href="">2-3-9 多类分类问题</a></p>
<ol type="1">
<li><p>某些算法原生的支持多分类，如：决策树、最近邻算法等。但是有些算法只能求解二分类问题，如：支持向量机。</p></li>
<li><p>对于只能求解二分类问题的算法，一旦遇到问题是多类别的，那么可以将多分类问题拆解成二分类任务求解。</p>
<p>即：</p>
<ul>
<li>先对原问题进行拆分，然后为拆出的每个二分类任务训练一个分类器。</li>
<li>测试时，对这些二分类器的预测结果进行集成，从而获得最终的多分类结果。</li>
</ul></li>
<li><p>多分类问题有三种拆解方式：</p>
<ul>
<li><p>一对其余(<code>One-vs-rest:OvR</code>) 。</p>
<ul>
<li>为每一对类别训练一个分类器。</li>
</ul></li>
<li><p>一对一(<code>one-vs-one:OvO</code>) 。</p>
<ul>
<li>训练k(k-1)个分类器</li>
</ul></li>
<li><p>多对多(<code>many-vs-many:MvM</code>) 。</p></li>
</ul></li>
</ol>
<h3 id="朴素贝叶斯模型">朴素贝叶斯模型</h3>
<ul class="task-list">
<li><label><input type="checkbox"><a href="2-4-1">2-4-1
讲解贝叶斯定理？</a> <span class="math display">\[
P\left(B_{i} | A\right)=\frac{P\left(B_{i}\right) P\left(A |
B_{i}\right)}{\sum_{j=1}^{n} P\left(B_{j}\right) P\left(A |
B_{j}\right)}
\]</span></label></li>
</ul>
<p>[ ] <a href="#2-4-2">2-4-2
什么是条件概率、边缘概率、联合概率？</a></p>
<p><strong>条件概率</strong>：条件概率表示在条件<span class="math inline">\(Y=b\)</span>成立的情况下，<span class="math inline">\(X=a\)</span>的概率，记作<span class="math inline">\(P(X=a|Y=b)\)</span>或<span class="math inline">\(P(a|b)\)</span>。它具有如下性质：
“在条件Y=b下X的条件分布”也是一种“X的概率分布”，因此穷举X的可取值之后，所有这些值对应的概率之和为1
即： <span class="math display">\[
  \sum_{a} P(X=a | Y=b)=1
  \]</span>
<strong>边缘概率</strong>：仅与单个随机变量有关的概率称为边缘概率，如
<span class="math inline">\(P(X=a)\)</span> 或 <span class="math inline">\(P(Y=b)\)</span></p>
<p><strong>联合概率</strong>：联合概率指的是包含多个条件且<strong>所有条件同时成立</strong>的概率，记作<span class="math inline">\(P(X=a,Y=b)\)</span>或<span class="math inline">\(P(a,b)\)</span></p>
<p>联合概率、边缘概率与条件概率的关系： <span class="math display">\[
  P(X=a | Y=b)=\frac{P(X=a, Y=b)}{P(Y=b)}
  \]</span></p>
<p>[ ] <a href="#2-4-3">2-4-3 后验概率最大化的含义是什么？</a></p>
<p>朴素贝叶斯法将实例分到后验概率最大的类中。后验概率最大化这等价于期望风险最小化。</p>
<p>假设选择0-1损失函数： <span class="math display">\[
  L(Y, f(X))=\left\{\begin{array}{ll}{1,} &amp; {Y \neq f(X)} \\ {0,}
&amp; {Y=f(X)}\end{array}\right.
  \]</span> 其中 <span class="math inline">\(f(X)\)</span>是分类决策函数。这是期望风险函数为
<span class="math display">\[
  R_{\operatorname{cap}}(f)=E[L(Y, f(X))]
  \]</span> 期望是对联合分布 <span class="math inline">\(P(X,Y)\)</span>
取的。由此取条件期望 <span class="math display">\[
  R_{\mathrm{exp}}(f)=E_{X} \sum_{k=1}^{K}\left[L\left(c_{k},
f(X)\right)\right] P\left(c_{k} | X\right)
  \]</span> 为了使期望奉献最小化，只需对 <span class="math inline">\(X=x\)</span> 逐个最小化，由此得到 <span class="math display">\[
  \begin{aligned} f(x) &amp;=\arg \min _{y \in \mathcal{Y}}
\sum_{k=1}^{K} L\left(c_{k}, y\right) P\left(c_{k} | X=x\right) \\
&amp;=\arg \min _{y \in \mathcal{Y}} \sum_{k=1}^{K} P\left(y \neq c_{k}
| X=x\right) \\ &amp;=\arg \min _{y \in
\mathcal{Y}}\left(1-P\left(y=c_{k} | X=x\right)\right) \\ &amp;=\arg
\max _{y \in \mathcal{Y}} P\left(y=c_{k} | X=x\right) \end{aligned}
  \]</span> 这样一来，根据期望风险最小化准则就得到了后延概率最大化准则：
<span class="math display">\[
  f(x)=\arg \max _{c_{k}} P\left(c_{k} | X=x\right)
  \]</span> 即朴素贝叶斯法所采用原理</p>
<p>[ ] <a href="#2-4-4">2-4-4
朴素贝叶斯模型如何学习的？训练过程是怎样？</a></p>
<p>对于给定的训练数据集，首先基于特征条件独立性假设学习输入输出的联合概率分布；</p>
<p>然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。</p>
<p><strong>训练过程</strong>：</p>
<p>（1）计算先验概率及条件概率 <span class="math display">\[
  \begin{array}{l}{P\left(Y=c_{k}\right)=\frac{\sum_{i=1}^{N}
I\left(y_{i}=c_{k}\right)}{N}, \quad k=1,2, \cdots, K} \\
{P\left(X^{(j)}=a_{j l} | Y=c_{k}\right)=\frac{\sum_{i=1}^{N}
I\left(x_{i}^{(j)}=a_{j}, y_{i}=c_{k}\right)}{\sum_{i=1}^{N}
I\left(y_{i}=c_{k}\right)}} \\ {j=1,2, \cdots, n ; \quad l=1,2, \cdots,
S_{j} ; \quad k=1,2, \cdots, K}\end{array}
  \]</span> （2）对于给定实例 <span class="math inline">\(x=\left(x^{(1)}, x^{(2)}, \cdots,
x^{(n)}\right)^{\mathrm{T}}\)</span>，计算 <span class="math display">\[
  P\left(Y=c_{k}\right) \prod_{i=1}^{n} P\left(X^{(j)}=x^{(j)} |
Y=c_{k}\right), \quad k=1,2, \cdots, K
  \]</span> （3）确定实例x的类（最大后验概率） <span class="math display">\[
  y = \arg\max_{c_k}\ P(Y=c_k)\prod_{j}P(X^{(j)}=x^{(j)}|Y=c_k)
  \]</span></p>
<p>[ ] <a href="#2-4-5">2-4-5 你如何理解生成模型和判别模型？</a></p>
<p><strong>生成方法</strong>由数据学习联合概率分布 <span class="math inline">\(P(X,Y)\)</span>，然后求出条件概率分布 <span class="math inline">\(P(Y|X)\)</span>作为预测模型： <span class="math display">\[
  P(Y|X) = \frac{P(X,Y)}{P(X)}
  \]</span> 之所以成为生成方法，是因为模型表示了给定输入 <span class="math inline">\(X\)</span> 产生输出 <span class="math inline">\(Y\)</span>的生成关系。</p>
<p>典型的生成模型：朴素贝叶斯法、隐马尔可夫模型。</p>
<p><strong>判别方法</strong>由数据直接学习决策函数 <span class="math inline">\(f(X)\)</span> 或者条件概率分布 <span class="math inline">\(P(X,Y)\)</span>作为预测的模型，关心的是对给定的输入
<span class="math inline">\(X\)</span>，应该预测什么样的输出 <span class="math inline">\(Y\)</span>。</p>
<p>典型的判别模型：k近邻、感知机、决策树、逻辑斯蒂回归、最大熵模型、支持向量机、提升方法、条件随机场。</p>
<p>[ ] <a href="#2-4-6">2-4-6
朴素贝叶斯模型“朴素”体现在哪里？存在什么问题？有哪些优化方向？</a></p>
<p>"朴素"体现在朴素贝叶斯模型对条件概率分布作了<strong>条件独立性假设</strong>，这是一个较强的假设。
<span class="math display">\[
  \begin{aligned} P(X&amp;=x | Y=c_{k} )=P\left(X^{(1)}=x^{(1)}, \cdots,
X^{(n)}=x^{(n)} | Y=c_{k}\right) \\ &amp;=\prod_{j=1}^{n}
P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right) \end{aligned}
  \]</span>
存在问题：当特征分布不满足条件独立性假设时，分类的性能不高</p>
<p>优化方法：贝叶斯网络</p>
<p>[ ] <a href="#2-4-7">2-4-7
什么是贝叶斯网络？它能解决什么问题？</a></p>
<p>朴素贝叶斯法假设输入变量都是条件独立的，如果假设他们之间<strong>存在概率依存关系</strong>，模型就被成了贝叶斯网络。</p>
<p>贝叶斯网络也称为“信念网”，借助<strong>有向无环图</strong>来刻画属性之间的依赖关系，并使用<strong>条件概率表</strong>来描述属性的联合概率分布。贝叶斯网结构有效地表达了属性的条件独立性。</p>
<p>具体来说，一个贝叶斯网B由结构G和参数 <span class="math inline">\(\theta\)</span> 表示，即 <span class="math inline">\(B = &lt;G,\theta&gt;\)</span>
。网络结构G是一个邮箱无环图，其每个节点对应于一个属性，若两个属性有直接依赖关系，则它们由一条边连接起来；参数
<span class="math inline">\(\theta\)</span>
定量描述这种依赖关系，假设属性 <span class="math inline">\(x_i\)</span>
在G中的父节点集为 <span class="math inline">\(\pi_i\)</span>，则 <span class="math inline">\(\theta\)</span>包含了每个属性的条件概率 <span class="math inline">\(\theta_{x_i|\pi_i} = P_B(x_i|\pi_i)\)</span>。</p>
<p>给定父节点集，贝叶斯网假设每个属性与它的非后裔属性独立，于是将属性的联合概率分布定义为</p>
<p><span class="math display">\[
P_{B}\left(x_{1}, x_{2}, \ldots, x_{d}\right)=\prod_{i=1}^{d}
P_{B}\left(x_{i} | \pi_{i}\right)=\prod_{i=1}^{d} \theta_{x_{i} |
\pi_{i}}以上图为例，联合概率分布定义为
\]</span></p>
<p>​<br>
<span class="math display">\[
P\left(x_{1}, x_{2}, x_{3}, x_{4}, x_{5}\right)=P\left(x_{1}\right)
P\left(x_{2}\right) P\left(x_{3} | x_{1}\right) P\left(x_{4} | x_{1},
x_{2}\right) P\left(x_{5} | x_{2}\right)
\]</span> ​ <strong>贝叶斯网学习过程</strong></p>
<p>​
精确求解NP难，所以（1）贪心法：从某个网络结构出发，每次调整一条边，直到评分函数值不再降低（2）给网络结构施加约束条件：如限定为树形结构等。</p>
<p>​ <strong>贝叶斯网推断</strong></p>
<p>​
理想情况根据贝叶斯网定义的联合概率分布来精确计算后验概率，但这样的精确推断时NP难的。近似推断采用吉布斯采样法，通过随机游走，使马尔可夫链趋于平稳分布。</p>
<p>[ ] <a href="#2-4-8">2-4-8
为什么说朴素贝叶斯也是线性模型而不是非线性模型呢？</a></p>
<p>线性分类器是通过特征的线性组合来做出分类决定的分类器。本质上，朴素贝叶斯分类器是一种线性分类器。</p>
<p>朴素贝叶斯分类器是建立在属性变量相互独立的基础上，后验概率为判定准则的分类器。不等式1成立，则样例x=[x_1,...,x_n]为正类。否则，样例为负类。</p>
<ol type="1">
<li></li>
</ol>
<figure>
<img src="https:////upload-images.jianshu.io/upload_images/1385318-0c8849c769c7cae3?imageMogr2/auto-orient/strip%7CimageView2/2/w/291/format/webp" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>线性分类器直观地来说，是在高维样本空间中找到一组超平面，将样本空间划分了两个区域。每个区域对应于不同的类别。数学上来说，线性分类器能找到权值向量w，使得判别公式可以写成特征值的线性加权组合。</p>
<ol start="2" type="1">
<li></li>
</ol>
<figure>
<img src="https:////upload-images.jianshu.io/upload_images/1385318-2443a8f4fea70ee7?imageMogr2/auto-orient/strip%7CimageView2/2/w/137/format/webp" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>如果公式2成立，则样本属于正类；反之，则样本属于负类。</p>
<hr>
<p><strong>离散特征的朴素贝叶斯分类器</strong></p>
<p>一般离散特征的取值范围有两种，{-1,1}或者{0,1}。这两种取值方式不会影响分析。不妨假设离散特征的取值范围为{-1,1}。下面的不等式成立，样例x=[x_1,...,x_n]为正类。
(3)</p>
<figure>
<img src="https:////upload-images.jianshu.io/upload_images/1385318-fbf05fdf34f5fdd5?imageMogr2/auto-orient/strip%7CimageView2/2/w/385/format/webp" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>对于某个特征x，我们很容易推导出下面的公式</p>
<ol start="4" type="1">
<li></li>
</ol>
<figure>
<img src="https:////upload-images.jianshu.io/upload_images/1385318-f7280559286d0abc?imageMogr2/auto-orient/strip%7CimageView2/2/w/526/format/webp" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>其中p(x|F)也有类似的结果，从而有 (5) <img src="https:////upload-images.jianshu.io/upload_images/1385318-101318b723db87f3?imageMogr2/auto-orient/strip%7CimageView2/2/w/490/format/webp" alt="img"></p>
<p>将公式5带入朴素贝叶斯分类器的公式3，得到下面的公式 (6)</p>
<figure>
<img src="https:////upload-images.jianshu.io/upload_images/1385318-d3e418e1bef50305?imageMogr2/auto-orient/strip%7CimageView2/2/w/529/format/webp" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>根据公式6，离散特征的朴素贝叶斯分类器判别公式能够写成特征值的加权线性组合。也就是说，离散特征的朴素贝叶斯分类器本质上是线性分类器。</p>
<p>[ ] <a href="#2-4-9">2-4-9
如何解决用极大似然法可能出现所要估计的概率为0的情况？</a></p>
<p>分子加1，分母加可能情况数</p>
<p>用极大似然法估计可能会出现所要估计的概率值为0的情况。这是会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用贝叶斯估计。具体地，条件概率的贝叶斯估计是
<span class="math display">\[
  P_{\lambda}\left(X^{(j)}=a_{j l} | Y=c_{k}\right)=\frac{\sum_{i=1}^{N}
I\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\right)+\lambda}{\sum_{i=1}^{N}
I\left(y_{i}=c_{k}\right)+S_{j} \lambda}
  \]</span> 式中 <span class="math inline">\(\lambda \geq
0\)</span>。等价于在随机变量各个取值的频数上赋予一个正数 <span class="math inline">\(\lambda\)</span>。当<span class="math inline">\(\lambda=0\)</span>时就是极大似然估计。常取 <span class="math inline">\(\lambda=1\)</span>，这时称为拉普拉斯平滑（laplacian
smoothing）。显然，对任何<span class="math inline">\(l=1,2, \cdots,
S_{j}, \quad k=1,2, \cdots, K\)</span> 有 <span class="math display">\[
  \begin{array}{l}{P_{\lambda}\left(X^{(j)}=a_{j l} |
Y=c_{k}\right)&gt;0} \\ {\sum_{l=1}^{s_{j}} P\left(X^{(j)}=a_{j l} |
Y=c_{k}\right)=1}\end{array}
  \]</span></p>
<p>表明上式确实为一种概率分布。同样，先验概率的贝叶斯估计是 <span class="math display">\[
  P_{\lambda}\left(Y=c_{k}\right)=\frac{\sum_{i=1}^{N}
I\left(y_{i}=c_{k}\right)+\lambda}{N+K \lambda}
  \]</span></p>
<h3 id="fm模型">FM模型</h3>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="#2-7-1">2-7-1
FM模型与逻辑回归相比有什么优缺点？</a></label></p>
<p>优点：</p>
<ul>
<li>存储空间和计算复杂度减小</li>
<li>解决样本过于稀疏训练不充分的问题</li>
</ul>
<p>缺点：</p>
<ul>
<li>记忆能力不如LR</li>
</ul></li>
<li><p><label><input type="checkbox"><a href="#2-7-2">2-7-2
为什么FM模型计算复杂度时O(kn)？</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#2-7-3">2-7-3
介绍FFM场感知分解机器（Field-aware Factorization
Machine），说说与FM异同？</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#2-7-4">2-7-4
使用FM进行模型训练时候，有哪些核心参数对模型效果影响大？</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#2-7-5">2-7-5
如何从神经网络的视角看待FM模型？</a></label></p></li>
</ul>
<h3 id="决策树">决策树</h3>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><a href="#2-8-1">2-8-1
讲解完成的决策树的建树过程</a></label></li>
</ul>
<p>自上而下，对样本数据进行树形分类的过程。每个内部节点表示一个特征，叶节点表示一个类别。从顶部根节点开始，所有的样本聚在一起。经过根节点的划分，样本被分到不同的子节点，再根据子节点的特征进一步划分，直至所有样本被归到某一个类别（叶节点）中。</p>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><a href="#2-8-2">2-8-2
你是如何理解熵？从数学原理上解释熵公式可以作为信息不确定性的度量？</a></label></li>
</ul>
<p>熵（entropy）是表示随机变量不确定性的度量， <span class="math inline">\(X\)</span>
是一个取有限个值的离散随机变量，其概率分布为 <span class="math display">\[
P(X = x_i) = p_i, \ i=1,2,\cdots,n
\]</span> 则随机变量 <span class="math inline">\(X\)</span> 的熵定义为
<span class="math display">\[
H(X) = -\sum_{i=1}^{n} p_i {\rm log } \ p_i
\]</span> 熵越大，随机变量的不确定性就越大。</p>
<p>而熵其实表示的是一个系统的平均信息量。<strong>自信息量</strong>是用来描述某一条信息的大小
<span class="math display">\[
I = - {\rm log} \ p_i
\]</span>
通常以2为底，单位是bit；含义是用多少位二进制可以表示衡量该信息的大小。而通常我们衡量整个系统的信息量，系统存在多个事件
<span class="math inline">\(X=\{x_1,\cdots,x_n\}\)</span>
，每个事件的概率分布<span class="math inline">\(P=\{p_1,\cdots,p_n\}\)</span>
，<strong>熵是整个系统的平均信息量</strong> 。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-8-3">2-8-3
联合熵、条件熵、KL散度、信息增益、信息增益比、gini系数都是什么？如何计算？</a></label></li>
</ul>
<p><strong>联合熵</strong>：将一维随机变量分布推广到多维随机变量分布
<span class="math display">\[
H(X,Y) = -\sum\limits_{x,y} p(x,y)\ {\rm log}\ p(x,y)
\]</span> <strong>条件熵</strong>：某个特征A对于数据集D的经验条件熵
<span class="math inline">\(H(D|A)\)</span> 为 <span class="math display">\[
H(D|A) = - \sum_{i=1}^{n} \frac{|D_i|}{|D|} H(D_i) \\ = - \sum_{i=1}^{n}
\frac{|D_i|}{|D|} \lgroup \sum_{k=1}^{K} \frac{|D_{ik}|}{|D_i|} {\rm log
} \frac{|D_{ik}|}{|D_i|} \rgroup
\]</span> <strong>信息增益</strong>： <span class="math inline">\(g(D,A)\)</span> 定义为数据集D的经验熵 <span class="math inline">\(H(D)\)</span> 与特征A给定条件下D的经验条件熵 <span class="math inline">\(H(D|A)\)</span> 的差 <span class="math display">\[
g(D,A) = H(D) - H(D|A)
\]</span></p>
<p><strong>信息增益比</strong>：特征A对于数据集D 的信息增益比定义为
<span class="math display">\[
g_R(D|A) = \frac{g(D|A)}{H_A(D)}
\]</span> 其中 <span class="math display">\[
H_A{(D)} = - \sum_{i=1}^{n} \frac{|D_i|}{|D|} {\rm log }
\frac{|D_i|}{|D|}
\]</span> 为数据集D关于A的取值熵；n为特征A在D上的取值数目；</p>
<p><strong>Gini系数</strong>：描述数据的不确定性。数据集D的Gini系数为
<span class="math display">\[
{\rm Gini}(D) = 1 - \sum_{k=1}^{K
}(\frac{|C_k|}{|D|})^2
\]</span> 其中 <span class="math inline">\(C_k\)</span>是
D中第k类的样本子集，K是类的个数。例如二分类问题，K=2。基尼系数越大，样本集合的不确定性也就越大，这一点与熵相似。基尼系数Gini(D,A)表示经A=a分割后集合D的不确定性。</p>
<p><strong>交叉熵</strong>：刻画两个概率分布之间的距离，通过q来表示p的交叉熵为；一般<strong>p(x)为真实分布</strong>，<strong>q(x)为预测分布</strong></p>
<p>交叉熵不对称。交叉熵越小，概率分布越接近 <span class="math display">\[
H(p,q) = - \sum\limits_{x} p(x) {\rm log } \ q(x)
\]</span> <strong>KL散度/相对熵</strong>： <span class="math display">\[
D_{K L}(p \| q)=\sum_{i=1}^{n} p\left(x_{i}\right) \log
\left(\frac{p\left(x_{i}\right)}{q\left(x_{i}\right)}\right)
\]</span>
n表示事件可能发生的情况总数，KL散度的值越小表示两个分布越接近。 <span class="math display">\[
D_{KL}(p||q) = H(p,q) - H(p)
\]</span></p>
<p>机器学习中，我们常常使用KL散度来评估predict和label之间的差别，但是由于KL散度的后半部分是一个常量，所以我们常常将前半部分的交叉熵作为损失函数，其实二者是一样的。</p>
<ul class="task-list">
<li><label><input type="checkbox" checked=""><a href="#2-8-4">2-8-4
常用的决策树有哪些？ID3、C4.5、CART有啥异同？</a></label></li>
</ul>
<table>
<colgroup>
<col style="width: 11%">
<col style="width: 29%">
<col style="width: 26%">
<col style="width: 32%">
</colgroup>
<thead>
<tr>
<th>不同点</th>
<th>ID3</th>
<th>C4.5</th>
<th>CART</th>
</tr>
</thead>
<tbody>
<tr>
<td>原则</td>
<td>信息增益最大</td>
<td>信息增益比最大</td>
<td>划分后集合基尼指数最小</td>
</tr>
<tr>
<td>用途</td>
<td>分类</td>
<td>分类</td>
<td>分类、回归</td>
</tr>
<tr>
<td>输入取值</td>
<td>离散</td>
<td>离散、连续</td>
<td>离散、连续</td>
</tr>
<tr>
<td>树结构</td>
<td>多叉树</td>
<td>多叉树</td>
<td>二叉树</td>
</tr>
<tr>
<td></td>
<td>特征在层级间不复用</td>
<td>特征在层级间不复用</td>
<td>每个特征可被重复利用</td>
</tr>
<tr>
<td></td>
<td>对样本特征缺失值敏感</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>ID3 最大信息增益</strong></p>
<p>信息增益 <span class="math inline">\(g(D,A)\)</span>
定义为数据集D的经验熵 <span class="math inline">\(H(D)\)</span>
与特征A给定条件下D的经验条件熵 <span class="math inline">\(H(D|A)\)</span> 的差 <span class="math display">\[
g(D,A) = H(D) - H(D|A)
\]</span> 选择 <span class="math inline">\(g(D,A)\)</span>
最大的特征，所有样本根据此特征，划分到不同的节点上。在经验熵不为0的节点中继续生长。ID3算法只有树的生成，容易产生过拟合。</p>
<p><strong>C4.5 最大信息增益比</strong></p>
<p>因为信息增益对取值数目多的属性有所偏好，为了减少这种偏好带来的影响，使用信息增益比来选择最优划分属性。</p>
<p><strong>CART 基尼指数</strong></p>
<p>基尼系数Gini（D）用来表示集合D的不确定性。CART在每一次迭代中选择划分后<strong>基尼指数最小</strong>的特征及其对应的切分点进行分类。CART是一颗二叉树，每次将数据按特征A的区分分成两份，分别进入左右子树。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-8-5">2-8-5
决策树如何防止过拟合？前剪枝和后剪枝过程是怎样的？剪枝条件都是什么</a></label></li>
</ul>
<p>通过<strong>剪枝</strong>防止过拟合。</p>
<p><strong>预剪枝</strong>是指在决策树生成的过程中，对每个节点在划分前先进行估计，若当前节点的划分不能带来决策树泛化性能提升，则停止划分，并将当前节点标记为叶子节点；此时可能存在不同类别的样本同时存于同个节点中，按照多数投票的原则判断节点所属类别</p>
<p>预剪枝对于何时停止决策树的生长：</p>
<p>（1）当树达到一定深度</p>
<p>（2）当到达当前节点的样本数量小于某个阈值</p>
<p>（3）计算每次分裂对测试集的准确度提升，小于某个阈值时停止</p>
<p><strong>后剪枝</strong>则是先从训练集生成一棵完整的决策树，然后自底向上地对<strong>非叶子节点</strong>进行考察，若该节点对应的<strong>子树替换成叶子结点</strong>能带来泛化性能提升，则将该子树替换为叶子节点。</p>
<h3 id="随机森林rf">随机森林（RF）</h3>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-9-1">2-9-1
介绍RF原理和思想</a></label></li>
<li><label><input type="checkbox"><a href="#2-9-2">2-9-2
RF是如何处理缺失值？</a></label></li>
<li><label><input type="checkbox"><a href="#2-9-3">2-9-3
RF如何衡量特征重要度？</a></label></li>
<li><label><input type="checkbox"><a href="#2-9-4">2-9-4
RF“随机”主要体现在哪里？</a></label></li>
<li><label><input type="checkbox"><a href="#2-9-5">2-9-5
RF有哪些优点和局限性？</a></label></li>
<li><label><input type="checkbox"><a href="#2-9-6">2-9-6
为什么多个弱分类器组合效果会比单个要好？如何组合弱分类器可以获得更好的结果？原因是什么？</a></label></li>
<li><label><input type="checkbox"><a href="#2-9-7">2-9-7
Bagging的思想是什么？它是降低偏差还是方差，为什么？</a></label></li>
</ul>
<p>Bagging的思想是通过对数据再抽样，然后在每组样本上训练出来的模型取平均。Bagging是降低方差，防止过拟合。可以这样理解，对n个独立不相关的模型的预测结果取平均，方差是原来单个模型的
<span class="math inline">\(1/n\)</span> 。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-9-8">2-9-8
可否将RF的基分类模型由决策树改成线性模型或者knn？为什么？</a></label></li>
</ul>
<p>随机森林属于bagging类的集成学习方法，主要好处是减小集成后分类器的方差，比基分类器的方差小。所以Bagging所采用的的基分类器最好是本身对样本分布较为敏感（不稳定分类器），这样bagging才能体现效果。而线性分类器和KNN属于较为稳定的分类器，本身方差不大，所以将他们作为基分类器使用bagging不能再原基分类器的基础上获得更好的表现。相反地，可能因为bagging的采样而使得训练中难以收敛从而增大集成分类器的偏差。</p>
<h3 id="gbdt">GBDT</h3>
<p>梯度提升<strong>Gradient
Boosting</strong>的基本思想是根据当前模型损失函数<strong>负梯度</strong>信息来训练新加入的弱分类器，然后将训练好的弱分类器以<strong>累加</strong>的形式结合到现有的模型中。</p>
<p>GBDT（梯度提升决策树）的核心思想：每一棵树学的是之前所有树结果和的残差，这个残差就是加上预测之后能得到真实值的累加量。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-10-1">2-10-1
梯度提升和梯度下降有什么区别和联系？</a></label></li>
</ul>
<p>两者都是在每一轮迭代中，利用损失函数相对于模型的负梯度方向的信息来对当前模型进行更新，只不过在梯度下降中，模型是以参数化的形式表示，从而模型的更新等价于参数的更新。</p>
<p>而在梯度提升中，模型并不需要参数化表示，而是直接定义在函数空间中，从而大大扩展了可以使用的模型种类。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-10-2">2-10-2
你是如何理解Boosting和Bagging？他们有什么异同？</a></label></li>
</ul>
<p>Bagging通过模型集成降低方差，提高弱分类器的性能。</p>
<p>Boosting通过模型集成降低偏差，提高弱分类器的性能。</p>
<table>
<thead>
<tr>
<th></th>
<th>Bagging</th>
<th>Boosting</th>
</tr>
</thead>
<tbody>
<tr>
<td>降低</td>
<td>方差</td>
<td>偏差</td>
</tr>
<tr>
<td>训练</td>
<td>各个弱分类器可独立训练</td>
<td>弱分类器需要依次生成</td>
</tr>
<tr>
<td>典型方法</td>
<td>随机森林</td>
<td>Adaboost，GBDT，XGBoost</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-10-3">2-10-3
讲解GBDT的训练过程？</a></label></li>
</ul>
<p>用每个样本的残差训练下一棵树，直到残差收敛到某个阈值以下，或者树的总数达到某个上限为止。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-10-4">2-10-4
你觉得GBDT训练过程中哪些环节可以平行提升训练效率？</a></label></li>
</ul>
<p>决策树内部局部并行。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-10-5">2-10-5
GBDT的优点和局限性有哪些？</a></label></li>
</ul>
<p><strong>优点</strong></p>
<p>（1）预测阶段计算速度块，树与树之间可并行化计算</p>
<p>（2）在分布稠密的数据集上，泛化能力和表达能力都很好</p>
<p>（3）采用决策树作为弱分类器使得GBDT模型具有较好的可解释性和鲁棒性，能够自动发现特征间的高阶关系，并且不需要对数据进行特殊的预处理如归一化等</p>
<p><strong>缺点</strong></p>
<p>（1）GBDT在高维稀疏的数据集上，表现不如支持向量机或者神经网络</p>
<p>（2）GBDT在处理文本分类特征问题上，优势不如在处理数值特征时明显</p>
<p>（3）训练过程需要串行训练，只能在决策树内容采用一些局部并行手段提高训练速度</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-10-6">2-10-6
GBDT是否对异常值敏感，为什么？</a></label></li>
</ul>
<p><strong>GDBT对异常值敏感</strong>。对于回归类的问题，如果采用平方损失函数。当出现异常值时，后续模型会对异常值关注过多。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#2-10-7">2-10-7
如何防止GBDT过拟合？</a></label></li>
</ul>
<ol type="1">
<li><p>在工程应用中，通常利用下列公式来更新模型： <span class="math inline">\(f_{m}(\overrightarrow{\mathbf{x}})=f_{m-1}(\overrightarrow{\mathbf{x}})+\nu
h_{m}\left(\overrightarrow{\mathbf{x}} ; \Theta_{m}\right), \quad
0&lt;\nu \leq 1\)</span>。</p>
<p>其中 <span class="math inline">\(\nu\)</span>
称作<strong>学习率</strong>。</p>
<p>学习率是正则化的一部分，它可以降低模型更新的速度（需要更多的迭代）。</p>
<ul>
<li>经验表明：一个小的学习率 (<span class="math inline">\(\nu&lt;0.1\)</span>)
可以显著提高模型的泛化能力（相比较于<span class="math inline">\(\nu=1\)</span> ) 。</li>
<li>如果学习率较大会导致预测性能出现较大波动。</li>
</ul></li>
<li><p><code>Freidman</code> 从<code>bagging</code>
策略受到启发，采用<strong>随机梯度提升</strong>来修改了原始的梯度提升树算法。</p></li>
</ol>
<ul>
<li><p>每一轮迭代中，新的决策树拟合的是原始训练集的一个子集（而并不是原始训练集）的残差。</p>
<p>这个子集是通过对原始训练集的无放回随机采样而来。</p></li>
<li><p>子集的占比 <span class="math inline">\(f\)</span>
是一个超参数，并且在每轮迭代中保持不变。</p>
<ul>
<li>如果 <span class="math inline">\(f=1\)</span>
，则与原始的梯度提升树算法相同。</li>
<li>较小的<span class="math inline">\(f\)</span>
会引入随机性，有助于改善过拟合，因此可以视作一定程度上的正则化。</li>
<li>工程经验表明， <span class="math inline">\(0.5 \leq f \leq
0.8\)</span>会带来一个较好的结果。</li>
</ul></li>
<li><p>这种方法除了改善过拟合之外，另一个好处是：未被采样的另一部分子集可以用来计算包外估计误差。</p>
<p>因此可以避免额外给出一个独立的验证集。</p></li>
</ul>
<ol start="3" type="1">
<li><p>梯度提升树会<strong>限制每棵树的叶子结点包含的样本数量至少包含
<span class="math inline">\(m\)</span> 个样本</strong>，其中 <span class="math inline">\(m\)</span>为超参数。在训练过程中，一旦划分结点会导致子结点的样本数少于
<span class="math inline">\(m\)</span>，则终止划分。</p>
<p>这也是一种正则化策略，它会改善叶结点的预测方差。</p></li>
</ol>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="#2-10-8">2-10-8
在训练过程中哪些参数对模型效果影响比较大？这些参数造成影响是什么？</a></label></p>
<p>减小步长需要对应增加最大迭代次数</p>
<ol type="1">
<li><p><strong>n_estimators</strong>:
也就是弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说n_estimators太小，容易欠拟合，n_estimators太大，又容易过拟合，一般选择一个适中的数值。默认是100。在实际调参的过程中，我们常常将n_estimators和下面介绍的参数learning_rate一起考虑。</p></li>
<li><p><strong>learning_rate</strong>:
即每个弱学习器的权重缩减系数νν，也称作步长，在原理篇的正则化章节我们也讲到了，加上了正则化项</p></li>
<li><p><strong>subsample</strong>:
即我们在原理篇的正则化章节讲到的子采样，取值为(0,1]。注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是不放回抽样。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在[0.5,
0.8]之间，默认是1.0，即不使用子采样。</p></li>
</ol></li>
</ul>
<h3 id="k-means">k-means</h3>
<p>kmean的总体特点</p>
<ul>
<li><p>基于划分的聚类方法</p></li>
<li><p>类别k事先指定</p></li>
<li><p>以欧式距离平方表示样本之间的距离</p></li>
<li><p>以中心或样本的均值表示类别</p></li>
<li><p>以样本和其所属类的中心之间的距离总和为最优化的目标函数</p></li>
<li><p>得到的类别是平坦的、非层次化的</p></li>
<li><p>算法是迭代算法，不能保证全局最优</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-1">2-11-1
简述kmeans建模过程？</a></label></p>
<p>kmeans聚类是基于样本集合划分的聚类算法</p>
<p>（1）首先随机选择k个样本点作为初始聚类中心</p>
<p>（2）计算每个样本到类中心的距离，将样本逐个指派到与其最近的类中，得到一个聚类结果</p>
<p>（3）更新每个类的样本的均值，作为新的中心</p>
<p>（4）重复以上步骤，知道划分不再改变，收敛为止</p>
<p>kmeans的算法复杂度是<span class="math inline">\(O(mnk)\)</span>，其中m是样本位数，n是样本个数，k是类别个数。比层次聚类复杂度低。</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-2">2-11-2
Kmeans损失函数是如何定义？</a></label></p>
<p>样本与所属类的中心之间的距离的总和为损失函数 <span class="math display">\[
W(C) = \sum_{l=1}^k \sum_{C(i)=l} {||x_i - \overline{x}_l||}
\]</span> 其中 <span class="math inline">\(\overline{x}_l\)</span> 是第
<span class="math inline">\(l\)</span>
个类的均值或中心。相似的样本被聚到同类时，损失函数值最小。但是这是一个组合优化问题，n个样本分到k个类，可能的分法数目是指数级的，NP难问题。采样迭代的方法求解。</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-3">2-11-3
你是如何选择初始类族的中心点？</a></label></p>
<p><strong>初始类中心点的选择</strong></p>
<p>（1）可以用层次聚类对样本进行聚类，得到k个类时停止。然后从每个类中选取一个与中心距离最近的点。</p>
<p><strong>类别数k的选择</strong></p>
<p>k值需要预先指定，而在实际应用中最优的k值是不知道的。解决这个问题的一个方法是尝试用不同的k值聚类，检验各自得到聚类结果的质量，推测最优的k值</p>
<p>（1）一般地，类别数变小时，平均直径会增加；类别数变大超过某个值后，平均直径会不变；而这个值是最优的k值。实验时可以采用二分查找，快速找到最优的k值。</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-4">2-11-4
如何提升kmeans效率？</a></label></p>
<p>kmeans时间复杂度 <span class="math inline">\(O(nkt)\)</span>
n，k，t分别为样本数，聚类中心数，迭代轮次</p>
<p>（1）我们可以使用kd树以及ball
树（数据结构）来提高k-means算法的效率。（KNN计算的优化）</p>
<p>（2）并行计算</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-5">2-11-5
常用的距离衡量方法有哪些？他们都适用什么类型问题？</a></label></p>
<p>见 2-2-3</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-6">2-11-6
Kmeans对异常值是否敏感？为什么？</a></label></p>
<p>敏感，因为需要计算距离，使用传统的欧式距离度量方式。所以需要预处理离群点、数据归一化。</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-7">2-11-7
如何评估聚类效果？</a></label></p>
<p>知乎：https://zhuanlan.zhihu.com/p/53840697</p>
<p>（1）<strong>纯度</strong>（<em>Purity</em>）</p>
<p>我们把每个簇中最多的类作为这个簇所代表的类，然后计算正确分配的类的数量，然后除以
<span class="math inline">\(N\)</span> 。 <span class="math display">\[
(\Omega, \mathbb{C})=\frac{1}{N} \sum_{k} \max _{j}\left|\omega_{k} \cap
c_{j}\right|
\]</span> 其中 <span class="math inline">\(\Omega=\left\{\omega_{1},
\omega_{2}, \ldots, \omega_{K}\right\}\)</span> 是聚类结果的集合 <span class="math inline">\(\omega_{k}\)</span>表示第k个聚类的集合；<span class="math inline">\(\mathbb{C}=\left\{c_{1}, c_{2}, \ldots,
c_{J}\right\}\)</span> 是原始分类的集合，<span class="math inline">\(c_j\)</span>表示第j个分类的集合。</p>
<figure>
<img src="https://pic4.zhimg.com/v2-e19781ffa33cc60608fad3fa60d5769f_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>purity优点：方便计算，值在0~1之间；</p>
<p>缺点：当簇的数量很多的时候，容易达到较高的纯度——特别是，如果每个文档都被分到独立的一个簇中，那么计算得到的纯度就会是1。因此，不能简单用纯度来衡量聚类质量与聚类数量之间的关系。</p>
<p>（2）<strong>归一化化互信息</strong>（NMI, <em>Normalized Mutual
Information</em>）</p>
<p>NMI越大，聚类效果越好 <img src="https://www.zhihu.com/equation?tex=%5Ctext%7BNMI%7D%28%5COmega%2C+C%29+%3D+%5Cfrac%7BI%28%5COmega%3B+C%29%7D%7B%28H%28%5COmega%29%2BH%28C%29%2F2%29%7D%5C%5C" alt="[公式]"></p>
<p>其中, <img src="https://www.zhihu.com/equation?tex=I" alt="[公式]">
表示互信息(Mutual Information), H 为熵，当 <img src="https://www.zhihu.com/equation?tex=+%5Clog" alt="[公式]"> 取 2
为底时，单位为 bit，取 e 为底时单位为 nat。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bsplit%7D+I%28%5COmega%3B+C%29+%26%3D%5Csum_%7Bk%7D%5Csum_%7Bj%7DP%28w_k+%5Ccap+c_j%29%5Clog+%5Cfrac%7BP%28w_k+%5Ccap+c_j%29%7D%7BP%28w_k%29P%28c_j%29%7D%5C%5C+%26%3D+%5Csum_%7Bk%7D%5Csum_%7Bj%7D%5Cfrac%7B%7Cw_k+%5Ccap+c_j%7C%7D%7BN%7D%5Clog+%5Cfrac%7BN%7Cw_k+%5Ccap+c_j%7C%7D%7B%7Cw_k%7C%7Cc_j%7C%7D+%5Cend%7Bsplit%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中, <img src="https://www.zhihu.com/equation?tex=P%28w_k%29%2CP%28c_j%29%2CP%28w_k+%5Ccap+c_j%29+" alt="[公式]"> 可以分别看作样本 (document) 属于聚类簇 <img src="https://www.zhihu.com/equation?tex=w_k" alt="[公式]"> , 属于类别
<img src="https://www.zhihu.com/equation?tex=c_j" alt="[公式]"> ,
同时属于两者的概率。第二个等价式子则是由概率的极大似然估计推导而来。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bsplit%7D+H%28%5COmega%29+%26%3D+-%5Csum_%7Bk%7DP%28w_k%29%5Clog+P%28w_k%29%5C%5C+%26%3D+-%5Csum_%7Bk%7D+%5Cfrac%7B%7Cw_k%7C%7D%7BN%7D%5Clog+%5Cfrac%7B%7Cw_k%7C%7D%7BN%7D+%5Cend%7Bsplit%7D%5C%5C" alt="[公式]">互信息 <img src="https://www.zhihu.com/equation?tex=I%28%5COmega%3B+C%29" alt="[公式]"> 表示给定类簇信息 <img src="https://www.zhihu.com/equation?tex=C" alt="[公式]">
的前提条件下,类别信息 <img src="https://www.zhihu.com/equation?tex=%5COmega" alt="[公式]">
的增加量,或者说其不确定度的减少量。直观地,互信息还可以写出如下形式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=I%28%5COmega%3B+C%29+%3D+H%28%5COmega%29+-+H%28%5COmega+%7C+C%29%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>（3）<strong>兰德指数</strong>（RI, <em>Rand
Index</em>）能度量聚类过程中的假阳性和假阴性结果的惩罚</p>
<p>兰德指数 (Rand index, RI),
将聚类看成是一系列的决策过程,即对文档集上所有 <img src="https://www.zhihu.com/equation?tex=N%28N-1%29%2F2" alt="[公式]">个文档 (documents)
对进行决策。当且仅当两篇文档相似时,我们将它们归入同一簇中。</p>
<p>Positive:</p>
<ul>
<li>TP 将两篇相似文档归入一个簇 (同 - 同)</li>
<li>TN 将两篇不相似的文档归入不同的簇 (不同 - 不同)</li>
</ul>
<p>Negative:</p>
<ul>
<li>FP 将两篇不相似的文档归入同一簇 (不同 - 同)</li>
<li>FN 将两篇相似的文档归入不同簇 (同- 不同) (worse)</li>
</ul>
<p>RI 则是计算「正确决策」的比率(精确率, accuracy).</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=RI+%3D+%5Cfrac%7BTP%2BTN%7D%7BTP%2BFP%2BTF%2BFN%7D%3D%5Cfrac%7BTP%2BTN%7D%7BC%5E%7B2%7D_%7BN%7D%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>（4）<strong>熵</strong>（Entropy）</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-8">2-11-8
超参数类的个数k如何选取？</a></label></p>
<p>（1）<strong>手肘法</strong></p>
<p>尝试不同的K值，并将不同K值所对应的损失函数化成折线，横轴为K的取值，纵轴为误差平方和所定义的损失函数。K值越大，距离和越小。当K=K'时，存在一个拐点，像人的肘部。当
<span class="math inline">\(K\in(1,K')\)</span>，曲线急速下降；当
<span class="math inline">\(K&gt;K'\)</span>，曲线趋于平稳。手肘法认为拐点就是K的最佳值。</p>
<p>（2）<strong>Gap Statistic</strong></p>
<p>手肘法是一个经验方法，缺点是不够自动化。Gap
Statistic方法的优点是，不需要肉眼判断，只需要找到最大Gap
statistic对应的K即可。因此该方法适用于批量化作业。 <span class="math display">\[
{\rm Gap}(K) = E({\rm log}D_k) - {\rm log}D_k
\]</span> 当分为K簇时，对应的损失函数记为 <span class="math inline">\(D_k\)</span>，<span class="math inline">\(E({\rm
log}D_k)\)</span>是 <span class="math inline">\({\rm log}D_k\)</span>
的期望，通过蒙特卡洛模拟产生。$(K) $
的物理含义是随机样本的损失与实际样本的损失之差。当$(K)
$取最大时，是样本的损失应该相对较小。</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-9">2-11-9
Kmeans有哪些优缺点？是否有了解过改进的模型，举例说明？</a></label></p>
<p><strong>优点</strong></p>
<p>（1）对于大数据集，kmeans聚类算法相对是可伸缩和高效的，它的计算复杂度是<span class="math inline">\(O(NKt)\)</span>
接近线性，其中N是样本数，K是聚类的簇数，t是迭代的轮数。</p>
<p>（2）尽管算法经常以局部最优解结束，但一般情况下达到的局部最优已经可以满足聚类的需求</p>
<p><strong>缺点</strong></p>
<p>（1）受初值和离群点的影响，每次的结果不稳定</p>
<p>（2）结果通常不是全局最优而是局部最优解</p>
<p>（3）无法很好地解决数据簇分布差别比较大的情况（比如一类是另一类样本数量的100倍）</p>
<p>（4）不太适用于离散分类</p>
<p>（5）K值需要人工预先确定，且该值和真实的数据分布未必吻合【最大缺点】</p>
<p>（6）样本点只能被划分到单一的类中</p>
<p><strong>如何对Kmeans进行调优</strong></p>
<p>（1）数据归一化和离群点处理</p>
<p>​
Kmeans聚类本质上是一种基于欧式距离度量的数据划分方法，均值和方差大的维度对聚类结果产生决定性影响。未做归一化无法直接参与计算；离群点或少量噪声会对均值产生较大影响，导致中心偏移。</p>
<p>（2）合理选择K值</p>
<p>​ 手肘法、Gap Statistic（不需要肉眼判断，只需要找到最大Gap
statistic对应的K）</p>
<p>（3）采用核函数</p>
<p>​
核聚类。通过非线性映射，将输入空间中的数据点映射到高维的特征空间中，并在新的特征空间中进行聚类。非线性映射增加了数据点线性可分的概率，从而在经典的聚类算法失效的情况下，通过引入核函数可以达到更为准确的聚类效果</p>
<p><strong>改进的模型</strong></p>
<p>（1）kmeans++ （对初始值选择的改进）</p>
<p>​
原始的kmeans算法最开始随机选取数据集中K个点作为聚类中心，而kmeans++按照以下思想选取k个聚类中心：假设已经选取了n个初始聚类中心（0&lt;n&lt;k），则在选取第n+1个聚类中心时，距离当前n个聚类中心越远的点会有更高的概率被选为第n+1个聚类中心。在选取第一个聚类中心时同样通过随机的方法。这符合我们的直觉：聚类中心互相离得越远越好。后续步骤与kmeans一致。</p>
<p>（2）ISODATA（K值不确定时）</p>
<p>​ ISODATA全称是
迭代自组织数据分析法。在kmeans算法中，聚类个数K值需要预先人为确定，并且在整个算法过程中无法更改。当遇到高维度、海量数据时，难以准确估计出K的大小。ISODATA的思想是：当属于某个类别的样本数过少时，把该类别去除（合并操作）；当属于某个类别的样本数过多、分散程度大时，把该类别分为两个子类别（分裂操作）。</p>
<p>​ 缺点是需要制定的参数比较多，4个：预期聚类中心数目 <span class="math inline">\(K_0\)</span>、每个类所要求的最少样本数目 <span class="math inline">\(N_{min}\)</span>、最大方差 <span class="math inline">\(\sigma\)</span> 、两个聚类中心之间所允许最小距离
<span class="math inline">\(D_{min}\)</span>。</p>
<p>（3）模糊C均值，高斯混合模型</p>
<p>​ 样本不划分到单一的类中，即软聚类。</p>
<p>​
<strong>高斯混合模型</strong>：假设不同簇中的样本各自服从不同的高斯分布，由此得到的聚类算法称为高斯混合模型。在该假设下，每个单独的分模型都是标准高斯模型，其均值
<span class="math inline">\(u_i\)</span> 和方差 <span class="math inline">\(\Sigma_i\)</span>
是待估计的参数。瓷王每个分模型还都有一个参数 <span class="math inline">\(\pi_i\)</span>，可以理解为权重或者生成数据的概率。
<span class="math display">\[
p(x)=\sum_{i=1}^{K}\pi_iN(x|u_i,\Sigma_i)
\]</span> ​ 高斯混合模型是一个生成式模型。</p>
<p>相比Kmeans的优点：可以给出一个样本属于某类的概率是多少；不仅仅可以用于聚类，还可以用于概率密度的估计；并且可以用于生成新的样本点。</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-10">2-11-10
试试证明kmeans算法的收敛性</a></label></p>
<p>kmeans聚类属于启发式方法，不能保证收敛到全局最优，初始中心的选择会直接影响聚类结果。</p>
<p>类中心在聚类过程中会发生移动，但是往往不会移动太大，因为在每一步，样本被分到与其最近的中心的类中。</p></li>
<li><p><label><input type="checkbox"><a href="#2-11-11">2-11-11
除了kmeans聚类算法之外，你还了解哪些聚类算法？简要说明原理</a></label></p>
<p><strong>层次聚类</strong>（hierarchical
clustering）假设类别之间存在层次结构，分为聚合（自下而上）和分裂（自上而下）两种方法。<strong>聚合法</strong>开始讲每个样本各自分到一个类；之后将相邻最近的两类合并（根据类间距离最小合并规则），建立一个新的类，重复此操作直到满足停止条件（类的个数达到阈值/类的直径超过阈值）；得到层次化的分类。<strong>分裂法</strong>开始讲所有样本分到一个类；之后将已有类中相距最远的样本分到两个新的类，重复此操作直到满足停止条件；得到层次化的分类。</p>
<p>层次聚类算法复杂度：<span class="math inline">\(O(n^3m)\)</span>
其中n是样本个数，m是样本维数。</p>
<p><strong>k-means聚类</strong>是基于中心的聚类方法，通过迭代，将样本分到k个类别中，使得每个样本与其所属类的中心或均值最近；得到k个平坦的、非层次化的类别。</p>
<p>基于密度的方法DBSCAN</p>
<p>谱聚类</p></li>
<li><p><label><input type="checkbox"><a href="">kmeans初始化为什么要从数据中随机挑k个，可以生成k个随机点吗？</a></label></p>
<p>不可以；如果是用随机值，可能某个簇在第一轮就没有任何节点，无法继续计算</p></li>
</ul>
<h3 id="pca降维">PCA降维</h3>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="#2-12-1">2-12-1
为什么要对数据进行降维？它能解决什么问题？</a></label></p>
<p>高维（多变量）数据，很难观察变量的样本区分能力，也很难观察样本之间的关系。降维是将样本集合中的样本从高维空间转换到低维空间。假设样本原本存在于低维空间，或近似存在与低维空间，通过降维则可以更好地表示样本数据的结构，即更好地表示样本之间的关系。降维有线性降维和非线性降维。</p>
<p>维度灾难</p></li>
<li><p><label><input type="checkbox"><a href="#2-12-1">2-12-2
你是如何理解维度灾难？</a></label></p>
<p>特征数量超过一定值的时候，分类器的效果反而下降。原因：特征数过多，过拟合</p></li>
<li><p><label><input type="checkbox"><a href="#2-12-1">2-12-3
PCA主成分分析思想是什么？</a></label></p>
<p>变量之间可能存在相关性，以致增加了分析的难度。考虑用少数不想管的变量来替代相关的变量，用来表示数据，并且要求能保留数据中的大部分信息。</p>
<p>PCA利用正交变换把线性相关变量表示的观测数据转换为少数几个由线性无关变量表示的数据，线性无关的变量称为主成分。PCA属于降维方法。</p></li>
<li><p><label><input type="checkbox"><a href="#2-12-1">2-12-4
如何定义主成分？</a></label></p>
<p>协方差矩阵的特征向量</p></li>
<li><p><label><input type="checkbox"><a href="#2-12-1">2-12-5
如何设计目标函数使得降维达到提取主成分的目的？</a></label></p>
<p>PCA目标函数：最大化投影方差。因为方差表示新变量的信息量大小。</p></li>
<li><p><label><input type="checkbox"><a href="#2-12-1">2-12-6
PCA有哪些局限性？如何优化</a></label></p>
<p>（1）无法进行非线性降维</p>
<p>​ 通过核映射对PCA进行扩展得到核主成分分析（KPCA）</p>
<p>​
通过流形映射的降维方法，比如等距映射、局部线性嵌入（LLE）、拉普拉斯特征映射等</p>
<p>（2）无监督的，算法没有考虑数据的标签，只是把把元数据映射到方差比较大的方向</p>
<p>​ 有监督的降维方法：线性判别分析 LDA</p></li>
<li><p><label><input type="checkbox"><a href="#2-12-1">2-12-7
线性判别分析和主成分分析在原理上有何异同？在目标函数上有何区别和联系？</a></label></p>
<p>PCA选择的是投影后数据方差最大的方向。由于PCA是无监督的，因此假设方差越大，信息量越多，用主成分来表示原始数据可以去除冗余的维度，达到降维。</p>
<p>LDA选择的是投影后类内方差最小，类间方差最大的方向。其用到了类别标签信息，为了找到数据中具有判别性的维度，使得原始数据在这些方向投影后，不同类别尽可能区分开。</p></li>
</ul>
<h2 id="深度学习">3、 深度学习</h2>
<h3 id="dnn">DNN</h3>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#3-1-1">3-1-1
描述一下神经网络？推倒反向传播公式？</a></label></li>
<li><label><input type="checkbox"><a href="#3-1-2">3-1-2
讲解一下dropout原理？</a></label></li>
</ul>
<p>在神经网络前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。</p>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="#3-1-3">3-1-3
梯度消失和梯度膨胀的原因是什么？有什么方法可以缓解？</a></label></p>
<p>（1）深度学习的网络层数太多，在进行反向传播时根据链式法则，要连乘每一层梯度值</p>
<p>（2）每一层的梯度值是由，非线性函数的导数以及本层的权重相乘得到的，这样非线性的导数的大小和初始化权重的大小会直接影响是否发生梯度弥散或者梯度爆炸</p>
<p>注：任何网络都有可能发生梯度弥散或者梯度爆炸，这是深度学习的基本性质决定的，无法避免。</p></li>
</ul>
<p>梯度消失（梯度弥散）的原因：</p>
<p>解决方法：</p>
<p>梯度爆炸的原因：</p>
<p>解决方法：</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#3-1-4">3-1-4
什么时候该用浅层神经网络，什么时候该选择深层网络</a></label></li>
<li><label><input type="checkbox"><a href="#3-1-5">3-1-5
Sigmoid、Relu、Tanh激活函数都有哪些优缺点？</a></label></li>
</ul>
<p><strong>Sigmoid</strong> <span class="math display">\[
f(x) = \frac{1}{1+ exp(-x)} \\
f'(x) = f(x)(1-f(x))
\]</span> <span class="math display">\[
\begin{aligned}
f'(z) &amp;= (\frac{1}{1+e^{-z}})'
\\
&amp;= \frac{e^{-z}}{(1+e^{-z})^{2}}
\\
&amp;= \frac{1+e^{-z}-1}{(1+e^{-z})^{2}}  
\\
&amp;= \frac{1}{(1+e^{-z})}(1-\frac{1}{(1+e^{-z})})
\\
&amp;= f(z)(1-f(z))
\\
\end{aligned}
\]</span></p>
<p>优点：</p>
<p>缺点：（1）需要计算指数，速度慢（2）会产生梯度消失问题</p>
<p><strong>Tanh</strong> $$ f(x) = tanh(x) = \</p>
<p>f'(x) = 1 - (f(x))^2 $$ 优点：</p>
<p>缺点：（1）需要计算指数，速度慢（2）会产生梯度消失问题</p>
<p><strong>Relu</strong> <span class="math display">\[
f(x) = max(x,0) \\
\begin{equation}
f'(x)=\left\{
\begin{aligned}
    1,x&gt;0 \\
    0,x\leq0 \\
\end{aligned}
\right.
\end{equation}
\]</span>
优点：（1）从计算的角度上，sigmoid和tanh都需要计算指数，复杂度高，而ReLU只需要一个阈值就可以得到激活值</p>
<p>（2）ReLU的非饱和性可以有效解决梯度消失的问题，提供相对宽的激活边界</p>
<p>（3）ReLU的单侧抑制提供了网络的稀疏表达能力（防止过拟合）</p>
<p>缺点：（1）训练过程中会导致神经元死亡的问题</p>
<p>缺点：（1）训练过程中会导致神经元死亡的问题</p>
<p><strong>Leaky ReLU</strong> $$ <span class="math display">\[\begin{equation}
f(x)=\left\{
\begin{aligned}
    x,x&gt;0 \\
    ax,x\leq0 \\
\end{aligned}
\right.
\end{equation}\]</span> \</p>
f'(x)={
<span class="math display">\[\begin{aligned}
    1,x&gt;0 \\
    a,x\leq0 \\
\end{aligned}\]</span>
<p>. $$ 优点：实现单侧抑制，又保留了部分附体度信息以致不完全消失</p>
<p>缺点：a值需要人工选择</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#3-1-6">3-1-6
写出常用激活函数的导数</a></label></li>
</ul>
<p><img src="https://cdn.mathpix.com/snip/images/lch_19BxC77kvBQ20p3no_Z71liDpIIAvdPnxoYWoYA.original.fullsize.png"></p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#3-1-7">3-1-7
训练模型的时候，是否可以把网络参数全部初始化为0？为什么</a></label></li>
</ul>
<p>不可以；参数全部为0时，网络不同神经元的输出必然相同，相同输出则导致梯度更新完全一样，会使得更新后的参数仍然保持完全相同。从而使得模型无法训练。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#3-1-8">3-1-8
Batchsize大小会如何影响收敛速度？</a></label></li>
</ul>
<h3 id="cnn">CNN</h3>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#3-2-1">3-2-1
简述CNN的工作原理？</a></label></li>
</ul>
<p>CNN利用了图像的三个性质：</p>
<p>（1）图像的pattern通常比整张图像小</p>
<p>（2）通用的patterns会出现在图像的不同区域</p>
<p>（3）对图像进行子采样并不影响图像的识别</p>
<p>CNN通过卷积层+pooling层不断堆积，从小的pattern开始不断识别到大的pattern，从而识别整张图像。</p>
<blockquote>
<p>CNN适合处理什么问题</p>
</blockquote>
<p>具有以上三个特性的问题</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#3-2-2">3-2-2
卷积核是什么？选择大卷积核和小卷积核有什么影响？</a></label></li>
<li><label><input type="checkbox"><a href="#3-2-3">3-2-3
你在实际应用中如何设计卷积核？</a></label></li>
<li><label><input type="checkbox"><a href="#3-2-4">3-2-4
为什么CNN具有平移不变性？</a></label></li>
</ul>
<p>参数共享的物理意义是使得卷积层具有平移等变性。在卷积神经网路中，卷积核中的每一个元素将作用于每一次局部输入的特定位置上。</p>
<p>假如图像中有一只猫，无论它出现在图像中的任何位置，我们都应该将它识别为猫，也就是说神经网络的输出对于平移变换来说应当是等变的。</p>
<ul class="task-list">
<li><label><input type="checkbox"><a href="#3-2-5">3-2-5
Pooling操作是什么？有几种？作用是什么？</a></label></li>
</ul>
<p>将Pooling核覆盖区域中所有值的平均值（最大值）作为汇合结果</p>
<p>average-pooling，Max-polling，stochastic-polling（对输入数据中的元素按照一定概率大小随机选择，元素值大的activattion被选中的概率大）</p>
<p>Pooling操作后的结果相比起输入减小了，是一种<strong>降采样</strong>操作。</p>
<p>pooling层的作用</p>
<ol type="1">
<li><p><strong>特征不变性（feature
invariant）</strong>。pooling操作使模型更关注是否存在某些特征而不是特征具体的位置。</p></li>
<li><p><strong>数据降维</strong>。降采样的操作使模型可以抽取更广范围的特征，同时减小了下一层输入大小，进而减少计算量和参数个数</p></li>
</ol>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="#3-2-6">3-2-6
为什么CNN需要pooling操作？</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#3-2-7">3-2-7
什么是batchnormalization？它的原理是什么？在CNN中如何使用？</a></label></p>
<p>为了解决内部协方差偏移（ICS）问题提出的。高层网络需要不断适应底层输出的分布，导致</p>
<p>对于某一层某个神经元d维输入<span class="math inline">\(\mathrm{x}=\left(x^{(1)} \ldots
x^{(d)}\right)\)</span>，对每一个维度进行批标准化 <span class="math display">\[
\widehat{x}^{(k)}=\frac{x^{(k)}-\mathrm{E}\left[x^{(k)}\right]}{\sqrt{\operatorname{Var}\left[x^{(k)}\right]}}
\]</span> <img src="C:\Users\Kevin\AppData\Roaming\Typora\typora-user-images\1567511107747.png" alt="1567511107747"></p>
<figure>
<img src="https://cdn.mathpix.com/snip/images/3nV904o42ao1MH6C2EGrKbM59gU5lXNzzy5TFJ5Le_w.original.fullsize.png" alt="1567511156114">
<figcaption aria-hidden="true">1567511156114</figcaption>
</figure>
<p><strong>BN训练和测试的区别</strong></p>
<p>先说结论：并不是测试时的mean,var的计算方式与训练时不同，而是测试时的mean,var在训练完成整个网络中就全部固定了。</p>
<p>由于在优化网络的时候，我们一般采用的是batch梯度下降。所以在训练过程中，只能计算当前batch样本上的mean和var。但是我们做的normalization是对于整个输入样本空间，因此需要对<strong>每个batch</strong>的mean,
var做<strong>指数加权平均</strong>来将batch上的mean和var近似成<strong>整个样本空间</strong>上的mean和var.</p>
<p>而在测试Inference过程中，一般不必要也不合适去计算测试时的batch的mean和var，比如测试仅对单样本输入进行测试时，这时去计算单样本输入的mean和var是完全没有意义的。因此会直接拿训练过程中对整个样本空间估算的mean和var直接来用。此时对于inference来说，BN就是一个线性变换。</p></li>
<li><p><label><input type="checkbox"><a href="#3-2-8">3-2-8
卷积操作的本质特性包括稀疏交互和参数共享，具体解释这两种特性以其作用？</a></label></p></li>
</ul>
<p><strong>稀疏交互</strong>：每个神经元的只跟上一层的某些神经元连接（vs
DNN全连接），用到较少参数</p>
<p><strong>参数共享</strong>：同一层的不同神经元之间共享部分权重，用到比原来更少的参数</p>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="#3-2-9">3-2-9
你是如何理解fine-tune？有什么技巧</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#3-2-10">3-2-10
怎么观察CNN每个神经元学到了什么</a></label></p></li>
</ul>
<p>假设第k个filter是一个11 x 11
的矩阵（一个神经元），可以用以下系数来表示第k个filter被激活的程度 <span class="math display">\[
a^k = \sum_{i=1}^{11} \sum_{i=1}^{11} a_{ij}^k
\]</span> 并通过梯度上升找到使 <span class="math inline">\(a^k\)</span>
最大的x，该x表示的图像表示该filter对应的检测纹路。 <span class="math display">\[
x^* = \mathop{arg \ \rm max}\limits_{x}  \ a^k
\]</span></p>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="">resnet
skip-connection</a></label></p>
<p>假如，我们在这个block的旁边加了一条“捷径”（如图5橙色箭头），也就是常说的“skip
connection”。假设左边的上一层输入为x，虚线框的输出为f(x)，上下两条路线输出的激活值相加为h(x)，即h(x)
= F(x) + x，得出的h(x)再输入到下一层。</p>
<figure>
<img src="https://pic2.zhimg.com/v2-79e9feb7ee38f64c6cc15c501327b7bd_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>图6</p>
<p>当进行后向传播时，右边来自深层网络传回来的梯度为1，经过一个加法门，橙色方向的梯度为dh(x)/dx=1，蓝色方向的梯度也为1。这样，经过梯度传播后，现在传到前一层的梯度就变成了[1,
0.0001,
0.01]，多了一个“1”！<strong>正是由于多了这条捷径，来自深层的梯度能直接畅通无阻地通过，去到上一层，使得浅层的网络层参数等到有效的训练！</strong></p></li>
</ul>
<h3 id="rnn">RNN</h3>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="#3-3-1">3-3-1
简述RNN模型原理，说说RNN适合解决什么类型问题？为什么</a></label></p>
<p>RNN能够很好地处理文本数据变长并且有序的输入序列。它模拟了人阅读一篇文章的顺序，从前到后阅读文章中的每一个单词，将前面阅读到的有用信息编码到状态变量中去，从而拥有一定的记忆能力，可以更好地理解之后的文本。</p>
<p>不定长；下一时刻的状态于当前输入以及当前状态有关</p></li>
<li><p><label><input type="checkbox"><a href="#3-3-2">3-3-2
RNN和DNN有何异同？</a></label></p>
<p>相同点：一个长度为T的序列用xun</p>
<p>不同点：RNN的循环性，序列的每个时刻都执行相同的任务，每个时刻的输出依赖于当前时刻的输入和上一时刻的隐藏状态</p></li>
<li><p><label><input type="checkbox"><a href="#3-3-3">3-3-3
RNN为什么有记忆功能？</a></label></p>
<p>RNN是包含<u>循环</u>的网络，将前面输入的有用信息编码到状态变量中去，从而拥有了一定的记忆功能。</p></li>
<li><p><label><input type="checkbox"><a href="#3-3-4">3-3-4
长短期记忆网络LSTM是如何实现长短期记忆功能的？</a></label></p>
<p>LSTM可以对有价值的信息进行长期记忆。</p>
<p>与RNN不同的是，LSTM记忆单元c的转移不一定完全取决于激活函数计算得到的状态，还由输入门和遗忘门共同控制。</p>
<p>在一个训练好的LSTM模型中，当输入序列中没有重要信息时，遗忘门的值接近于1，输入门的值接近于0，表示过去的记忆被完整保存，而输入信息被放弃，从而实现长期记忆功能。</p>
<p>当输入序列中存在重要信息时，LSTM应把他存入记忆中，此时输入门接近于1；</p>
<p>当输入序列中存在重要信息且该信息意味着之前的记忆不再重要时，输入门的值接近1，遗忘门的值接近0。</p></li>
<li><p><label><input type="checkbox"><a href="#3-3-5">3-3-5
长短期记忆网络LSTM各模块都使用什么激活函数，可以使用其他激活函数么？</a></label></p>
<p>百面p245。输入门、输出门、遗忘门使用sigmoid函数作为激活函数；在生成候选记忆时，使用双曲正切函数Tanh作为激活函数。</p>
<p>首先这两个激活函数都是饱和的，如果使用非饱和函数如ReLU，将难以实现门控的效果。</p>
<p>sigmoid作为门控信号的原因：sigmoid函数的输出在0~1之间，符合门控的物理定义。并且是饱和的，当输入较大或者较小时，其输出会非常接近1或0，从而保证该门的开或关。</p>
<p>Tanh用于生成候选记忆的原因：输出在
-1~1之间，这与大多数场景下特征分布式以0为中心相吻合；并且Tanh函数在输入为0附近相比sigmoid有更大的梯度，通常使模型收敛更快。</p></li>
<li><p><label><input type="checkbox"><a href="#3-3-6">3-3-6
GRU和LSTM有何异同</a></label></p>
<p>GRU：（1）将遗忘门和输入门合成了一个单一的更新门，只有两个门：更新门、复位门。（2）GRU不再区分cell的状态<span class="math inline">\(\overrightarrow{\mathrm{C}}\)</span>和cell的输出<span class="math inline">\(\overrightarrow{\mathbf{h}}\)</span>。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/42741-dd3d241fa44a71c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp">
reset gate <span class="math inline">\(r_t\)</span>：计算候选隐层 <span class="math inline">\(\tilde{h}_{t}\)</span> 时用来控制需要
保留多少之前的记忆 <span class="math inline">\(h_{t-1}\)</span>，比如如果 <span class="math inline">\(r_t\)</span> 为0，那么<span class="math inline">\(\tilde{h}_{t}\)</span>只包含当前词的信息。</p>
<p>update gate <span class="math inline">\(z_t\)</span>：控制需要从前一时刻的隐藏层<span class="math inline">\(h_{t-1}\)</span>中遗忘多少信息，需要加入多少当前
时刻的隐藏层信息 <span class="math inline">\(\tilde{h}_{t}\)</span>，最后得到 <span class="math inline">\(h_{t}\)</span></p>
<blockquote>
<p>一般来说那些具有短距离依赖的单元reset gate比较活跃（如果 <img src="https://www.zhihu.com/equation?tex=r_t" alt="[公式]"> 为1，而
<img src="https://www.zhihu.com/equation?tex=z_t" alt="[公式]"> 为0
那么相当于变成了一个标准的RNN，能处理短距离依赖），具有长距离依赖的单元update
gate比较活跃。</p>
</blockquote>
<p><strong>相同点</strong></p>
<p>（1）都会有门操作，决定是否保留上时刻的状态，和是否接收此时刻的外部输入，LSTM
是用遗忘门（forget gate <span class="math inline">\(f_t\)</span>）和输入门（input gate <span class="math inline">\(i_t\)</span>）来做到的，GRU
则是只用了一个更新门（update gate <span class="math inline">\(z_t\)</span> ）</p>
<p>（2）遗忘门或者更新门选择不重写（overwritten）内部的
memory，那么网络就会一直记住之前的重要特征，那么会对当前或者未来继续产生影响。缓解梯度消失。</p>
<p><strong>不同点</strong></p>
<p>（1）首先就是 LSTM 有一个输出门来控制 memory content
的曝光程度（exposure），而 GRU 则是直接输出。</p>
<p>（2）另一点是要更新的 new memory content 的来源也不同。<span class="math inline">\(\tilde{h}_{t}\)</span>会通过重置门（reset gate）
控制从<span class="math inline">\(h_{t-1}\)</span> 中得到信息的力度，而
<span class="math inline">\(\tilde{c}_{t}\)</span>
则没有，而是直接输入<span class="math inline">\(h_{t-1}\)</span>。</p>
<p>（3）相同个数参数的情况下，GRU 会比 LSTM 稍好一些</p></li>
<li><p><label><input type="checkbox"><a href="#3-3-7">3-3-7
什么是Seq2Seq模型？该模型能解决什么类型问题？</a></label></p>
<p>seq2seq模型是将一个序列信号，通过编码和解码生成一个新的序列信号，输入和输出序列的长度实现并不知道。seq2seq的模型的核心思想由编码输入和解码输出两个环节构成。在经典的实现中，编码器和解码器各由一个循环神经网络构成，两个循环神经网络是共同训练的。</p>
<p>解决问题：机器翻译、语音识别、自动对话</p></li>
<li><p><label><input type="checkbox"><a href="#3-3-8">3-3-8
注意力机制是什么？Seq2Seq模型引入注意力机制主要解决什么问题？</a></label></p>
<p>编码-解码架构的主要缺点：编码器<code>RNN</code>输出的上下文<code>C</code>的维度太小，难以恰当的概括一个长的输入序列的完整信息。</p>
<ul class="task-list">
<li><label><input type="checkbox">注意力机制主要解决问题：</label></li>
</ul>
<p>（1）随着输入序列增长，模型性能发生显著下降。</p>
<p>​
因为编码时输入序列的全部信息压缩到了一个定长向量表示中。随着序列增长，句子越前面的词的信息丢失就越严重。</p>
<p>（2）seq2seq输出序列中，常常会损失部分输入序列的信息。</p>
<p>​
这是因为在解码时，当前词及对应的源语言词的上下文信息和位置信息在编解码过程中丢失了。</p>
<p>原编码-解码架构</p>
<figure>
<img src="http://huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/imgs/dl_rnn/decoder_encoder.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>加入attention</p>
<figure>
<img src="http://huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/imgs/dl_rnn/attention.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>attention
本身可以理解为一种<strong>对齐关系</strong>，<strong>给出了模型输入、输出之间的对齐关系，解释了模型到底学到了什么知识。</strong></p>
<ul class="task-list">
<li><label><input type="checkbox">注意力打分函数的计算方式</label></li>
</ul>
<figure>
<img src="C:\Users\Kevin\AppData\Roaming\Typora\typora-user-images\1566132296775.png" alt="1566132296775">
<figcaption aria-hidden="true">1566132296775</figcaption>
</figure>
<p><img src="https://cdn.mathpix.com/snip/images/kLGt8ZRlTjA0PT7LYTuqIC2-ePp9Eh30KX5HANtYs4o.original.fullsize.png"></p>
<ul class="task-list">
<li><label><input type="checkbox">attention的分类</label></li>
</ul>
<p><strong>global attention vs local attention</strong></p>
<p>上述的 <code>attention</code> 机制中为了计算上下文向量 <span class="math inline">\(\overrightarrow{\mathbf{c}}_{i}\)</span>，
需要考虑 <code>encoder</code>
的所有隐向量（<code>global attention</code>）。当输入序列较长时（如一段话或一篇文章），计算效率较低。</p>
<p><code>local attention</code> <u>在计算上下文向量 <span class="math inline">\(\overrightarrow{\mathbf{c}}_{i}\)</span>
时只需要考虑 <code>encoder</code>
的部分隐向量：首选预测<code>encoder</code> 端对齐的位置 <span class="math inline">\(p_{i}\)</span>，然后基于位置 <span class="math inline">\(p_{i}\)</span> 选择一个窗口来计算上下文向量 <span class="math inline">\(\overrightarrow{\mathbf{c}}_{i}\)</span>
。</u></p>
<p><strong>self attention</strong></p>
<p>传统的 <code>attention</code> 是基于<code>encoder</code> 端和
<code>decoder</code> 端的隐向量来计算
<code>attention</code>的，得到的是输入序列的每个 <code>input</code>
和输出序列的每个 <code>output</code> 之间的依赖关系。</p>
<p><code>self attention</code> 计算三种 <code>attention</code>：</p>
<ul>
<li>在<code>encoder</code> 端计算自身的
<code>attention</code>，捕捉<code>input</code> 之间的依赖关系。</li>
<li>在 <code>decoder</code> 端计算自身的
<code>attention</code>，捕捉<code>output</code> 之间的依赖关系。</li>
<li>将 <code>encoder</code> 端得到的 <code>self attention</code> 加入到
<code>decoder</code> 端得到的
<code>attention</code>中，捕捉输入序列的每个 <code>input</code>
和输出序列的每个 <code>output</code> 之间的依赖关系。</li>
</ul></li>
<li><p><label><input type="checkbox"><a href="">RNN的长期依赖（Long-Term
Dependencies）问题是什么？怎么解决</a></label></p>
<p>长期依赖问题是：随着输入序列的增长，模型的性能发生显著下降，RNN难以捕捉长距离输入之间的依赖。</p>
<p>从结构上来看，理论上RNN可以学习捕捉到长距离依赖，但是实践中使用BPTT算法学习的RNN并不能成功捕捉长距离的医疗关系，主要源于深度神经网络中的<strong>梯度消失</strong>。</p>
<p>解决方法：</p>
<p>（1）LSTM、GRU等模型加入门控机制，捕捉长期记忆，很大程度上弥补了梯度消失</p>
<p>（2）残差结构</p>
<p>（2）设计多个时间尺度的模型：在细粒度的时间尺度上处理近期信息、在粗粒度时间尺度上处理远期的信息。得到粗粒度时间尺度方法1跳跃链接：增加从远期的隐变量到当前隐变量的直接连接；2.
是删除连接：主动删除时间跨度为 1 的连接，并用更长的连接替换。</p></li>
<li><p><label><input type="checkbox"><a href="">RNN为什么会产生梯度消失或者梯度爆炸</a></label></p>
<p>主要由于权重矩阵 <span class="math inline">\(W\)</span>
在不同时间步被重复使用，导致形成 <span class="math inline">\(W\)</span>
的幂乘</p>
<ol type="1">
<li><p>长期依赖的问题是深度学习中的一个主要挑战，其产生的根本问题是：<u>经过许多阶段传播之后，梯度趋向于消失或者爆炸。</u></p>
<ul>
<li>长期依赖的问题中，<u>梯度消失占大部分情况，而梯度爆炸占少数情况</u>。但是梯度爆炸一旦发生，就优化过程影响巨大。</li>
<li><code>RNN</code>
涉及到许多相同函数的多次复合作用，每个时间步一次。这种复合作用可以导致极端的非线性行为。因此在<code>RNN</code>
中，长期依赖问题表现得尤为突出。</li>
</ul></li>
<li><p>考虑一个没有非线性、没有偏置非常简单的循环结构： <span class="math inline">\(\overrightarrow{\mathbf{h}}^{(t)}=\mathbf{W}
\overrightarrow{\mathbf{h}}^{(t-1)}\)</span>。则有：</p>
<p><img src="https://cdn.mathpix.com/snip/images/XOmA-zH1pvODDFxVhIO99BFDrSBP_MyM2xjKywDNnyo.original.fullsize.png"></p>
<p>设<span class="math inline">\(\mathbf{N}\)</span> 可以正交分解时：
<span class="math inline">\(\mathbf{W}=\mathbf{Q} \mathbf{\Lambda}
\mathbf{Q}^{T}\)</span> 。其中 0 为正交矩阵，<span class="math inline">\(\mathbf{\Lambda}\)</span>
为特征值组成的三角阵。则： <span class="math display">\[
\begin{array}{c}{\overrightarrow{\mathbf{h}}^{(t)}=\mathbf{Q}
\mathbf{\Lambda}^{t} \mathbf{Q}^{T} \overrightarrow{\mathbf{h}}^{(0)}}
\\ {\nabla_{\overrightarrow{\mathbf{h}}^{(0)}} L=\frac{\partial
\overrightarrow{\mathbf{h}}^{(t)}}{\partial
\overrightarrow{\mathbf{h}}^{(0)}}
\nabla_{\overrightarrow{\mathbf{h}}^{(t)}} L=\mathbf{Q}
\mathbf{\Lambda}^{t} \mathbf{Q}^{T}
\nabla_{\overrightarrow{\mathbf{h}}^{(t)}} L}\end{array}
\]</span></p>
<ul>
<li><p>前向传播：</p>
<ul>
<li>对于特征值的幅度不到 1 的特征值对应的 <span class="math inline">\(\overrightarrow{\mathbf{h}}^{(0)}\)</span>
的部分将随着 <span class="math inline">\(t\)</span> 衰减到 0 。</li>
<li>对于特征值的幅度大于 1 的特征值对应的<span class="math inline">\(\overrightarrow{\mathbf{h}}^{(0)}\)</span>
的部分将随着<span class="math inline">\(t\)</span> 指数级增长。</li>
</ul></li>
<li><p>反向传播：</p>
<ul>
<li><p>对于特征值幅度不到1的梯度的部分将随着<span class="math inline">\(t\)</span> 衰减到 0 。</p></li>
<li><p>对于特征值幅度大于1的梯度的部分将随着 <span class="math inline">\(t\)</span> 指数级增长 。</p></li>
</ul></li>
</ul></li>
<li><p>若考虑非线性和偏置，即： <span class="math inline">\(\overrightarrow{\mathbf{h}}^{(t+1)}=\tanh
\left(\overrightarrow{\mathbf{b}}+\mathbf{W}
\overrightarrow{\mathbf{h}}^{(t)}+\mathbf{U}
\overrightarrow{\mathbf{x}}^{(t+1)}\right)\)</span>，有： <span class="math display">\[
\frac{\partial \overrightarrow{\mathbf{h}}^{(t+1)}}{\partial
\overrightarrow{\mathbf{h}}^{(t)}}=\operatorname{diag}\left(1-\left(\overrightarrow{\mathbf{h}}^{(t+1)}\right)^{2}\right)
\mathbf{w}
\]</span></p>
<ul>
<li><p>前向传播：</p>
<p><u>由于每一级的 <span class="math inline">\(\overrightarrow{\mathbf{h}}\)</span> 的幅度被
<span class="math inline">\(\tanh (\cdot)\)</span> 函数限制在
<code>(-1,1)</code> 之间，因此前向传播并不会指数级增长。</u></p>
<p><u>这也是为什么 <code>RNN</code> 使用 <code>tanh</code>
激活函数，而不使用 <code>relu</code>的原因。</u></p></li>
<li><p>反向传播：</p></li>
</ul>
<p>由于隐状态的幅度被<span class="math inline">\(\tanh (\cdot)\)</span>
函数限制在 <code>(-1,1)</code> 之间，因此 <span class="math inline">\(\operatorname{diag}\left(1-\left(\overrightarrow{\mathbf{h}}^{(t+1)}\right)^{2}\right)
\mathbf{W}\)</span> 对 <span class="math inline">\(\mathbf{W}\)</span>进行了一定程度上的缩小。<span class="math inline">\(\overrightarrow{\mathbf{h}}^{(t+1)}\)</span>
越大，结果越小。</p>
<ul>
<li>如果 <span class="math inline">\(\mathbf{W}\)</span>
的特征值经过这样的缩小之后，在每个时刻都远小于1（因为每个时刻缩小的比例会变化），则该梯度部分将衰减到
0 。</li>
<li>如果 <span class="math inline">\(\mathbf{W}\)</span>
的特征值经过这样的缩小之后，在每个时刻都远大于1，则该梯度部分将指数级增长。</li>
<li>如果 <span class="math inline">\(\mathbf{W}\)</span>
的特征值经过这样的缩小之后，在不同的时刻有时候小于1有时候大于1（因为每个时刻缩小的比例会变化），则该梯度部分将比较平稳。</li>
</ul></li>
</ol></li>
<li><p><label><input type="checkbox"><a href="">RNN如何解决梯度爆炸问题</a></label></p>
<p>梯度截断：对梯度值进行缩放，使得梯度的模不超过 <span class="math inline">\(\eta\)</span>。假设 <span class="math inline">\(g\)</span> 是梯度向量， <span class="math inline">\(|g|&gt;\eta\)</span>，那么 <span class="math display">\[
g=\frac{\eta g}{|g|}
\]</span></p></li>
<li><p><label><input type="checkbox"><a href="">RNN如何解决梯度消失问题</a></label></p>
<p>（1）LSTM、GRU等模型加入门控机制，捕捉长期记忆，很大程度上弥补了梯度消失。</p>
<p>​ 背后的思路是让路径的梯度乘积接近1</p>
<p>（2）多时间尺度（增加跳跃连接、删除连接）、泄露单元（线性自连接单元）</p>
<p>（3）引入残差结构</p>
<p>（4）RNN+初始化权重矩阵为单位矩阵</p></li>
<li><p><label><input type="checkbox"><a href="">LSTM的结构，每个门的作用，计算公式</a></label></p>
<p><img src="https://upload-images.jianshu.io/upload_images/17477516-8ef0e22accfffd33.png?imageMogr2/auto-orient/"></p>
<p>经典的LSTM中第t步计算公式为 <span class="math display">\[
\begin{array}{l}{i_{t}=\sigma\left(W_{i} x_{t}+U_{i}
h_{t-1}+b_{i}\right)} \\ {f_{t}=\sigma\left(W_{f} x_{t}+U_{j}
h_{t-1}+b_{f}\right)} \\ {o_{t}=\sigma\left(W_{\sigma} x_{t}+U_{o}
h_{t-1}+b_{o}\right)} \\ {\tilde{c}_{t}=\operatorname{Tanh}\left(W_{c}
x_{t}+U_{c} h_{t-1}\right)} \\ {c_{t}=f_{t} \odot c_{t-1}+i_{t} \odot
\tilde{c}_{t}} \\ {h_{t}=o_{t} \odot \tanh
\left(c_{t}\right)}\end{array}
\]</span></p>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="">LSTM变种有哪些</a></label></p>
<p>“<strong>peephole connection</strong>”：让 门控层
也会接受细胞状态的输入。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/42741-0f80ad5540ea27f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp"></p>
<p><strong>coupled forget and input
gates</strong>：将输入门和遗忘们耦合在一起，输入和遗忘是同步的。</p>
<p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-tied.png"></p>
<p><strong>GRU</strong></p></li>
<li><p><label><input type="checkbox"><a href="">LSTM为什么可以解决梯度消失</a></label></p>
<p><strong>将连乘关系转换为相加的线性关系</strong></p>
<p>在LSTM中 <span class="math inline">\(c_{t}=f_{t} \odot c_{t-1}+i_{t}
\odot \tilde{c}_{t}\)</span> ，其中 <span class="math inline">\(c_{t-1}\)</span>是此前的信息， <span class="math inline">\(\tilde{\mathbf{c}}_{t}\)</span>是当前即刻的新信息，
<span class="math inline">\(c_t\)</span> 是最终的信息。可以看到 <span class="math inline">\(c_t\)</span>和 <span class="math inline">\(c_{t-1}\)</span>此时是线性关系，不再是RNN中的连乘关系，梯度以线性在中间节点流动，因此可以保证很长时间的记忆。</p>
<p>进一步地，如果门控信号考虑bias，同时忽略输入变量 <span class="math inline">\(h_{j-1}\)</span>的作用，隐含层关系表示为： <span class="math display">\[
c_{j}=\sigma\left(W^{f} X_{j}+b^{f}\right) c_{j-1}+\sigma\left(W^{i}
X_{j}+b^{i}\right) \sigma\left(W X_{j}+b\right)
\]</span> 于是，需要连乘的项表示为： <span class="math display">\[
\frac{\partial c_{j}}{\partial c_{j-1}}=\sigma\left(W^{f} X_{j}+b\right)
\]</span>
该值范围在0~1之间。但是在实际参数更新中，可以通过控制bias比较大，使得该值接近于1；在这种情况下，即使通过很多次连乘的操作，梯度也不会消失，仍然可以保持“长距”连乘项的存在。即总可以通过选择合适的参数，在不发生梯度爆炸的情况下，找到合理的梯度方向来更新参数，而且这个方向可以充分地考虑远距离的隐含层信息的传播影响。</p></li>
</ul></li>
</ul>
<h1 id="二数学相关">二、数学相关</h1>
<h2 id="概率论和统计学">6、 概率论和统计学</h2>
<p>伯努利分布（0-1分布）</p>
<p>单个二值随机变量的分布，x的取值为0或者1；随机变量为1的概率p，为0的概率是1-p
<span class="math display">\[
p({\rm x} = x) = p^x(1-p)^{1-x}
\]</span></p>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="#6-1-1">6-1-1
说说你是怎样理解信息熵的？</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#6-1-2">6-1-2
能否从数据原理熵解析信息熵可以表示随机变量的不确定性？</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#6-1-3">6-1-3
怎样的模型是最大熵模型？它有什么优点</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#6-1-4">6-1-4
什么是Beta分布？它与二项分布有什么关系？</a></label></p>
<p>参考知乎回答：https://www.zhihu.com/question/30269898</p>
<p>beta分布可以看做一个概率的概率分布，当你不知道一个东西的具体概率是多少时，它可以给出了所有概率出现的可能性大小。<strong>它是对二项分布中成功概率p的概率分布的描述。它的形式如下：</strong></p>
<p>beta分布与二项分布是共轭先验的（<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Conjugate_prior%23Example">Conjugate_prior</a>）。所谓共轭先验就是先验分布是beta分布，而后验分布同样是beta分布。以棒球运动员击球为例，结果很简单：
<span class="math display">\[
\operatorname{Beta}\left(\alpha_{0}+\operatorname{hits}, \beta_{0}+\text
{ misses }\right)
\]</span></p></li>
<li><p><label><input type="checkbox"><a href="#6-1-5">6-1-5
什么是泊松分布？它与二项分布有什么关系？</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#6-1-6">6-1-6
什么是t分布？他与正态分布有什么关系？</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#6-1-7">6-1-7
什么是多项式分布？具体说明？</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#6-1-8">6-1-8
参数估计有哪些方法？</a></label></p>
<p><strong>极大似然估计MLE</strong></p>
<p><strong>最大后验概率估计MAP</strong></p>
<p><strong>期望极大化EM</strong></p>
<p>EM
算法解决这个的思路是使用启发式的迭代方法，既然我们无法直接求出模型分布参数，那么我们可以先猜想隐含参数（EM
算法的 E
步），接着基于观察数据和猜测的隐含参数一起来极大化对数似然，求解我们的模型参数（EM算法的M步)。由于我们之前的隐含参数是猜测的，所以此时得到的模型参数一般还不是我们想要的结果。我们基于当前得到的模型参数，继续猜测隐含参数（EM算法的
E
步），然后继续极大化对数似然，求解我们的模型参数（EM算法的M步)。以此类推，不断的迭代下去，直到模型分布参数基本无变化，算法收敛，找到合适的模型参数。</p>
<p>一个最直观了解 EM 算法思路的是 K-Means 算法。在 K-Means
聚类时，每个聚类簇的质心是隐含数据。我们会假设 K 个初始化质心，即 EM
算法的 E
步；然后计算得到每个样本最近的质心，并把样本聚类到最近的这个质心，即 EM
算法的 M 步。重复这个 E 步和 M 步，直到质心不再变化为止，这样就完成了
K-Means 聚类。</p>
<p>EM算法和极大似然估计的前提是一样的，都要假设数据总体的分布，如果不知道数据分布，是无法使用EM算法的)。</p>
<p>EM算法是通过不断求解下界的极大化逼近求解对数似然函数极大化的算法</p></li>
<li><p><label><input type="checkbox"><a href="#6-1-9">6-1-9
点估计和区间估计都是什么？</a></label></p></li>
<li><p><label><input type="checkbox"><a href="#6-1-10">6-1-10
讲解一下极大似然估计，以及适用场景？</a></label></p>
<p>在统计学中，常常使用极大似然估计法来估计参数。即找到一组参数，使得在这组参数下，我们数据的似然度（概率）最大。<strong>(极大似然估计：就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值，即‘模型已定，参数未知’</strong>)</p>
<p><strong>极大似然估计的前提一定是要假设数据总体的分布，如果不知道数据分布，是无法使用极大似然估计的</strong></p>
<p>求极大似然估计的步骤</p>
<p>（1）写出似然函数；</p>
<p>（2）对似然函数取对数，并整理；</p>
<p>（3）求导数，令导数为 0，得到似然方程；</p>
<p>（4）解似然方程，得到的参数。</p>
<p>应用场景</p>
<p>（1）<strong>回归问题中的极小化平方和</strong></p>
<p>（2）<strong>分类问题中极小化交叉熵</strong></p></li>
<li><p><label><input type="checkbox"><a href="#6-1-10">6-1-11
讲解一下最大后验概率估计，以及适用场景？</a></label></p></li>
</ul>
<p><strong>极大似然估计中采样需满足一个重要的假设，就是所有的采样都是独立同分布的。</strong></p>
<p>那么我们就知道了极大似然估计的核心关键就是对于一些情况，样本太多，无法得出分布的参数值，可以采样小样本后，利用极大似然估计获取假设中分布的参数。</p>
<p>极大似然估计就是经验风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计。</p>
<p>最大后验概率是计算给定数据条件下模型的条件概率，即后验概率。使用模型的先验分布是贝叶斯学习的特点。</p>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="">频率学派和贝叶斯学派什么区别？</a></label></p>
<p><strong>频率学派</strong></p>
<p>频率学派是上帝视角，认为频率是固定的，事件在多次重复实验中趋于一个稳定的值p，那么这个值就是该事件的概率。</p>
<p>他们认为模型参数是个定值，希望通过类似解方程组的方式从数据中求得该未知数。这就是频率学派使用的参数估计方法-<strong>极大似然估计（MLE）</strong>，这种方法往往在<u>大数据量的情况</u>下可以很好的还原模型的真实情况。</p>
<p><strong>贝叶斯派</strong></p>
<p>他们认为世界是不确定的，因获取的信息不同而异。假设对世界先有一个预先的估计，然后通过获取的信息来不断调整之前的预估计。他们认为模型参数源自某种潜在分布，希望从数据中推知该分布。对于数据的观测方式不同或者假设不同，那么推知的该参数也会因此而存在差异。这就是贝叶斯派视角下用来估计参数的常用方法-<strong>最大后验概率估计（MAP）</strong></p>
<p>这种方法在先验假设比较靠谱的情况下效果显著，随着数据量的增加，先验假设对于模型参数的主导作用会逐渐削弱，相反真实的数据样例会大大占据有利地位。极端情况下，比如把先验假设去掉，或者假设先验满足均匀分布的话，那她和极大似然估计就如出一辙了。</p></li>
<li><p><label><input type="checkbox"><a href="">MLE和MAP的联系</a></label></p>
<h2 id="mle与map的联系"><strong>MLE与MAP的联系</strong></h2>
<!-- 
**-**在介绍经验风险与结构风险最小化的时候以具体的逻辑回归（LR）与概率矩阵分解（PMF）模型来介绍MLE和MAP，接下里从宏观的角度，不局限于具体的某个模型来推导MLE与MAP。

**-**假设数据![[公式]](https://www.zhihu.com/equation?tex=x_1%2C+x_2%2C+...%2C+x_n+)是满足独立同分布（i.i.d.）的一组抽样![[公式]](https://www.zhihu.com/equation?tex=X+%3D+%28x_1%2C+x_2%2C+...%2C+x_n%29)，接下来就利用两种参数估计方法来求解。

- MLE对参数![[公式]](https://www.zhihu.com/equation?tex=%5Ctheta)的估计方法可以如下：

![img](https://pic3.zhimg.com/v2-72984f949719a9ac476dfdbaa90bb046_b.jpg)

- MAP对![[公式]](https://www.zhihu.com/equation?tex=%5Ctheta)的估计方法可以如下推导：

![img](https://pic2.zhimg.com/v2-356eca57f5aa3911dd6e00c0e053f21d_b.jpg)

**-**所以MAP和MLE在优化时的不同就是在于增加了一个先验项![[公式]](https://www.zhihu.com/equation?tex=-+%5Clog+P%28%5Ctheta%29)。

**-**通过以上的分析可以大致给出他们之间的联系： ![[公式]](https://www.zhihu.com/equation?tex=MAP%28%5Ctheta%29%5Capprox+MLE%28%5Ctheta%29%2BP%28%5Ctheta%29) 。 --></li>
</ul>
<p>[ ] <a href="">大数定理和中心极限定理</a></p>
<h2 id="最优化问题">7、 最优化问题</h2>
<p>[ ] <a href="#7-1-1">7-1-1 什么是梯度？</a></p>
<p>梯度的方向是函数值增加最快的方向，梯度的相反方向是函数值减小的最快的方向。</p>
<ul class="task-list">
<li><p><label><input type="checkbox"><a href="">为什么梯度的负方向是局部下降最快方向？</a></label></p>
<p>对 <span class="math inline">\(f(x+v)\)</span>在 <span class="math inline">\(x\)</span> 处进行泰勒一阶展开 <span class="math display">\[
f(x+v) \approx f(x)+\nabla f(x)^{T} v
\]</span> 这里有 <span class="math display">\[
f(x)-f(x+v) \approx-\nabla f(x)^{T} v
\]</span> 其中<span class="math inline">\(\nabla f(x)^{T}\)</span>和
<span class="math inline">\(v\)</span>均为向量，<span class="math inline">\(-\nabla f(x)^{T}
v\)</span>就是两个向量进行内积，而向量进行内积的最大值就是两者共线的时候，也就是
<span class="math inline">\(v\)</span> 的方向和 <span class="math inline">\(-\nabla f(x)^{T}\)</span>
方向相同时，内积最大。该内积值代表了最大的下降量。</p></li>
<li><p><label><input type="checkbox"><a href="#7-1-1">7-1-2
梯度下降找到的一定是下降最快的方法？</a></label></p>
<p>梯度下降法并不一定是全局下降最快的方向，它只是目标函数在当前的点的切平面（当然高维问题不能叫平面）上下降最快的方向。在practical
implementation中，牛顿方向（考虑海森矩阵）才一般被认为是下降最快的方向，可以达到superlinear的收敛速度。</p></li>
</ul>
<p>[ ] <a href="#7-1-1">7-1-3 牛顿法和梯度法有什么区别？</a></p>
<p>梯度下降法：<span class="math inline">\(\overrightarrow{\mathbf{x}}_{k+1}=\overrightarrow{\mathbf{x}}_{k}-\epsilon\overrightarrow{\mathbf{g}}\)</span></p>
<p>牛顿法：<span class="math inline">\(\overrightarrow{\mathbf{x}}_{k+1}=\overrightarrow{\mathbf{x}}_{k}-\mathbf{H}^{-1}
\overrightarrow{\mathbf{g}}\)</span></p>
<ol type="1">
<li><p>梯度法对目标函数进行一阶泰勒展开，梯度就是目标函数的一阶信息；</p></li>
<li><p>牛顿法对目标函数进行二阶泰勒展开，Hessian矩阵就是目标函数的二阶信息。</p></li>
<li><p>牛顿法的收敛速度一般要远快于梯度法，但是在高维情况下Hessian矩阵求逆的计算复杂度很大，而且当目标函数非凸时，牛顿法有可能会收敛到鞍点。</p></li>
<li><p>因为梯度法旨在朝下坡移动，而牛顿法目标是寻找梯度为0的点。</p></li>
<li><p>位于一个极小值点附近时，牛顿法比梯度下降法能更快地到达极小值点。</p>
<p>如果在一个鞍点附近，牛顿法效果很差，因为牛顿法会主动跳入鞍点。而梯度下降法此时效果较好（除非负梯度的方向刚好指向了鞍点）。</p></li>
<li><p>梯度下降法中，每一次 <span class="math inline">\(\overrightarrow{\mathbf{x}}\)</span>
增加的方向一定是梯度相反的方向 <span class="math inline">\(-\epsilon_{k}
\nabla_{k}\)</span> 。增加的幅度由<span class="math inline">\(\epsilon_{k}\)</span>
决定，若跨度过大容易引发震荡。</p>
<p>而牛顿法中，每一次 <span class="math inline">\(\overrightarrow{\mathbf{x}}\)</span>
增加的方向是梯度增速最大的反方向 <span class="math inline">\(-\mathbf{H}_{k}^{-1}
\nabla_{k}\)</span>（它通常情况下与梯度不共线）。增加的幅度已经包含在
<span class="math inline">\(\mathbf{H}_{k}^{-1}\)</span>
中（也可以乘以学习率作为幅度的系数）。</p></li>
</ol>
<p>[ ] <a href="#7-1-1">7-1-4 什么是拟牛顿法？</a></p>
<p>在牛顿法的迭代中，需要计算海森矩阵的逆矩阵 <span class="math inline">\(\mathbf{H}^{-1}\)</span>，这一计算比较复杂。可以考虑用一个
<span class="math inline">\(n\)</span> 阶矩阵 <span class="math inline">\(\mathbf{G}_{k}=G\left(\overrightarrow{\mathbf{x}}^{&lt;k&gt;}\right)\)</span>
来近似代替 。</p>
<p>如果选择 <span class="math inline">\(G_{k}\)</span> 作为<span class="math inline">\(\mathbf{H}_{k}^{-1}\)</span> 的近似时，<span class="math inline">\(\mathbf{G}_{k}\)</span> 同样要满足两个条件：</p>
<ul>
<li><p><span class="math inline">\(\mathbf{G}_{k}\)</span>必须是正定的。</p></li>
<li><p><span class="math inline">\(\mathbf{G}_{k}\)</span>满足下面的拟牛顿条件：<span class="math inline">\(\mathbf{G}_{k+1}
\overrightarrow{\mathbf{y}}_{k}=\vec{\delta}_{k}\)</span></p>
<p>因为 <span class="math inline">\(\mathbf{G}_{0}\)</span>
是给定的初始化条件，所以下标从 <span class="math inline">\(k+1\)</span>
开始。</p></li>
</ul>
<p>按照拟牛顿条件选择<span class="math inline">\(\mathbf{G}_{k}\)</span>作为<span class="math inline">\(\mathbf{H}_{k}^{-1}\)</span>的近似或者选择<span class="math inline">\(\mathbf{B}_{k}\)</span>作为<span class="math inline">\(\mathbf{H}_{k}\)</span>的近似的算法称为拟牛顿法</p>
<p>按照拟牛顿条件，在每次迭代中可以选择更新矩阵 <span class="math display">\[
  \mathbf{G}_{k+1}=\mathbf{G}_{k}+\Delta \mathbf{G}_{k}
  \]</span></p>
<p>[ ] <a href="#7-1-1">7-1-5
讲解什么是拉格朗日乘子法、对偶问题、kkt条件?</a></p>
<p><strong>凸优化问题</strong></p>
<ul class="task-list">
<li><p><label><input type="checkbox">拉格朗日乘子法</label></p>
<p><strong>对偶问题</strong></p>
<p>将极小极大的原问题转为极大极小的对偶问题；通常对偶问题更好求解，可以通过求解对偶问题而得到原始问题的解，进而确定分离超平面和决策函数（SVM）。</p>
<p><strong>KKT条件</strong></p></li>
<li><p><label><input type="checkbox"><a href="#7-1-1">7-1-6
是否所有的优化问题都可以转化为对偶问题？</a></label></p>
<p>对所有实数域上的优化问题都有其对偶问题</p></li>
<li><p><label><input type="checkbox"><a href="#7-1-1">7-1-7
讲解SMO（SequentialMinimalOptimization）算法基本思想？</a></label></p>
<p>SMO（序列最小优化算法）是一种启发式算法，是支持向量机学习的一种快速算法，其特点是不断地将原二次规划问题分解为只有两个变量的二次规划子问题，并对子问题进行解析求解，直到所有变量满足KKT条件为止，这时这个最优化问题的解就得到了。这样通过启发式的方法得到原二次规划问题的最优解。因为子问题有解析解，所以每次计算子问题都很快，虽然计算子问题次数很多，但在总体上还是高效的。</p>
<p>整个SMO算法包括两部分：（1）求解两个变量二次规划的解析方法（2）选择变量的启发式方法</p></li>
<li><p><label><input type="checkbox"><a href="#7-1-1">7-1-8
为什么深度学习不用二阶优化？</a></label></p>
<p>深度学习的目标函数复杂，非凸；目标函数非凸时，牛顿法有可能会收敛到鞍点</p></li>
</ul>
<p>[ ] <a href="#7-1-1">7-1-9 机器学习优化器总结</a></p>
<h4 id="梯度下降-gradient-descent-gd">1. 梯度下降 (Gradient Descent,
GD)</h4>
<p>梯度下降是一种基于梯度信息来更新参数的优化方法。假设损失函数为 <span class="math inline">\(J(\theta)\)</span>，对于每次迭代，更新权重的方式为：
<span class="math display">\[
\theta_{t+1} = \theta_t - \eta \nabla J(\theta_t),
\]</span> 其中，$ _t $ 是第 $ t $ 次迭代时的参数，$ $ 是学习率，<span class="math inline">\(\nabla J(\theta_t)\)</span>
是损失函数对参数的梯度。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：在凸问题中，只要学习率 $$
选得合适，梯度下降可以收敛到全局最优解。但对于<strong>非凸问题</strong>，它可能会收敛到局部最优解。</li>
<li><strong>优点</strong>：简单且易于实现。</li>
<li><strong>缺点</strong>：对于批量梯度下降，计算梯度会涉及整个训练集，计算成本高。</li>
</ul>
<h4 id="随机梯度下降-stochastic-gradient-descent-sgd">2. 随机梯度下降
(Stochastic Gradient Descent, SGD)</h4>
<p>SGD
是梯度下降的一个变种，它在每次更新时仅使用一个样本的梯度，而不是整个训练集的梯度：
<span class="math display">\[
\theta_{t+1} = \theta_t - \eta \nabla J(\theta_t; x_i, y_i)
\]</span> 其中 $ (x_i, y_i) $ 是随机选择的训练样本。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：在凸问题中，SGD
在学习率逐渐衰减的情况下可以收敛到全局最优值，但波动较大。在非凸问题中，SGD
可能会陷入局部最优，但随机性有时会帮助跳出局部最优。</li>
<li><strong>优点</strong>：计算开销低，每次迭代只计算一个样本的梯度。</li>
<li><strong>缺点</strong>：更新频繁，带有随机性，会造成损失函数在收敛过程中严重震荡。收敛较慢，更新过程存在噪声。</li>
</ul>
<h4 id="小批量梯度下降法mini-batch-gradient-descent-mbgd">3.
<strong>小批量梯度下降法（Mini-batch Gradient Descent,
MBGD）</strong></h4>
<p>小批量梯度下降是批量梯度下降和随机梯度下降的折中，使用一部分数据计算梯度，然后更新参数。这种方式可以降低参数更新时的方差，使得收敛更加稳定。但是对于非凸问题，依旧无法保证得到全局最优解。</p>
<p><strong>在梯度下降公式中，可以从两个角度进行改进。一是自适应选择学习率；二是梯度（动量）。</strong></p>
<p>首先，在修正梯度方面，主要有momentum动量法和nesterov 加速法。</p>
<h4 id="动量梯度下降-momentum-gd-和-nagnesterov-accelerated-gradient">4.
<strong>动量梯度下降 (Momentum GD) 和 NAG（Nesterov accelerated
gradient）</strong></h4>
<p>动量法：参数更新时在一定程度上保留之前更新的方向，同时又利用当前batch的梯度微调最终的更新方向，简言之就是通过积累之前的动量来
(previous_sum_of_gradient)
加速当前的梯度，可能更加稳定、更有利于跳出局部最优。</p>
<p>动量法的更新公式为： <span class="math display">\[
v_{t+1} = \gamma v_t + \eta \nabla J(\theta_t), \\
\theta_{t+1} = \theta_t - v_{t+1}
\]</span> 其中， $ $ 是动量因子（通常取值接近于 1），$ v_t $
是动量向量。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：在凸问题中，动量法可以比标准梯度下降更快收敛。在非凸问题中，它同样可能收敛到局部最优，但动量项可能有助于避免一些局部最优点。</li>
<li><strong>优点</strong>：加快收敛速度，减少震荡。</li>
<li><strong>缺点</strong>：动量项的选取较为敏感。</li>
</ul>
<p>NAG 进一步引入了nesterov
动量，先在计算梯度更新前做一个矫正，更新公式为： <span class="math display">\[
v_{t+1} = \gamma v_t + \eta \nabla J(\theta_t - \gamma v_t), \\
\theta_{t+1} = \theta_t - v_{t+1}.
\]</span></p>
<p>传统的优化算法要么将学习率设置为常数要么根据训练次数调节学习率。往往忽视了学习率其他变化的可能性。然而，学习率对模型的性能有着显著的影响，因此需要采取一些策略来想办法更新学习率，从而提高训练速度。如果学习率太小，则梯度很大的参数会有一个很慢的收敛速度；
如果学习率太大，则已经优化得差不多的参数可能会出现不稳定的情况。</p>
<p><strong>自适应学习率算法主要有：AdaGrad算法，RMSProp算法，Adam算法以及AdaDelta算法等。</strong></p>
<h4 id="adagrad-adaptive-gradient-algorithm">5. <strong>AdaGrad
(Adaptive Gradient Algorithm)</strong></h4>
<p>AdaGrad
根据历史梯度信息来调整学习率，能够自动缩放每个参数反比于其所有梯度历史总和的平方根。更新公式为：
<span class="math display">\[
\theta_{t+1, i} = \theta_{t,i}- \frac{\eta}{\sqrt{G_{t,ii} + \epsilon}}
g_{t,i}.
\]</span> 其中，<span class="math inline">\(g_{t,i}\)</span> 为 <span class="math inline">\(t\)</span>时刻，参数 <span class="math inline">\(\theta_{t,i}\)</span> 的梯度。<span class="math inline">\(G_t\)</span> 是对角矩阵，<span class="math inline">\((i,i)\)</span>元素为到第$ t $次迭代为止，参数
<span class="math inline">\(\theta_{t,i}\)</span> 的累积梯度平方和。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：AdaGrad
在凸问题中可以收敛到最优解，但在非凸问题中，学习率可能会变得非常小，导致无法继续有效更新。</li>
<li><strong>优点</strong>：具有损失函数最大梯度的参数相应地有个快速下降的学习率，而具有小梯度的参数在学习率上有相对较小的下降。</li>
<li><strong>缺点</strong>：中后期，分母上梯度累加的平方和会越来越大，学习率会逐渐减小到接近
0，使得训练提前结束，无法学习。</li>
</ul>
<h4 id="rmsprop-root-mean-square-propagation">6. <strong>RMSProp (Root
Mean Square Propagation)</strong></h4>
<p>RMSProp
通过调整每个参数的学习率来解决梯度震荡问题。其核心思想是对每个参数的梯度平方值进行指数加权平均，并使用这个平均值来调整每个参数的更新步长：
<span class="math display">\[
E[g^2]_t = \beta E[g^2]_{t-1} + (1 - \beta) g_t^2,
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t
\]</span> 其中，$ g_t $ 是梯度，$ E[g^2]_t $ 是梯度平方的移动平均，<span class="math inline">\(\beta\)</span>是衰减因子，<span class="math inline">\(\epsilon\)</span> 是防止除零的小量。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：RMSProp
能够在一定程度上控制学习率的大小，使得在深度学习中的表现较好。在非凸问题中，它能够有较好的局部收敛表现。</li>
<li><strong>优点</strong>：能够动态调整学习率，对稀疏数据有较好的处理能力。</li>
<li><strong>缺点</strong>：可能会在学习率过小的情况下导致收敛变慢。</li>
</ul>
<h4 id="adadelta">7. <strong>Adadelta</strong></h4>
<p>Adadelta 是 <strong>AdaGrad</strong> 的改进版，旨在解决 AdaGrad
中学习率逐渐衰减至过小的问题。</p>
<p>Adadelta
的主要思想是通过使用<strong>指数加权移动平均</strong>（Exponential
Moving Average, EMA）来代替 AdaGrad
中的累积平方梯度和累计学习率。通过这种方式，它能够更稳定地调整学习率，同时避免学习率在训练过程中过度减小。</p>
<p>Adadelta
不仅对梯度平方进行加权平均，还对参数更新的量进行加权平均，因此它不依赖于预设的全局学习率。</p>
<p>(1). <strong>梯度平方的指数加权移动平均</strong>： <span class="math display">\[
   E[g^2]_t = \rho E[g^2]_{t-1} + (1 - \rho) g_t^2
   \]</span></p>
<p>其中，$ g_t $$ 是在第 $ t $ 次迭代中计算的梯度，<span class="math inline">\(\rho\)</span> 是衰减率（通常取值在 0.9 左右），$
E[g^2]_t $ 是梯度平方的移动平均值。</p>
<p>(2). <strong>参数更新的移动平均</strong>： <span class="math display">\[
   \Delta \theta_t = - \frac{\sqrt{E[\Delta \theta^2]_{t-1} +
\epsilon}}{\sqrt{E[g^2]_t + \epsilon}} g_t
   \]</span> 其中，$ E[^2]_{t-1} $ 是之前参数更新量的移动平均值，$ $
是一个用于防止除零的小量（通常取 $ 10^{-6} $）。</p>
<p>(3). <strong>更新移动平均</strong>： <span class="math display">\[
   E[\Delta \theta^2]_t = \rho E[\Delta \theta^2]_{t-1} + (1 - \rho)
(\Delta \theta_t)^2
  \]</span></p>
<p>(4). <strong>参数更新</strong>： <span class="math display">\[
   \theta_{t+1} = \theta_t + \Delta \theta_t
  \]</span></p>
<ul>
<li><p><strong>是否收敛到最优值</strong>：在凸优化问题中，Adadelta
可以收敛到全局最优解。在非凸问题中，它的表现依然较好，能够避免陷入局部最优点。不过，类似于其他基于梯度的优化方法，Adadelta
在非凸问题中并不能保证一定收敛到全局最优解。</p></li>
<li><p><strong>AdaGrad</strong>
使用的是累积平方梯度求和来更新学习率，导致学习率在训练过程中逐渐趋近于零，尤其是在处理长时间训练或大量数据时。这会使得
AdaGrad 训练过程后期的学习率非常小，进而导致参数几乎无法更新。</p></li>
<li><p><strong>Adadelta</strong> 通过引入指数加权移动平均（EMA）代替了
AdaGrad 中的累积平方梯度求和，避免了学习率过早衰减的现象。同时，Adadelta
不再需要预设学习率，因为它会自动调整学习率。</p></li>
<li><p><strong>依赖于衰减率的选择</strong>：虽然不需要手动设置学习率，但衰减率
$ $
的选择依然是影响模型收敛速度的一个关键因素。对于不同的数据集和任务，可能需要针对衰减率进行调优。</p></li>
</ul>
<h4 id="adam-adaptive-moment-estimation">8. <strong>Adam (Adaptive
Moment Estimation)</strong></h4>
<p>Adam 是 RMSProp
和动量法的结合，通过同时计算梯度的一阶和二阶矩的指数加权平均来调整学习率：
<span class="math display">\[
m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t, \\
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2.
\]</span> <span class="math display">\[
\hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1 -
\beta_2^t}.
\]</span> <span class="math display">\[
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon}
\hat{m}_t
\]</span> 其中，$ m_t $ 和 $ v_t $ 分别是梯度的一阶和二阶矩，$ _1 $ 和 $
_2 $ 是超参数。</p>
<ul>
<li><strong>是否收敛到最优值</strong>：Adam
在许多实际问题中表现优越，但在某些情况下，Adam
可能会收敛到次优解。理论上，它能收敛到局部最优，但是否能达到全局最优取决于问题的性质。</li>
<li><strong>优点</strong>：能够动态调整学习率，对稀疏数据和噪声鲁棒性强。</li>
<li><strong>缺点</strong>：较为复杂，依赖超参数的设置。</li>
</ul>
<h4 id="adamw-adaptive-moment-estimation">8. <strong>AdamW (Adaptive
Moment Estimation)</strong></h4>
<p><strong>AdamW</strong> 是 <strong>Adam</strong>
优化算法的改进版本，它的主要改进是在 Adam
的基础上引入了<strong>权重衰减（Weight
Decay）</strong>的正确实现。这种权重衰减是通过将 L2
正则化直接应用于<strong>参数更新公式</strong>，而不是像 Adam
那样对梯度进行修正。这种改进旨在提高模型的泛化能力，尤其是避免深度学习模型中过拟合的问题。</p>
<ul>
<li><p><strong>Adam 中的错误正则化实现</strong>：在原版的 Adam
中，权重衰减实际上是通过将梯度中的 L2 惩罚项添加到更新公式中。这种做法在
Adam 中并不完全等同于对参数的惩罚，因为 Adam
依赖于动量和梯度的调整，它使得实际的正则化效果被稀释或扭曲，导致权重衰减效果不理想。</p></li>
<li><p><strong>AdamW 的提出</strong>：为了解决这个问题，AdamW
提出了更正的权重衰减实现。AdamW
将权重衰减项直接应用到参数本身的更新步骤，而不是施加在梯度上。这种做法能够更加有效地抑制模型的过拟合，提高泛化能力。</p></li>
</ul>
<p>AdamW 基本上继承了 Adam
的大部分更新过程，但在参数更新时引入了独立的权重衰减项。</p>
<p>(1). <strong>梯度的移动平均</strong>（一阶矩估计）： <span class="math display">\[
   m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
   \]</span> 其中，$g_t $是在第 $ t $ 次迭代中计算的梯度，$ m_t <span class="math inline">\(是梯度的移动平均，\)</span>_1 $
是动量衰减因子（通常取 0.9）。</p>
<p>(2). <strong>梯度平方的移动平均</strong>（二阶矩估计）： <span class="math display">\[
   v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
  \]</span> 其中，$ v_t $ 是梯度平方的移动平均，$ _2 $
是衰减因子（通常取 0.999）。</p>
<p>(3). <strong>偏差修正</strong>：
为了消除初期时矩估计的偏差，需要进行偏差校正： <span class="math display">\[
   \hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1
- \beta_2^t}
   \]</span></p>
<p>(4). <strong>参数更新</strong>（AdamW 核心改进部分）： AdamW
的更新步骤不仅包含 Adam
的参数更新公式，还直接在参数更新时引入了权重衰减项： <span class="math display">\[
   \theta_{t+1} = \theta_t - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} +
\epsilon} - \eta \lambda \theta_t
   \]</span> 其中，$ $ 是权重衰减系数（即 L2 正则化系数），$ $
是学习率。</p>
<p>AdamW 的关键在于第二个项 $_t
$，它直接将权重衰减施加在参数更新上，而不是施加在梯度上。这种方式与传统
SGD 中的权重衰减更一致。</p>
<ul>
<li><strong>Adam</strong>：权重衰减通过 L2
正则化实现，并作用在梯度上。这种实现可能会导致正则化效果受到 Adam
的梯度调整机制的干扰，导致模型参数更新不充分，特别是在学习率较小时。</li>
<li><strong>AdamW</strong>：权重衰减直接作用于参数本身，即在每次参数更新时独立加入一个基于参数的衰减项。这样可以保证权重衰减的效果更加直接和有效，避免了
Adam
对梯度的干扰。此外，这种权重衰减更加显式地对模型参数产生作用，从而能够更好地抑制模型过拟合，提高泛化性能。</li>
<li><strong>需要调优的超参数增加</strong>：相比 Adam，AdamW
多了一个权重衰减系数 $ $，这增加了模型调优的复杂性。</li>
</ul>
<h1 id="三-llm-and-vlm">三、 LLM and VLM</h1>
<h2 id="大模型常用微调方法lora和ptuning的原理">1.
大模型常用微调方法LORA和Ptuning的原理</h2>
<ul>
<li>LORA: Low-Rank Adaptation.
核心是在大型语言模型上对指定参数增加额外的低秩矩阵，也就是在原始pre-trained
LM
旁边增加一个旁路，做一个降维再升维的操作。假设模型中有一个需要更新的权重矩阵
<span class="math inline">\(W \in \mathbb{R}^{d \times
k}\)</span>，LORA的思想是修改为： <span class="math inline">\(W' = W
+ \delta W\)</span>，其中 <span class="math inline">\(\Delta W = A
\times B\)</span>, <span class="math inline">\(A \in \mathbb{R}^{d
\times r}\)</span>, <span class="math inline">\(B \in \mathbb{R}^{r
\times k}\)</span>, 且 <span class="math inline">\(r &lt;&lt; \min\{d,
k\}\)</span>。在模型训练过程中，固定PLM的参数，只训练降维矩阵 <span class="math inline">\(A\)</span> 与升维矩阵 <span class="math inline">\(B\)</span>。</li>
<li><h2 id="ptuning-prompt-tuning.">Ptuning: Prompt Tuning.</h2></li>
</ul>
<h2 id="diffusion-models-and-stable-diffusion">2. Diffusion models and
Stable diffusion</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#prog-distll">What
are Diffusion Models?</a></li>
<li><h2 id="diffusion-models-for-video-generation"><a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2024-04-12-diffusion-video/">Diffusion
Models for Video Generation</a></h2></li>
</ul>
<h2 id="llm的幻觉的问题">3. LLM的幻觉的问题</h2>
<p><a target="_blank" rel="noopener" href="https://aman.ai/primers/ai/hallucination/">NLP •
Hallucination Mitigation</a></p>
<hr>
<h2 id="llm-alignment">4. LLM Alignment</h2>
<p>Many thanks to this blog: <a target="_blank" rel="noopener" href="https://aman.ai/primers/ai/llm-alignment/">LLM Alignment</a></p>
<h3 id="overview">Overview</h3>
<ul>
<li>2017 年，OpenAI 在其论文 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03741">Deep reinforcement learning from
human preferences</a> 中提出了一种开创性的机器学习方法，称为
"从人类反馈出发的强化学习"
(RLHF)，特别关注人类偏好。这一创新概念自此激发了该领域的进一步研究和发展。</li>
<li>RLHF 概念:
使用一个预先训练好的语言模型，由人类评估员对其输出进行排序。然后，这种排序会让模型对某些类型的回答产生偏好，从而产生更可靠、更安全的输出。</li>
<li>RLHF
可以有效利用人类反馈来提高语言模型的性能。它将强化学习算法的优势与对人类输入的细微理解相结合，促进了模型的持续学习和改进。结合人类反馈，RLHF
不仅能提高模型的自然语言理解和生成能力，还能提高其在文本分类或翻译等特定任务中的效率。此外，RLHF
在解决语言模型中的偏差方面也发挥着至关重要的作用。通过允许人工输入来指导和纠正模型的语言使用，它可以促进更加公平和包容的交流。不过，在这一过程中，必须注意人为因素可能导致的偏差。</li>
</ul>
<h3 id="reinforcement-learning-强化学习基础概念">Reinforcement Learning
强化学习基础概念</h3>
<p><img src="/2024/10/08/statistic/rl.png"></p>
<p>如图所示，agent 采取一定的 action，对于当前的
action，环境会反馈其状态 state 以及 给出
reward。其中，reward是要优化的目标，state是环境当前的状态，policy用于根据state选择
action.</p>
<h3 id="reinforcement-learning-from-human-feedback-rlhf">Reinforcement
Learning from Human Feedback (RLHF)</h3>
<p>LLM
的最初目标是准确地预测下一个token。但是，这种方式无法保证输出的结果是有用、无害且诚实的，有可能产生不符合人类道德或安全标准的内容。为解决这一问题，需要有一种方式来引导模型输出符合人类价值观的结果。</p>
<p><img src="/2024/10/08/statistic/rlhf.png"></p>
<p>图中给出了使用RLHF训练LM的三个步骤，具体来说，</p>
<ol type="1">
<li><p>Collect Demonstration Data, and Train a Supervised Policy.
首先，从 prompts 中选择一个
prompt；然后人类标注者给出希望得到的输出；最后这些经过标注后的数据用于对LM进行
supervised fine-tune.</p></li>
<li><p>Collect Comparison Data, and Train a Reward Model.
首先，选取一个prompt，模型给出几个可能的输出结果；标注者根据有用性、准确性等准则对结果进行从好到差的排序；这些排序后的数据用来训练一个
reward model. Reward model用来评估模型输出结果的质量。</p></li>
<li><p>Optimize a Policy Against the Reward Model Using Reinforcement
Learning. 产生新的prompt, 基于当前的policy, model 得到新的输出 response;
Reward model 评估 response，然后得到 reward；基于得到的 reward
以及一些强化学习算法，比如PPO，对 policy 进行更新。调整 policy
是为了增加未来产生 higher-reward outputs 的可能性。</p></li>
</ol>
<p>Chip Huyen provides a zoomed out view of how the overall process
works in her flowchart below:</p>
<p><img src="/2024/10/08/statistic/rlhf1.jpeg"></p>
<h4 id="reward-model">REWARD MODEL</h4>
<p>Reward model 的主要功能是评估给定的输入（如文本序列）并产生scalar
reward。这种reward 量化了输出与人类偏好或期望行为的一致程度。</p>
<p><img src="/2024/10/08/statistic/rlhf2.png"> Reward 模型的结构包括 -
LM 分类器：一个二元分类器微调的
LLM，可对哪种反应更符合人类偏好进行评分。 - value
networks：一个回归模型，根据输入预测人类偏好评分。 -
评论生成器：经过训练的
LM，可生成评价性评论，解释哪种回答更好以及原因。该评论可用于指令调整。</p>
<h4 id="optimizing-the-policy">Optimizing the Policy</h4>
<p><strong>策略（policy）</strong>：在强化学习中，策略是一组规则或决策机制，指导智能体（agent）根据它所处的环境状态或观察结果来选择行动。也就是说，策略定义了智能体如何在不同的情境下采取什么样的行为。</p>
<p><strong>PPO（Proximal Policy
Optimization，邻近策略优化）</strong>：是一种常用的强化学习算法。在PPO中，策略是通过反复迭代来优化的。其目标是最大化奖励，即让智能体的行为逐步改善，获得更高的回报。
但是，PPO会确保策略的更新不会发生剧烈变化。这是通过引入一种约束，使更新后的策略保持与之前的策略相似性，以避免不稳定性或训练失败的情况。</p>
<p><strong>DPO（Direct Preference
Optimization，直接偏好优化）</strong>：是一种不同的策略优化方法。在DPO中，策略直接基于人类偏好进行优化。具体来说，它通过二元交叉熵损失函数（binary
cross entropy
loss），增加模型生成的优选输出的相对对数概率，而减少非优选输出的概率。这种方法直接根据人类的反馈进行优化，旨在使模型生成更符合人类期望的输出。
与此同时，DPO也通过KL散度约束来保持平衡，防止策略发生过大的偏离。</p>
<h4 id="training-llama-2">Training Llama 2</h4>
<p><img src="/2024/10/08/statistic/llama.jpeg"></p>
<p>以下是Llama 2 的主要训练阶段的介绍：</p>
<ol type="1">
<li><strong>预训练阶段</strong>（Pretraining）：
<ul>
<li>在最初的预训练阶段，Llama 2
使用大量数据通过<strong>自监督学习</strong>进行训练。这一阶段让模型学习语言模式和上下文的基本结构，使其能够理解语言的基本规则和含义。</li>
<li>自监督学习的方式通常是通过预测文本中隐藏的部分（如下一句话或遮盖的单词）来训练模型，帮助它积累广泛的语言知识。</li>
</ul></li>
<li><strong>有监督微调阶段</strong>（Supervised Fine-Tuning）：
<ul>
<li>在此阶段，模型进一步通过<strong>指令数据</strong>进行有监督微调。具体来说，模型会根据特定的指令进行训练，学习如何对不同的提示做出合适的响应。</li>
<li>这个过程使模型能够在实际应用中根据明确的要求或任务生成准确、相关的回答。</li>
</ul></li>
<li><strong>奖励模型创建（RLHF步骤1）</strong>（Reward Models Creation -
RLHF Step 1）：
<ul>
<li>为了进一步优化模型输出的质量，Llama 2
创建了两个<strong>奖励模型</strong>，一个针对<strong>帮助性（helpfulness）</strong>，另一个针对<strong>安全性（safety）</strong>。</li>
<li>这些奖励模型通过<strong>人类偏好数据</strong>训练，预测在两种不同的输出中哪一个更符合人类的判断。此阶段基于二元比较，模型通过评估每对输出的优劣来学习。</li>
</ul></li>
<li><strong>边际损失与排名</strong>（Margin Loss and Ranking）：
<ul>
<li>Llama 2
使用二元比较数据集来优化排名。在每次比较中，标注者只需要选择两种响应中的一个，并通过<strong>边际标签</strong>来表示偏好的强度。这种边际标签可以用于进一步计算<strong>排名损失</strong>，提高模型对不同偏好的敏感性。</li>
</ul></li>
<li><strong>拒绝采样与PPO对齐（RLHF步骤2）</strong>（Rejection Sampling
and PPO - RLHF Step 2）：
<ul>
<li>在最后一步，Llama 2
使用<strong>拒绝采样</strong>和<strong>邻近策略优化（PPO）</strong>来进一步优化模型。</li>
<li>拒绝采样是指从模型生成的多个输出中，选择<strong>奖励最高</strong>的输出用于更新梯度，从而增强模型生成高质量输出的能力。</li>
<li>之后通过PPO算法对模型进行进一步对齐，使其生成的回答更加安全且有帮助，同时确保优化过程中策略更新的稳定性。</li>
</ul></li>
</ol>
<p>总的来说，Llama 2
的训练流程结合了大规模的自监督学习、基于指令的有监督微调，以及基于人类偏好的强化学习，通过一系列精细的步骤来提升模型的语言理解、输出的帮助性和安全性。</p>
<h4 id="proximal-policy-optimization-ppo">Proximal Policy Optimization
(PPO)</h4>
<p>建议先阅读以下两篇博客： - <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xingzheai/p/15826847.html">详解策略梯度算法</a>
- <a target="_blank" rel="noopener" href="https://www.cnblogs.com/xingzheai/p/15931681.html">详解近端策略优化</a></p>
<p><strong>PPO-clip</strong>:
在PPO（邻近策略优化）中，代理损失函数（surrogate loss）
是通过当前策略和参考策略下执行同一动作的概率比率来定义的。这一比率用于引导策略向那些能够获得更高奖励的动作倾斜，同时确保策略更新的幅度不会过大，从而保持训练的稳定性。为防止策略的更新幅度过大，PPO引入了剪裁，限制比率在一定范围内。通过在一定阈值外“剪裁”比率的变化，模型可以避免发生过大的更新，从而保证训练过程的稳定性。</p>
<p>定义 <span class="math inline">\(\pi_{\theta}\)</span>为当前策略（参数为 <span class="math inline">\(\theta\)</span> 的一个网络），<span class="math inline">\(\pi_{ref}\)</span>
是实际的、可参考的策略空间。<span class="math inline">\(A(s_t,
a_t)\)</span>为在状态 <span class="math inline">\(s_t\)</span>
下采取行为 <span class="math inline">\(a_t\)</span>
时得到的奖励。近端策略优化裁剪函数为： <span class="math display">\[
L(\theta) = E_{(s_t, a_t) \sim \pi_{ref}} \min{(\frac{p_{\theta}(a_t |
s_t)}{p_{\pi_{ref}}(a_t|s_t)} A(s_t, a_t), clip(\frac{p_{\theta}(a_t |
s_t)}{p_{\pi_{ref}}(a_t|s_t)}, 1-\epsilon, 1+\epsilon)A(s_t, a_t))},
\]</span> <span class="math inline">\(\epsilon\)</span>
是一个超参数，要需要我们调整的，一般设置为0.1或0.2。</p>
<p><strong>PPO-penalty</strong>: 在PPO中，除了使用剪裁目标函数（clipped
objective）外，另一种常见的方法是直接在目标函数中加入KL散度惩罚项。这意味着算法会根据新策略与参考策略的偏离程度对目标函数进行惩罚。具体损失函数为：
<span class="math display">\[
L(\theta) = E_{(s_t, a_t) \sim \pi_{ref}} \frac{p_{\theta}(a_t |
s_t)}{p_{\pi_{ref}}(a_t|s_t)} A(s_t, a_t) - \beta
KL(\pi_{ref}||\pi_{\theta}),
\]</span></p>
<p>通过<strong>最大化目标函数</strong>得到最优策略。对于大规模语言模型（LLM）来说，这个目标函数反映了模型对齐的目标，比如生成<strong>有帮助</strong>、<strong>真实</strong>、<strong>无害</strong>的回答。</p>
<p><strong>参考策略 (Reference
Policy)</strong>：参考策略是训练过程中用作<strong>基准</strong>或<strong>对照</strong>的一套策略。它通常是一个<strong>稳定的策略</strong>，模型可以从这个基准出发，或者在训练过程中参考该策略来指导学习。它确保最优策略的更新不会偏离初始策略太远，防止训练过程中产生剧烈变化或不稳定的行为。</p>
<h3 id="reinforcement-learning-with-ai-feedback-rlaif">Reinforcement
Learning with AI Feedback (RLAIF)</h3>
<p>RLAIF
使用AI生成的偏好（而不是人工标注的偏好）来训练大规模语言模型（LLMs）。这种方法通过利用强大的预训练模型（如GPT-4）生成反馈，为训练其他LLM提供高效、成本更低的替代方案。在RLAIF中，反馈生成的语言模型相当于充当了“虚拟人工标注者”的角色。它评估训练中的模型生成的多个输出，选择优选响应或提供改进建议。</p>
<h4 id="direct-preference-optimization-dpo">Direct Preference
Optimization (DPO)</h4>
<p>本文前面讨论的 RLHF
主要包括两个阶段：根据人类偏好标签训练奖励模型，然后使用强化学习（RL）对
LM 进行微调，使其与这些偏好保持一致。然而，RLHF
存在复杂性和不稳定性问题，它需要拟合一个奖励模型，然后训练一个策略来优化该奖励，这就容易产生稳定性问题。</p>
<p>DPO算法摆脱了传统RL方法中的两个阶段。通过定义新的损失函数来训练LLM，以避免不稳定性问题。
DPO使用一种特殊格式的数据集，形式为：&lt;prompt, worse completion,
better
completion&gt;（即“提示，较差的完成，较好的完成”）。在训练过程中，DPO的损失函数鼓励模型增加较好完成的概率，同时降低较差完成的概率。这个过程是通过加权实现的，权重基于隐含的奖励模型。这里的关键在于，LLM本身充当了奖励模型，因此不再需要一个显式的奖励模型。下图给出了DPO和RLHF的区别。</p>
<p><img src="/2024/10/08/statistic/DPO.jpg"></p>
<p><strong>Binary Cross-Entropy Loss</strong> DPO
通过使用二元交叉熵（Binary Cross-Entropy,
BCE）损失函数来优化语言模型以更好地与人类偏好对齐的训练方法。对于每个输入，模型会生成两个响应，并由人类标注者指明他们的偏好（哪个响应更好）。DPO通过比较模型生成的响应对（即优选响应和不优选响应）与人类偏好进行训练。</p>
<p>损失定义如下： <span class="math display">\[
L_{DPO}(\theta) = -E_{(x, y_w, y_l) \sim D} [\log \sigma (\beta
\log\frac{\pi_{\theta}(y_w| x)}{\pi_{ref}(y_w|x)} - \beta \beta
\log\frac{\pi_{\theta}(y_l| x)}{\pi_{ref}(y_l|x)})],
\]</span> 其中，<span class="math inline">\(\pi_{\theta}\)</span>
为要训练的策略模型， <span class="math inline">\(\pi_{ref}\)</span>
是参考的策略模型；<span class="math inline">\(y_w\)</span> 和 <span class="math inline">\(y_l\)</span> 分别表示优选response 和 不优选的
response. <span class="math inline">\(\beta\)</span>
控制待训练模型与参考策略模型的接近程度。<span class="math inline">\(\sigma\)</span> 为 logistic 函数。</p>
<ul>
<li>DPO标志着语言模型训练方法的转变，通过将强化学习与人类反馈（RLHF）过程整合为<strong>单个的端到端</strong>优化步骤，简化了模型的训练。</li>
</ul>
<p><strong>DPO 的训练过程</strong> -
选择一个已经经过基础指令调优的语言模型作为参考模型，这个模型提供了良好的基础。
-
使用不同的采样/解码方法（例如不同的温度设置）对同一提示生成成对输出，并让人类选择他们喜欢的哪一个。这一过程将产生一个人类偏好/反馈的数据集。
-
在LLM上添加一个线性层，使得模型能够输出一个标量值。这一层将帮助模型在训练过程中产生更具体的数值输出。
-
使用DPO损失，该损失函数基于二元交叉熵损失。计算参考模型和正在调优模型的标量输出的对数比率，并乘以一个散度参数，以调整模型的输出。
-
在训练完成后，去掉最后的线性层，这样就得到了一个基于人类反馈微调的LLM。</p>
<p>通过以上步骤，DPO方法通过简化RLHF过程，去掉了复杂的强化学习步骤和专门的奖励模型，使得模型训练更为高效和直接。这样，最终得到的模型能够更好地反映人类的偏好，提供更优质的输出</p>
<h4 id="kahneman-tversky-optimization-kto">Kahneman-Tversky Optimization
(KTO)</h4>
<p>人类在面对不确定事件时，由于‘厌恶损失’，往往会做出无法最大化期望值的决策。直接以人的偏好指导大模型的训练，其训练的数据中包含了大量的人类偏好，往往无法做出期望最大的决策。KTO是一种对齐手段，将重点从传统训练目标（如下一个标记预测或拟合配对偏好数据）转向直接优化被<strong>认为有价值或可取</strong>的输出。</p>
<p>KTO消除了对配对偏好排名或比较数据的需求，显著简化了数据要求。它只需要二元标签，指示某个LLM输出是可取的还是不可取的。这种二元偏好数据的需求使KTO在现实场景中更为实用，因为收集详细的偏好数据往往比较困难。</p>
<p><strong>前景理论 (prospect theory)</strong></p>
<p>KTO 的灵感来自 Daniel Kahneman 和 Amos Tversky
提出的决策行为模型，特别是他们的前景理论 (prospect theory)。KTO
将这些概念调整为损失函数，通过捕捉人类的偏差（如损失规避和风险敏感性），使
LLM 与人类反馈保持一致。</p>
<p>在前景理论中，人类在不确定性下的决策行为偏离了预期效用最大化的原则，主要是因为一些心理偏差，如损失厌恶（loss
aversion）和非线性概率加权（nonlinear probability
weighting）。这些概念是KTO损失函数的基础。</p>
<ol type="1">
<li><strong>价值函数 (Value
Function)</strong>：前景理论中的价值函数用于描述人们如何看待收益和损失的差异。它具有以下特征：</li>
</ol>
<ul>
<li><p><strong>对收益的凹性</strong>：当收益增加时，价值函数是凹的，这意味着人们在获得相同金额的收益时，所感受到的价值增加会逐渐减小。这反映了人们在面对收益时的风险厌恶（risk
aversion）。</p></li>
<li><p><strong>对损失的凸性</strong>：当面临损失时，价值函数是凸的，这意味着在损失相同金额时，所感受到的损失会逐渐增大，反映了人们在面对损失时的风险寻求（risk-seeking）行为。</p></li>
<li><p><strong>损失的影响大于收益</strong>：损失对人们的情感影响通常大于收益，这一点通过损失厌恶参数
<span class="math inline">\(\lambda\)</span>
来建模。该参数通常大于1，意味着人们在面对损失时的感受强于获得相同金额收益时的感受。</p></li>
</ul>
<ol start="2" type="1">
<li><strong>数学表达式</strong>. 价值函数 <span class="math inline">\(v(x)\)</span> 可以用以下公式表示： <span class="math display">\[
v(x) = \begin{cases}
x^\alpha &amp; \text{if } x \geq 0 \\
-\lambda (-x)^\beta &amp; \text{if } x &lt; 0
\end{cases}
\]</span> 其中：</li>
</ol>
<ul>
<li>$ (0,1)$ 和 <span class="math inline">\(\beta \in (0,1)\)</span>
控制对收益和损失的减敏感性（diminishing
sensitivity）。这意味着随着收益或损失的增加，人们的感知效应会逐渐减弱。</li>
<li>$ $
是损失厌恶因子，通常大于1，这表示人们对损失的反应比对收益更为强烈。</li>
</ul>
<ol start="3" type="1">
<li><strong>概率加权函数 (Probability Weighting Function)</strong>:
人们在判断概率时，往往会倾向于高估小概率事件和低估大概率事件。尽管这一元素并非KTO的核心部分，但它强调了主观不确定性感知如何影响决策。这种加权使得人们在面对不确定性时的决策并不是完全理性的，而是受到了心理因素的影响。</li>
</ol>
<p>Kahneman-Tversky Optimization (KTO)
的损失函数是基于前景理论构建的，其设计目标是直接最大化语言模型生成输出的效用。以下是
KTO 损失函数的关键要素及其解释：</p>
<p><strong>KTO‘s loss function</strong></p>
<ul>
<li><p>KTO 使用了一个 <strong>逻辑函数 <span class="math inline">\(\sigma\)</span></strong>，而不是经典前景理论中的分段价值函数。这种逻辑函数保持了对收益的<strong>凹性</strong>和对损失的<strong>凸性</strong>，反映了人类对风险的感知。</p></li>
<li><p><strong>风险厌恶参数 <span class="math inline">\(\beta\)</span></strong>
被纳入模型中，用于控制风险厌恶程度。这一参数影响价值函数饱和的陡峭程度，进而影响模型如何感知收益和损失。</p></li>
<li><p>在 KTO 中，传统的损失厌恶参数 <span class="math inline">\(\lambda\)</span>
被替换为两个独立的超参数：<strong><span class="math inline">\(\lambda_D\)</span></strong>（用于积极反馈的输出）和
<strong><span class="math inline">\(\lambda_U\)</span></strong>（用于消极反馈的输出）。允许模型根据输出类型的不同（积极或消极），以更细致的控制方式来处理反馈，从而更好地反映人类的风险厌恶特性。</p></li>
<li><p>模型的参考点通过 <strong>KL 散度</strong>
来定义，表示当前模型策略 <span class="math inline">\(\pi_\theta\)</span>
与参考策略 <span class="math inline">\(\pi_{\text{ref}}\)</span>
之间的差异。KL
散度项控制当前模型输出与预训练参考模型的偏离程度，并作为优化中评估收益和损失的参考点
<span class="math inline">\(z_0\)</span>。</p></li>
</ul>
<p>KTO（Kahneman-Tversky Optimization）损失函数的数学公式如下： <span class="math display">\[
L_{KTO}(\pi_\theta, \pi_{\text{ref}}) = \mathbb{E}_{x,y \sim
D}[\lambda_y - v(x,y)], \\
\quad \\
v(x,y) =
   \begin{cases}
   \lambda_D \sigma(\beta(r_\theta(x,y) - z_0)), &amp; \text{if } y \sim
\text{desirable} \\
   \lambda_U \sigma(\beta(z_0 - r_\theta(x,y))), &amp; \text{if } y \sim
\text{undesirable}
   \end{cases}
\]</span></p>
<p>其中：</p>
<ul>
<li><p><strong><span class="math inline">\(\mathbb{E}_{x,y \sim
D}\)</span></strong>：表示对数据集 <span class="math inline">\(D\)</span> 中的样本进行期望计算，其中 <span class="math inline">\(x\)</span> 是输入，<span class="math inline">\(y\)</span> 是模型生成的输出。</p></li>
<li><p><strong><span class="math inline">\(\lambda_y\)</span></strong>：代表与输出 <span class="math inline">\(y\)</span> 相关的损失厌恶参数，可以是
<strong><span class="math inline">\(\lambda_D\)</span></strong>（用于积极输出）或
<strong><span class="math inline">\(\lambda_U\)</span></strong>（用于消极输出），用于表示人类对损失的厌恶程度。</p></li>
<li><p><strong><span class="math inline">\(r_\theta(x,y)\)</span></strong>： $ r_(x,y) = . $
该函数表示在当前策略 <span class="math inline">\(\pi_\theta\)</span>
下生成输出 <span class="math inline">\(y\)</span> 的对数概率与参考策略
<span class="math inline">\(\pi_{\text{ref}}\)</span>
下生成同一输出的对数概率之比。它衡量了当前模型与参考模型在生成特定输出时的相对表现。</p></li>
<li><p><strong><span class="math inline">\(z_0\)</span></strong>： <span class="math inline">\(z_0 = KL(\pi_\theta(y'|x) \|
\pi_{\text{ref}}(y'|x))\)</span>. 这里量化当前策略 <span class="math inline">\(\pi_\theta\)</span> 和参考策略 <span class="math inline">\(\pi_{\text{ref}}\)</span>
之间的差异。它作为评估当前策略与参考策略偏离程度的参考点。</p></li>
<li><p><strong><span class="math inline">\(v(x,y)\)</span></strong>：价值函数，依赖于输出
<span class="math inline">\(y\)</span> 的性质. <strong><span class="math inline">\(\sigma\)</span></strong>：逻辑函数，用于对价值函数进行调整，使其保持凹性（对于收益）和凸性（对于损失），模型就会在收益时更加规避风险，在损失时更加追求风险。<strong><span class="math inline">\(\beta\)</span></strong>：风险厌恶参数，控制风险厌恶的程度。增加
<span class="math inline">\(\beta\)</span>会增加收益时的风险规避行为和损失时的风险追求行为。</p></li>
</ul>
<h3 id="ppo-dpo-以及-kto-的对比">PPO, DPO 以及 KTO 的对比</h3>
<table>
<colgroup>
<col style="width: 13%">
<col style="width: 33%">
<col style="width: 26%">
<col style="width: 27%">
</colgroup>
<thead>
<tr>
<th>Aspect</th>
<th>PPO</th>
<th>DPO</th>
<th>KTO</th>
</tr>
</thead>
<tbody>
<tr>
<td>目标</td>
<td>最大化预期奖励，同时防止策略更新过大（目标函数clip）。</td>
<td>根据人类偏好直接优化策略，使用二元分类目标（使用 KL
散度约束）。</td>
<td>通过最大化 LLM
生成的效用对齐模型，基于前景理论，不需要详细的偏好对。</td>
</tr>
<tr>
<td>输入</td>
<td>来自环境的状态和奖励。</td>
<td>来自环境的状态和人类偏好反馈。</td>
<td>带有二元标签（可取或不可取结果）的 LLM 输出。</td>
</tr>
<tr>
<td>输出</td>
<td>在环境中采取的行动。</td>
<td>在环境中采取的行动，与人类偏好对齐。</td>
<td>与简化人类效用函数对齐的 LLM 生成结果。</td>
</tr>
<tr>
<td>学习机制</td>
<td>使用clip替代目标的策略梯度来更新策略和价值网络。</td>
<td>在人类偏好数据上进行二元交叉熵优化，更新单个策略网络。</td>
<td>基于 LLM 输出与二元反馈的对齐进行优化，无需复杂的偏好模型。</td>
</tr>
<tr>
<td>网络结构</td>
<td>独立的策略网络和价值网络。</td>
<td>单个策略网络。</td>
<td>针对 KTO 方法学调整的 LLM 框架。</td>
</tr>
<tr>
<td>反馈机制</td>
<td>使用来自环境的奖励作为学习的反馈。</td>
<td>使用人类偏好数据作为直接反馈进行学习。</td>
<td>利用对 LLM 输出的二元反馈来指导对齐，无需复杂的偏好数据。</td>
</tr>
<tr>
<td>稳定性</td>
<td>目标函数中的剪辑机制保持策略更新的稳定性。</td>
<td>通过直接优化偏好，利用动态逐例重要性加权实现内在稳定性。</td>
<td>通过简化反馈机制和聚焦于效用最大化来实现稳定的对齐。</td>
</tr>
<tr>
<td>复杂性</td>
<td>由于双网络结构和奖励最大化与策略更新稳定性之间的平衡，较复杂。</td>
<td>更简单，因为它绕过显式的奖励建模，直接从人类偏好优化政策。</td>
<td>通过消除对详细偏好建模的需求，专注于二元效用优化，降低复杂性。</td>
</tr>
<tr>
<td>适用性</td>
<td>适用于各种 RL 环境，其中奖励信号可用。</td>
<td>在与人类偏好对齐至关重要的场景中特别有效。</td>
<td>在快速和简化对齐人类反馈的场景中尤为有用。</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="mixture-of-experts">5. Mixture of Experts</h2>
<p><a target="_blank" rel="noopener" href="https://aman.ai/primers/ai/mixture-of-experts/">Mixture of
Experts</a></p>
<h2 id="deepspeed-框架">6. Deepspeed 框架</h2>
<hr>
<h2 id="decoder-only的模型推理阶段是串行进行计算速度很慢训练的时候实际上是并行训练的介绍训练的细节">6.
decoder
only的模型，推理阶段是串行进行计算,速度很慢。训练的时候实际上是并行训练的，介绍训练的细节。</h2>
<h2 id="encoder-only的结构比如birt如何进行模型训练的">7. encoder
only的结构，比如birt，如何进行模型训练的？</h2>
<h2 id="为什么视觉上使用bntransformer上使用ln-几种-normalization-介绍">8.
为什么视觉上使用BN，transformer上使用LN ？几种 normalization 介绍。</h2>
<h2 id="overview-of-vision-language-models">9. Overview of
Vision-Language Models</h2>
<p>https://aman.ai/primers/ai/interview/</p>
<hr>
<h1 id="reference">Reference</h1>
<p><a target="_blank" rel="noopener" href="https://github.com/315386775/DeepLearing-Interview-Awesome-2024?tab=readme-ov-file">DeepLearing-Interview-Awesome-2024</a></p>
<p><a target="_blank" rel="noopener" href="https://oi-wiki.org/basic/radix-sort/">几种排序算法</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/zhengjingwei/machine-learning-interview?tab=readme-ov-file#1-1">machine-learning-interview</a></p>
<p><a target="_blank" rel="noopener" href="https://aman.ai/primers/ai/">Distilled AI</a></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://xueyu-ubc.github.io/2024/10/08/statistic/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/2024/09/12/multi_modalv2/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Blip, Blip2 (Q-former), InstructBlip, CONCH, PULSE</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "",
    app_key: "",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021-2024
        <i class="ri-heart-fill heart_icon"></i> Xue Yu
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Welcome to XueYu&#39;s Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2021/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i></p>
  <div class="reward-box">
    
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>
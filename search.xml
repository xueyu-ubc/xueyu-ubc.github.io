<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Metropolis-Hastings</title>
      <link href="/2023/07/15/Metropolis-Hastings/"/>
      <url>/2023/07/15/Metropolis-Hastings/</url>
      
        <content type="html"><![CDATA[<h1 id="markov-chains-definitions-and-representations">Markov Chains:Definitions and Representations</h1><h1 id="reference">Reference</h1><ul><li>Mitzenmacher, M., &amp; Upfal, E. (2005). Probability and Computing.Cambridge University Press.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Reading Group </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markov Chains </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Discrete Markov Chains</title>
      <link href="/2023/07/12/Markov-Chains/"/>
      <url>/2023/07/12/Markov-Chains/</url>
      
        <content type="html"><![CDATA[<h1 id="markov-chains-definitions-and-representations">Markov Chains:Definitions and Representations</h1><p>A stochastic process <span class="math inline">\(X = \{ x(t): t\inT\}\)</span> is a collection of random variables.</p><p>There are two elements:</p><ul><li>Time <span class="math inline">\(t\)</span>:<ul><li>discrete time (<span class="math inline">\(T\)</span> is a countablyinfinite set; under this case, we call 'Markov chain')</li><li>continuous time (under this case, we call 'Markov process')</li></ul></li><li>Space <span class="math inline">\(\Omega\)</span>:<ul><li>discrete space (<span class="math inline">\(X_{t}\)</span> comesfrom a countably infinite set)</li><li>continuous space.</li></ul></li></ul><p>Markov chain is a <strong>discrete-time</strong> process for whichthe future behaviour, given the past and the present, only depends onthe present and not on the past.</p><p>Markov process is the <strong>continuous-time</strong> version of aMarkov chain.</p><blockquote><p>Definition 1.[Markov chain] A discrete time stochastic process $ X_0,X_1, X_2, $. . . is a Markov chain if <span class="math display">\[P(X_{t} = a_t | X_{t-1} = a_{t-1}, X_{t-2} = a_{t-2}, ..., X_0 = a_0) =P(X_{t} = a_t | X_{t-1} = a_{t-1}) = P_{a_{t-1},  a_{t}}\]</span></p></blockquote><p>Remark 1: This is time-homogeneous markov chain, for <span class="math inline">\(\forall t\)</span>, for <span class="math inline">\(\forall a_{t-1}, a_{t} \in \Omega\)</span>, thetransition probability <span class="math inline">\(P_{a_{t-1}, a_{t}}\)</span> is the same.</p><p>Remark 2: In DDPM, it is not a time-homogeneous chain, as thetransition probability at t is obtained by a network(t).</p><p>The state <span class="math inline">\(X_{t}\)</span> depends on theprevious state <span class="math inline">\(X_{t-1}\)</span> but isindependent of the particular history <span class="math inline">\(X_{t-2}, X_{t-3},...\)</span>. This is called the<strong>Markov property</strong> or <strong>memorylessproperty</strong>.</p><p>The Markov property does not imply that <span class="math inline">\(X_{t}\)</span> is independent of the randomvariables <span class="math inline">\(X_{0}\)</span>, <span class="math inline">\(X_{1}\)</span>,..., <span class="math inline">\(X_{t-2}\)</span>; it just implies that <strong>anydependency of <span class="math inline">\(X_{t}\)</span> on the past iscaptured in the value of <span class="math inline">\(X_{t-1}\)</span></strong>.</p><p>The Markov chain is <strong>uniquely</strong> defined by the one-steptransition probability matrix P: <span class="math display">\[P =\begin{pmatrix}P_{0,0} &amp; P_{0, 1} &amp; \cdots &amp; P_{0, j} &amp; \cdots\\\vdots &amp; \vdots &amp; \ddots &amp; \vdots&amp; \vdots\\P_{i,0} &amp; P_{i, 1} &amp; \cdots &amp; P_{i, j} &amp; \cdots\\\vdots &amp; \vdots &amp; \ddots &amp; \vdots&amp; \vdots\\\end{pmatrix}\]</span> where <span class="math inline">\(P_{i,j}\)</span> is theprobability of transition from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span>. <span class="math inline">\(P_{i,j} =P(X_{t} = j| X_{t-1} = i), i,j \in \Omega\)</span>. For <span class="math inline">\(i\)</span>, <span class="math inline">\(\sum_{j\geq 0} P_{i,j} = 1\)</span>.</p><h1 id="classification-of-states">Classification of States</h1><p>For simplicity, we assume that the state space <span class="math inline">\(\Omega\)</span> is finite. ## Communicatingclass</p><blockquote><p>Definition 2. [Communicating class] A state <span class="math inline">\(j\)</span> is reachable from state <span class="math inline">\(i\)</span> if there exists a positive integer<span class="math inline">\(n\)</span> such that <span class="math inline">\(P_{i,j}^{(n)} &gt; 0\)</span>. We write <span class="math inline">\(i \rightarrow j\)</span>. If <span class="math inline">\(j\)</span> is reachable from <span class="math inline">\(i\)</span>, and <span class="math inline">\(i\)</span> is reachable from <span class="math inline">\(j\)</span>, then the states <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are said to<strong>communicate</strong>, denoted by <span class="math inline">\(i\leftrightarrow j\)</span>. A communicating class <span class="math inline">\(C\)</span> is a <strong>maximal</strong> set ofstates that communicate with each other. <strong>No state in <span class="math inline">\(C\)</span> communicates with any state not in<span class="math inline">\(C\)</span>.</strong></p></blockquote><h2 id="irreducible">Irreducible</h2><blockquote><p>Definition 3: A Markov chain is <strong>irreducible</strong> if allstates belong to <strong>one</strong> communicating class.</p></blockquote><p>This means that <strong>any state can be reached from any otherstate</strong>. For <span class="math inline">\(\forall i, j \in\Omega\)</span>, <span class="math inline">\(P_{i,j} &gt;0\)</span>.</p><blockquote><p>Lemma 1. A finite Markov chain is irreducible if and only if itsgraph representation is a strongly connected graph.</p></blockquote><h3 id="transient-vs-recurrent-states">Transient vs Recurrentstates</h3><p>Let <span class="math inline">\(r_{i,j}^{t}\)</span> denote theprobability that the chain, starting at state <span class="math inline">\(i\)</span>, <strong>the first time</strong>transition to state <span class="math inline">\(j\)</span> occurs attime <span class="math inline">\(t\)</span>. That is, <span class="math display">\[r_{i,j}^{t} = P(X_{t} = j, X_{s} \neq j, \forall 1 \leq s \leq t-1 |X_{0} = i)\]</span></p><blockquote><p>Definition 4. A state is <strong>recurrent</strong> if <span class="math inline">\(\sum_{t \geq 1} r_{i,i}^{t} = 1\)</span> and it is<strong>transient</strong> if <span class="math inline">\(\sum_{t \geq1} r_{i,i}^{t} &lt; 1\)</span>. A Markov chain is recurrent if everystate in the chain is recurrent.</p></blockquote><ul><li><p>If state i is recurrent then, once the chain visits that state,it will (with probability 1) eventually return to that state. Hence thechain will visit state <span class="math inline">\(i\)</span> over andover again, <strong>infinitely</strong> often.</p></li><li><p>A transient state has the property that a Markov chain startingat this state returns to this state only <strong>finitelyoften</strong>, with probability 1.</p></li><li><p>If one state in a communicating class is transient (respectively,recurrent) then all states in that class are transient (respectively,recurrent).</p></li></ul><blockquote><p>Definition 5. An irreducible Markov chain is called recurrent if atleast one (equivalently, every) state in this chain is recurrent. Anirreducible Markov chain is called transient if at least one(equivalently, every) state in this chain is transient.</p></blockquote><p>Let <span class="math inline">\(h_{i,i} = \sum_{t \geq 1} t \cdotr_{i,i}^{t}\)</span> denote the expected time to return to state <span class="math inline">\(i\)</span> when starting at state <span class="math inline">\(i\)</span>.</p><blockquote><p>Definition 6. A state <span class="math inline">\(i\)</span> is<strong>positive recurrent</strong> if <span class="math inline">\(h_{i,i} &lt; \infty\)</span> and <strong>nullrecurrent</strong> if <span class="math inline">\(h_{i,i} =\infty\)</span>.</p></blockquote><p>Here we give an example of a Markov chain that has null recurrentstates. Consider the following markov chain whose states are thepositive integers.</p><figure><img src="/2023/07/12/Markov-Chains/image.png" alt="Fig. 1 An example of a Markov chain that has null recurrent states"><figcaption aria-hidden="true">Fig. 1 An example of a Markov chain thathas null recurrent states</figcaption></figure><p>Starting at state 1, the probability of not having returned to state1 within the first <span class="math inline">\(t\)</span> steps is <span class="math display">\[\prod_{j=1}^{t} \frac{j}{j+1} = \frac{1}{t+1}.\]</span> The probability of never returning to state 1 from state 1 is0, and state 1 is recurrent. Thus, the probability of the first timetransition to state <span class="math inline">\(1\)</span> occurs attime <span class="math inline">\(t\)</span> is <span class="math display">\[r_{1,1}^{t} = \frac{1}{t} \cdot \frac{1}{t+1} = \frac{1}{t(t+1)}.\]</span> The expected number of steps until the first return to state 1when starting at state 1 is <span class="math display">\[h_{1,1} = \sum_{t = 1}^{\infty} t \cdot r_{1,1}^{t} = \sum_{t =1}^{\infty} \frac{1}{t+1} = \infty.\]</span> State 1 is recurrent but null recurrent.</p><blockquote><p>Lemma 2. In a finite Markov chain: 1. at least one state isrecurrent; and 2. all recurrent states are positive recurrent.</p></blockquote><p>Thus, all states of a finite, irreducible Markov chain are positiverecurrent.</p><h3 id="periodic-vs-aperiodic-states">Periodic vs Aperiodic states</h3><blockquote><p>Definition 7. A state <span class="math inline">\(j\)</span> in adiscrete time Markov chain is <strong>periodic</strong> if there existsan integer <span class="math inline">\(k&gt;1\)</span> such that <span class="math inline">\(P(X_{t+s}= j | X_t = j) = 0\)</span> unless <span class="math inline">\(s\)</span> is divisible by <span class="math inline">\(k\)</span>. A discrete time Markov chain isperiodic if any state in the chain is periodic. A state or chain that isnot periodic is <strong>aperiodic</strong>.</p></blockquote><p>A state <span class="math inline">\(i\)</span> is periodic means thatfor <span class="math inline">\(s = k, 2k, 3k,...\)</span>, <span class="math inline">\(P(X_{t+s}= j | X_t = j) &gt; 0\)</span>.</p><p><strong>NB: k &gt; 1</strong></p><h3 id="ergodic">Ergodic</h3><blockquote><p>Definition 8. An <strong>aperiodic</strong>, <strong>positiverecurrent</strong> state is an <strong>ergodic</strong> state. A Markovchain is ergodic if all its states are ergodic.</p></blockquote><blockquote><p>Corollary 1. Any finite, irreducible, and aperiodic Markov chain isan ergodic chain.</p></blockquote><h3 id="stationary-distribution">Stationary distribution</h3><blockquote><p>Definition 9. A probability distribution <span class="math inline">\(\pi\)</span> on the state space <span class="math inline">\(\Omega\)</span> is called a <strong>stationarydistribution</strong> (or an equilibrium distribution) for the Markovchain with transition probability matrix <span class="math inline">\(P\)</span> if <span class="math inline">\(\pi =\pi P\)</span>.</p></blockquote><p>If a chain ever reaches a stationary distribution then it maintainsthat distribution for all future time, and thus a stationarydistribution represents a steady state or an equilibrium in the chain’sbehavior.</p><blockquote><p>Theorem 1. Consider an irreducible Markov chain, (1) if it is<strong>positive recurrent</strong>, <span class="math inline">\(\exists\)</span> an unique stationary distribution<span class="math inline">\(\pi\)</span>, such that <span class="math inline">\(\pi_i = \frac{1}{h_{i,i}}\)</span>. (2) if it is<strong>null recurrent</strong> or <strong>transient</strong>, nostationary distribution exists.</p></blockquote><blockquote><p>Theorem 2. Consider an irreducible, aperiodic Markov chain, we have<span class="math inline">\(\lim\limits_{t \to \infty} P_{i,j}^{t} =\frac{1}{h_{j,j}}\)</span></p></blockquote><table style="width:7%;"><colgroup><col style="width: 6%"></colgroup><tbody><tr class="odd"><td>????????? if we consider finite state space? if not, it is may not aergodic state. ergodic = aperiodic + positive recurrent</td></tr><tr class="even"><td>if so (finite), in Theorem 1, why do we consider null recurrent?(remember finite+irreducible = positive recurrent)</td></tr></tbody></table><blockquote><p>Theorem 3. Consider an <strong>irreducible</strong> Markov chain, wehave <span class="math inline">\(\lim\limits_{t \to \infty}V_{i,j}^{t}/t = \frac{1}{h_{j,j}}\)</span>, where <span class="math inline">\(V_{i,j}^{t} = |\{ n &lt; t | X_n =j\}|\)</span>.</p></blockquote><p><strong>finite or infinite ???</strong></p><blockquote><p>Theorem 2. Consider a finite, irreducible, and ergodic Markov chainwith transition matrix <span class="math inline">\(P\)</span>. If thereare nonnegative numbers <span class="math inline">\(\bar{\pi} = (\pi_0,\pi_1, ..., \pi_n)\)</span> such that <span class="math inline">\(\sum_{i=0}^{n} \pi_i = 1\)</span> and if, for anypair of states <span class="math inline">\(i, j\)</span>, <span class="math display">\[\pi_i P_{i,j} = \pi_{j} P_{j,i},\]</span> then <span class="math inline">\(\bar{\pi}\)</span> is thestationary distribution corresponding to <span class="math inline">\(P\)</span>.</p></blockquote><p>Proof. <span class="math display">\[\sum_{i} \pi_i P_{i,j} = \sum_{i}\pi_{j} P_{j,i} = \pi_{j}\]</span> Thus, <span class="math inline">\(\bar{\pi} =\bar{\pi}P\)</span>. Since this is a finite, irreducible, and ergodicMarkov chain, <span class="math inline">\(\bar{\pi}\)</span> must be theunique stationary distribution of the Markov chain.</p><p>Remark: Theorem 2 is a sufficient but not necessary condition.</p><h1 id="reference">Reference</h1><ul><li>Mitzenmacher, M., &amp; Upfal, E. (2005). Probability and Computing.Cambridge University Press.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Reading Group </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markov Chains </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Introduction about diffusion model</title>
      <link href="/2023/07/12/diffusion%20model/"/>
      <url>/2023/07/12/diffusion%20model/</url>
      
        <content type="html"><![CDATA[<p>Please refer to <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">Blog</a></p>]]></content>
      
      
      <categories>
          
          <category> Reading Group </category>
          
      </categories>
      
      
        <tags>
            
            <tag> diffusion model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gradient Descent, Stochastic Gradient Descent, Variance Reduction</title>
      <link href="/2021/02/27/GD/"/>
      <url>/2021/02/27/GD/</url>
      
        <content type="html"><![CDATA[<h1 id="svrg2013-accelerating-stochastic-gradient-descent-using-predictive-variance-reduction">[SVRG2013]Accelerating Stochastic Gradient Descent using Predictive VarianceReduction</h1><h2 id="introduction">Introduction</h2><p>考虑如下优化问题 <span class="math display">\[\min P(\omega) = \frac{1}{n}\psi_{i}(\omega)\]</span></p><ul><li>如果采用平方损失，最小二乘回归；</li><li>考虑正则项，令 <span class="math inline">\(\psi_{i}(\omega) = \ln(1+ \exp(-\omega^{T}x_{i}y_{i})) + 0.5\lambda\omega^{T}\omega, y_{i} \in\{-1,1\}\)</span>，regularized logistic regression。</li></ul><p>梯度下降算法更新过程： <span class="math display">\[\omega^{(t)} = \omega^{(t-1)} - \eta_{t}\nabla P(\omega^{(t-1)}) =\omega^{(t-1)} - \frac{\eta_{t}}{n}\sum_{i=1}^{n}\nabla\psi_{i}(\omega^{(t-1)})\]</span></p><p>但是，在每一步，GD都需要计算 <span class="math inline">\(n\)</span>个一阶偏导，计算量大。所以，一个改进就是随机梯度下降SGD：在每一步迭代时，随机从<span class="math inline">\(\{1,...,n\}\)</span> 中抽取 <span class="math inline">\(i_{t}\)</span>，然后 <span class="math display">\[\omega^{(t)} = \omega^{(t-1)} - \eta_{t}\nabla\psi_{i_{t}}(\omega^{(t-1)})\]</span></p><p>期望 <span class="math inline">\(E[\omega^{(t)}|\omega^{(t-1)}]\)</span>同梯度更新的结果一致。 SGD的更一般表达形式为 <span class="math display">\[\omega^{(t)} = \omega^{(t-1)} - \eta_{t}g_{t}(\omega^{(t-1)},  \xi_{t})\]</span></p><p><span class="math inline">\(\xi_{t}\)</span> 为一个依赖于 <span class="math inline">\(\omega^{(t-1)}\)</span> 的随机变量， 并且期望<span class="math inline">\(E[g_{t}(\omega^{(t-1)},\xi_{t})|\omega^{(t-1)}] = \nabla P(\omega^{(t-1)})\)</span>。</p><p>SGD的优势就是每步迭代只需要计算一个梯度，因此计算成本是GD的 <span class="math inline">\(\frac{1}{n}\)</span>。但是，SGD的一个缺点就是随机性引入了方差：虽然<span class="math inline">\(g_{t}(\omega^{(t-1)}, \xi_{t})\)</span>的期望等于梯度 <span class="math inline">\(\nablaP(\omega^{(t-1)})\)</span>，但是每个<span class="math inline">\(g_{t}(\omega^{(t-1)}, \xi_{t})\)</span>是不同的。方差的出现导致收敛速度变慢。对于SGD，由于随机取样带来的方差，一般都会要求其步长 <span class="math inline">\(\eta_{t} = O(1/t)\)</span>，从而得到一个sub-linear 收敛率 <span class="math inline">\(O(1/t)\)</span>。</p><ul><li>GD: 每步迭代计算慢，收敛快。</li><li>SGD：每步迭代计算快，收敛慢。</li></ul><p>为了改进SGD，一些学者开始设计算法以减少方差，从而可以使用较大的步长<span class="math inline">\(\eta_{t}\)</span>。有一些算法被提出来，比如：SAG(stochasticaveragegradient)，SDCA。但是这两个算法需要存储所有的梯度，一些情况下不太实际。因此作者提出了一个新的算法，该算法不需要存储所有的梯度信息，并且有较快的收敛速度，可以应用于非凸优化问题。</p><h2 id="stochastic-variance-reduced-gradient-svrg">Stochastic VarianceReduced Gradient (SVRG)</h2><p>为了保证收敛，SGD的步长必须衰减到0，从而导致收敛率变慢。需要较小步长的原因就是SGD的方差。作者提出一个解决方案。每进行<span class="math inline">\(m\)</span> 次SGD迭代后，记录当前参数 <span class="math inline">\(\tilde{\omega}\)</span> 以及平均梯度： <span class="math display">\[\tilde{\mu} = \nabla P(\tilde{\omega}) = \frac{1}{n}\sum_{i=1}^{n}\nabla \psi_{i}(\tilde{\omega}).\]</span></p><p>然后接下来的更新为：</p><p><span class="math display">\[\omega^{(t)} = \omega^{(t-1)} - \eta_{t}(\nabla\psi_{i_{t}}(\omega^{(t-1)}) - \nabla \psi_{i_{t}}(\tilde{\omega}) +\tilde{\mu})\]</span></p><p>注意到： <span class="math display">\[E[\omega^{(t)}|\omega^{(t-1)}] = \omega^{(t-1)} - \eta_{t}\nablaP(\omega^{(t-1)})\]</span></p><p>算法如下：</p><p><img src="/2021/02/27/GD/SVRG.png"></p><p>更新步骤中梯度的方差是减小的。当 <span class="math inline">\(\tilde{\omega}\)</span> 和 <span class="math inline">\(\omega^{(t)}\)</span> 收敛到最优参数 <span class="math inline">\(\omega_{*}\)</span>，<span class="math inline">\(\tilde{\mu} \to 0\)</span>， <span class="math inline">\(\nabla\psi_{i}(\tilde{\omega}) \to \nabla\psi_{i}(\omega_{*})\)</span>，有 <span class="math display">\[\nabla\psi_{i}(\omega^{(t-1)}) - \nabla\psi_{i}(\tilde{\omega}) + \tilde{\mu} \to \nabla\psi_{i}(\omega^{(t-1)}) -\nabla\psi_{i}(\omega_{*}) \to 0\]</span></p><p>SVRG的学习率不需要衰减，因此能有较快的收敛速度。作者提到，参数 <span class="math inline">\(m\)</span> 应该 <span class="math inline">\(O(n)\)</span>， 比如对于凸问题：<span class="math inline">\(m = 2n\)</span>，非凸问题：<span class="math inline">\(m = 2n\)</span>。</p><h1 id="saga2015-saga-a-fast-incremental-gradient-method-with-support-for-non-strongly-convex-composite-objectives">[SAGA2015]SAGA: A Fast Incremental Gradient Method With Support for Non-StronglyConvex Composite Objectives</h1><p>考虑最小化函数： <span class="math display">\[f(x) = \frac{1}{n}\sum_{i=1}^{n}f_{i}(x)\]</span></p><p>作者提出了一个叫做SAGA的算法，在目标函数为强凸函数时，SAGA的收敛速度优于SAG和SVRG。算法如下：</p><p><img src="/2021/02/27/GD/SAGA.png"></p><p>本文给出了variance reduction算法的一个解释： <img src="/2021/02/27/GD/SAGA1.png"></p><p>几种算法比较： <img src="/2021/02/27/GD/SAGA2.png"></p><h1 id="variance-reduced-stochastic-gradient-descent-with-neighbors-2015">[VarianceReduced Stochastic Gradient Descent with Neighbors 2015]</h1><h1 id="katyusha-2017-katyusha-the-first-direct-acceleration-of-stochastic-gradient-methods">[Katyusha2017] Katyusha: The First Direct Acceleration of Stochastic GradientMethods</h1><p>Nesterov's momentum通常用于加速梯度下降算法，但是，对于随机梯度下降，Nesterov's momentum可能无法对算法进行加速，即使优化目标为凸函数。因此，针对SGD，作者提出Katyusha 算法，借助于动量Katyusha momentum实现加速SGD。</p><p>考虑如下优化问题：</p><p><span class="math display">\[\min_{x \in \mathbb{R}^{d}} \{F(x) = f(x) + \psi(x) =\frac{1}{n}\sum_{i=1}^{n} f_{i}(x) + \psi(x)\}\]</span> 其中 <span class="math inline">\(f(x) =\frac{1}{n}\sum_{i=1}^{n} f_{i}(x)\)</span> 为凸函数，并且是 <span class="math inline">\(n\)</span> 个凸函数的有限平均。<span class="math inline">\(\psi(x)\)</span>为凸函数，可为近端函数。大多数假设 <span class="math inline">\(\psi(x)\)</span> 为 <span class="math inline">\(\sigma\)</span>-strongly，并且 <span class="math inline">\(f_{i}(x)\)</span> L-smooth。</p><p>作者提出一个可以求解上述优化问题的加速随机梯度下降算法-Katyusha：</p><p><img src="/2021/02/27/GD/ka.png"></p><p>其中，<span class="math inline">\(\tilde{x}\)</span> 为snapshotpoint，每经过 <span class="math inline">\(n\)</span>次迭代更新一次。<span class="math inline">\(\tilde{\nabla}_{k+1}\)</span> 为variance reduction中的梯度形式。<span class="math inline">\(\tau_{1}\)</span>，<span class="math inline">\(\tau_{2} \in[0,1]\)</span> 为两个动量参数，<span class="math inline">\(\alpha = \frac{1}{3\tau_{1}L}\)</span>。</p><h2 id="our-new-technique-katyusha-momentum">Our New Technique –Katyusha Momentum</h2><p>最novel的部分是 <span class="math inline">\(x_{k+1}\)</span>的更新步骤，是 <span class="math inline">\(y_{k}\)</span>, <span class="math inline">\(z_{k}\)</span> 以及 <span class="math inline">\(\tilde{x}\)</span> 的凸组合。理论建议参数 <span class="math inline">\(\tau_{2} = 0.5\)</span>，<span class="math inline">\(\tau_{1} = \min\{\sqrt{n\sigma/L},0.5\}\)</span>。</p><p>对于传统的加速梯度下降算法，<span class="math inline">\(x_{k+1}\)</span> 仅仅是 <span class="math inline">\(y_{k}\)</span> 和 <span class="math inline">\(z_{k}\)</span> 的凸组合，<span class="math inline">\(z_{k}\)</span>起到了一个“动量”的作用，即将历史加权的梯度信息添加到 <span class="math inline">\(y_{k+1}\)</span> 上。比如假设 <span class="math inline">\(\tau_{2} = 0, \tau_{1} = \tau\)</span>, <span class="math inline">\(x_{0} = y_{0} = z_{0}\)</span>，我们可以得到：</p><p><img src="/2021/02/27/GD/ka1.png"></p><p>由于 <span class="math inline">\(\alpha\)</span> 通常大于 <span class="math inline">\(1/3L\)</span>，上述递推过程意味着随着迭代进行，梯度<span class="math inline">\(\tilde{\nabla}_{t}\)</span>的贡献越高。比如，<span class="math inline">\(\tilde{\nabla}_{1}\)</span> 的权重不断增大 (<span class="math inline">\(\frac{1}{3L} &lt; ((1-\tau)\frac{1}{3L} +\tau\alpha) &lt; ((1 - \tau)^{2}\frac{1}{3L} + (1 - (1 -\tau)^{2})\alpha)\)</span>)。这就是一阶加速方法的核心思想。</p><p>在Katyusha算法中，作者认为 <span class="math inline">\(\tilde{x}\)</span> 同等重要，它能保证 <span class="math inline">\(x_{k+1}\)</span> 不要太远离 <span class="math inline">\(\tilde{x}\)</span>。<span class="math inline">\(\tilde{x}\)</span> 的添加可以看作是一个 “negativemomentum”，使 <span class="math inline">\(x_{k+1}\)</span> back to <span class="math inline">\(\tilde{x}\)</span>，抵消一部分前面迭代时的positive momentum”。</p><p>当 <span class="math inline">\(\tau_{1} = \tau_{2} = 0.5\)</span>时，Katyusha同SVRG几乎一致。</p><h1 id="l-svrg-l-katyusha-2019-dont-jump-through-hoops-and-remove-those-loops-svrg-and-katyusha-are-betterwithout-the-outer-loop">[L-SVRG,L-Katyusha 2019] Don’t Jump Through Hoops and Remove Those Loops: SVRGand Katyusha are BetterWithout the Outer Loop</h1><p>SVRG和Katyusha算法的共同关键结构就是两者都包含一个外层循环 (outerloop)。最初先在outerloop上使用所有样本计算梯度，然后计算出来的结果再用于内层循环 (innerloop)，结合新的随机梯度信息，构造variance-reduced梯度估计量。作者指出，由于SVRG和Katyusha算法都包括一个outerloop，所以存在一些问题，比如：算法很难分析；人们需要决定内部循环的次数。对于SVRG，理论上内部循环的最优次数取决于<span class="math inline">\(L\)</span>和 <span class="math inline">\(\mu\)</span>，但是 <span class="math inline">\(\mu\)</span>通常未知。由于这些问题存在，人们只能选择次优的inner loopsize，通常设置内部循环次数为 <span class="math inline">\(O(n)\)</span>或者 <span class="math inline">\(n\)</span>。</p><p>在这篇论文中，作者将外层循环 (outer loop)丢弃，在每次迭代时采用掷硬币技巧决定是否计算梯度，从而解决了上述问题。作者证明，新提出的算法和原始两个算法具有同样的理论性质。</p><p><img src="/2021/02/27/GD/loopless1.jpg"> <img src="/2021/02/27/GD/loopless1.jpg"></p><h1 id="l-svrg-l-katyusha-2019-l-svrg-and-l-katyusha-with-arbitrary-sampling">[L-SVRG,L-Katyusha 2019] L-SVRG and L-Katyusha with Arbitrary Sampling</h1><h1 id="参考文献">参考文献</h1><ul><li>Johnson, R. and Zhang, T. Accelerating stochastic gradient descentusing predictive variance reduction. In Advances in Neural InformationProcessing Systems 26, pp. 315–323, 2013a.<br></li><li>Defazio, A., Bach, F., and Lacoste-Julien, S. SAGA: a fastincremental gradient method with support for non-strongly convexcomposite objectives. In Advances in Neural Information ProcessingSystems, pp. 1646–1654, 2014.<br></li><li>Hofmann, T., Lucchi, A., Lacoste-Julien, S., and McWilliams, B.Variance reduced stochastic gradient descent with neighbors. In Advancesin Neural Information Processing Systems, pp.2305–2313, 2015.<br></li><li>Allen-Zhu, Z. Katyusha: The first direct acceleration of stochasticgradient methods. In Proceedings of the 49th Annual ACM SIGACT Symposiumon Theory of Computing, pp.1200–1205. ACM,2017.</li><li>Kovalev, D., Horváth, S., and Richtárik, P. Don’t jump through hoopsand remove those loops: SVRG and Katyusha are better without the outerloop. In Proceedings of the 31st International Conference on AlgorithmicLearning Theory, 2020.</li><li>Qian, X., Qu, Z., and Richtárik, P. L-SVRG and L-Katyusha witharbitrary sampling. arXiv preprint arXiv:1906.01481, 2019a.</li></ul>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ADMMdecentralized</title>
      <link href="/2021/02/03/ADMMdecentralized/"/>
      <url>/2021/02/03/ADMMdecentralized/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="#abstract">Abstract</a></li><li><a href="#introduction">Introduction</a></li><li><a href="#preliminaries">Preliminaries</a><ul><li><a href="#notations-and-problem-setting">Notations and ProblemSetting</a></li></ul></li><li><a href="#model-propagation">Model Propagation</a><ul><li><a href="#asynchronous-gossip-algorithm">Asynchronous GossipAlgorithm</a></li></ul></li><li><a href="#collaborative-learning">Collaborative Learning</a><ul><li><a href="#problem-formulation">Problem Formulation</a></li><li><a href="#asynchronous-gossip-algorithm-1">Asynchronous GossipAlgorithm</a></li></ul></li><li><a href="#experiments">Experiments</a><ul><li><a href="#collaborative-linear-classification">Collaborative LinearClassification</a></li></ul></li><li><a href="#参考文献">参考文献</a></li></ul><!-- /TOC --><h1 id="abstract">Abstract</h1><p>考虑点对点的协作网络。本文解决的问题是：每个节点如何与具有相似目标的其他节点进行通信来改善本地模型？作者介绍了两种完全去中心化的算法，一种是受标签传播的启发，旨在平滑预先训练好的局部模型；第二种方法，节点基于本地数据核相邻节点进行迭代更新来共同学习和传播。</p><h1 id="introduction">Introduction</h1><p>数据不断产生，当前从数据中提取信息的主要方式是收集所有用户的个人数据于一个服务器上，然后进行数据挖掘。但是，中心化的方式存在一些问题，比如说一些用户拒绝提供个人数据，带宽和设备花费问题。即使一些算法允许数据分布在用户设备上，通常需要中心端来进行聚合和协调。</p><p>在本文中，作者考虑完全去中心化的点对点网络。不同于那些求解全局模型的算法，本文关注于每个节点可以根据自身目标函数学习一个个性化模型。作者假设网络结构已知，该网络结构能够反映出不同节点的相似度（如果两个节点具有相似的目标函数，那么这两个节点在网络中是邻居），每个节点只知道与其直接相邻的节点。一个节点不仅可以根据自身数据学习模型，还可以结合它的邻居。假设每个节点只知道相邻节点的信息，不知道整个网络结构。</p><p>作者提出两个算法。第一个是 modelpropagation：首先，每个节点先基于自己的局部数据学习到模型参数，然后，结合整个网络结构，平滑这些参数。第二个是collaborativelearning，这个算法更加灵活，它通过优化一个模型参数正则化（平滑）和局部模型准确性上的折中问题。作者基于分布式的ADMM算法提出一个异步gossip算法。</p><h1 id="preliminaries">Preliminaries</h1><h2 id="notations-and-problem-setting">Notations and ProblemSetting</h2><p>考虑 <span class="math inline">\(n\)</span> 个节点 <span class="math inline">\(V = [n] = \{1,...,n\}\)</span>。凸的损失函数 <span class="math inline">\(l: \mathbb{R}^{p} \times \mathcal{X} \times\mathcal{Y}\)</span>，节点 <span class="math inline">\(i\)</span>的目标是学习模型参数 <span class="math inline">\(\theta_{i} \in\mathbb{R}^{p}\)</span>，使得关于未知分布 <span class="math inline">\(\mu_{i}\)</span> 的期望损失 <span class="math inline">\(E_{(x_{i}, y_{i})\sim \mu_{i}}l(\theta_{i}; x_{i},y_{i})\)</span> 很小。节点 <span class="math inline">\(i\)</span> 具有<span class="math inline">\(m_{i}\)</span> 个来自分布 <span class="math inline">\(\mu_{i}\)</span> 的 i.i.d 的训练样本 <span class="math inline">\(S_{i} = \{(x_{i}^{j},y_{i}^{j})\}_{j=1}^{m_{i}}\)</span>。允许不同节点的样本量相差很大。每个节点可以最小化局部损失函数得到<span class="math inline">\(\theta_{i}^{sol}\)</span>:</p><p><span class="math display">\[\theta_{i}^{sol} \in \argmin_{\theta \in \mathbb{R}^{p}} L_{i}(\theta) =\sum_{j=1}^{m_{i}} l(\theta;x_{i}^{j}, y_{i}^{j}).\]</span></p><p>我们目标是通过结合其他节点信息，进一步改善上述模型。考虑一个加权网络结构<span class="math inline">\(G = (V, E)\)</span>，具有 <span class="math inline">\(V\)</span> 个节点，<span class="math inline">\(E\subseteq V \times V\)</span> 为无向边。定义 <span class="math inline">\(W \in \mathbb{R}^{n \times n}\)</span> 为由 <span class="math inline">\(G\)</span> 得到的对称非负加权矩阵，如果 <span class="math inline">\((i,j) \ne E\)</span> or <span class="math inline">\(i = j\)</span>， <span class="math inline">\(W_{ij} =0\)</span>。本文假设权重矩阵已知。定义对角阵 <span class="math inline">\(D\in \mathbb{R}^{n \times n}\)</span>，<span class="math inline">\(D_{ii} = \sum_{j=1}^{n} W_{ij}\)</span>。节点<span class="math inline">\(i\)</span> 的邻域 ：<span class="math inline">\(\mathcal{N}_{i} = \{j \ne i: W_{ij} &gt;0\}\)</span>。</p><h1 id="model-propagation">Model Propagation</h1><p>假设每个节点通过最小化局部损失函数得到各自的模型 <span class="math inline">\(\theta_{i}^{sol}\)</span>。由于每个节点上的模型都是在不同大小数据集上考虑得到，作者使用<span class="math inline">\(c_{i} \in (0,1]\)</span>定义每个节点模型的可信度。 <span class="math inline">\(c_{i}\)</span>的值应该和节点 <span class="math inline">\(i\)</span>的样本量大小呈正相关，可以设置为 <span class="math inline">\(c_{i} =\frac{m_{i}}{\max_{j} m_{j}}\)</span>。如果 <span class="math inline">\(m_{i}=0\)</span>，可以设置为一个小量。</p><p>定义 <span class="math inline">\(\Theta = [\theta_{1};\theta_{2};...;\theta_{n}] \in \mathbb{R}^{n \timesp}\)</span>，我们要优化的目标函数为：</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612018569.jpg" alt="1612018569"><figcaption aria-hidden="true">1612018569</figcaption></figure><p>第一项二次函数用来平滑相邻节点的参数，当两个节点间权重越大时，节点间参数越相近；第二项的目的是使具有较高置信度的模型的参数不要太远离各自模型上的参数。具有较低置信度的模型的参数被允许具有较大的偏差，容易被相邻节点影响。<span class="math inline">\(D_{ii}\)</span> 的目的是为了normalization。</p><p><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612018994(1).png" alt="1612018994(1)"><br><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612019022(1).png" alt="1612019022(1)"></p><p>计算 (4)需要知道整个网络的信息以及所有节点的独立模型信息，这对于节点而言是未知的，因为每个节点只知道相邻节点的信息。因此，作者提出下面的迭代形式：</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612019342(1).png" alt="1612019342(1)"><figcaption aria-hidden="true">1612019342(1)</figcaption></figure><p>作者证明，无论初始值 <span class="math inline">\(\Theta(0)\)</span>取何值，上述迭代序列收敛到 (4)。(5) 式可以进一步分解为</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612019480(1).png" alt="1612019480(1)"><figcaption aria-hidden="true">1612019480(1)</figcaption></figure><p>考虑一个同步计算：在每一步，每个节点都和其所有相邻节点进行通信，收集它们当前参数，然后使用它们的参数更新上式。同步更新会导致很大的延迟，因为任何节点都必须等剩余节点更新完后才能进行下一步更新。并且，每一步，所有节点都需要和其邻居节点进行通信，降低了算法的效率。所以作者提出一个异步算法。</p><h2 id="asynchronous-gossip-algorithm">Asynchronous GossipAlgorithm</h2><p>在异步设置中，每个节点都有一个局部clock ticking at times of rate 1Poisson process.由于节点都是独立同分布的，所以相当于在每一步时等概率激活每个节点。</p><p>在时间 <span class="math inline">\(t\)</span>时，每个节点都存有相邻节点的信息。以数学形式表示，考虑矩阵 <span class="math inline">\(\tilde{\Theta}_{i}(t) \in \mathbb{R}^{n \timesp}\)</span>，第 <span class="math inline">\(i\)</span> 行 <span class="math inline">\(\tilde{\Theta}_{i}^{i}(t) \in\mathbb{R}^{p}\)</span> 为节点 <span class="math inline">\(i\)</span>在时刻 <span class="math inline">\(t\)</span> 的模型参数，<span class="math inline">\(\tilde{\Theta}_{i}^{j}(t) \in \mathbb{R}^{p} (j\ne i)\)</span> 为节点 <span class="math inline">\(i\)</span>储存的关于邻居节点 <span class="math inline">\(j\)</span> 的lastknowledge. 对于 <span class="math inline">\(j \notin \mathcal{N}_{i}\bigcup \{i\}\)</span>，<span class="math inline">\(\forall t &gt;0\)</span>，<span class="math inline">\(\tilde{\Theta}_{i}^{j}(t) =0\)</span>。令<span class="math inline">\(\tilde{\Theta} =[\tilde{\Theta}_{1}^{T}, ...,\tilde{\Theta}_{n}^{T}] \in\mathbb{R}^{n^{2} \times p}\)</span>。</p><p>如果在时间 <span class="math inline">\(t\)</span> 时，节点 <span class="math inline">\(i\)</span> wakes up，执行如下步骤：</p><ul><li><p>communication: 节点 <span class="math inline">\(i\)</span>随机选择一个邻居节点 <span class="math inline">\(j \in\mathcal{N}_{i}\)</span>，(先验概率 <span class="math inline">\(\pi_{i}^{j}\)</span>)，节点 <span class="math inline">\(i\)</span> 和节点 <span class="math inline">\(j\)</span> 同时更新它们的参数： <span class="math display">\[\tilde{\Theta}_{i}^{j}(t+1) = \tilde{\Theta}_{j}^{j}(t) \qquad\tilde{\Theta}_{j}^{i}(t+1) = \tilde{\Theta}_{i}^{i}(t),\]</span></p></li><li><p>update: 基于当前信息，节点 <span class="math inline">\(i\)</span>和节点 <span class="math inline">\(j\)</span> 更新自己的模型参数： <span class="math display">\[\tilde{\Theta}_{l}^{l}(t+1) = (\alpha +\bar{\alpha}c_{l})^{-1}(\alpha\sum_{k \in \mathcal{N}_{l}}\frac{W_{lk}}{D_{ll}}\tilde{\Theta}_{l}^{k}(t+1) +\bar{\alpha}c_{l}\theta^{sol}_{l}) \quad(l \in \{i,j\}).\]</span></p><p>网络中的其他变量保持不变。作者提出的算法属于 gossipalgorithms，每个节点每次最多只和一个邻居节点通信。</p><p>作者证明，上述算法可以收敛到使每个节点具有最优参数。</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612340701.jpg" alt="1612340701"><figcaption aria-hidden="true">1612340701</figcaption></figure></li></ul><h1 id="collaborative-learning">Collaborative Learning</h1><p>上述算法先在局部节点上进行学习，然后在进行网络通信。在这部分，作者提出了一个使节点可以同时进行基于局部数据和邻居节点信息更新模型参数的算法。相较于前面的算法，该算法通信成本较高，但是估计精度高于前者。</p><h2 id="problem-formulation">Problem Formulation</h2><p>优化目标：</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612341031(1).png" alt="1612341031(1)"><figcaption aria-hidden="true">1612341031(1)</figcaption></figure><p>注意到，这里的置信度通过 <span class="math inline">\(\mathcal{L}_{i}\)</span> 体现，因为 <span class="math inline">\(\mathcal{L}_{i}\)</span> 为局部节点 <span class="math inline">\(i\)</span> 上所有观测的损失函数和。</p><p>一般情况下，上述问题没有解析解，作者提出一个分散式迭代算法进行求解。</p><h2 id="asynchronous-gossip-algorithm-1">Asynchronous GossipAlgorithm</h2><p>作者基于ADMM提出了一个异步分散式算法。本文的目的不是寻找一个consensus解，因为我们的目标是为了学习到每个节点的personalized model.作者通过将问题 (7)进行变换为一个部分consensus问题，使用ADMMD进行求解。</p><p>令 <span class="math inline">\(\Theta_{i} \in\mathbb{R}^{(|\mathcal{N_{i}}|+1)\times p}\)</span> 为变量 <span class="math inline">\(\theta_{j} \in \mathbb{R}^{p}(j \in\mathcal{N_{i}} \bigcup \{i\})\)</span> 的集合。定义 <span class="math inline">\(\theta_{j}\)</span> 为 <span class="math inline">\(\Theta_{i}^{j}\)</span>。优化问题(7)重新写为：</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612341938(1).png" alt="1612341938(1)"><figcaption aria-hidden="true">1612341938(1)</figcaption></figure><p>在这个目标函数中，所有的节点相互依赖，因为它们共享一个优化变量 <span class="math inline">\(\in\Theta\)</span>。为了使用ADMM，需要将各个节点的优化变量独立，对于每个节点<span class="math inline">\(i\)</span>，定义一个local copy <span class="math inline">\(\tilde{\Theta}_{i} \in\mathbb{R}^{(|\mathcal{N_{i}}|+1)\times p}\)</span>，添加等式约束：<span class="math inline">\(\tilde{\Theta}_{i}^{i} =\tilde{\Theta}_{j}^{i}\)</span>，对于所有的 <span class="math inline">\(i \in [n], j \in \mathcal{N}_{i}\)</span>。</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612342502(1).png" alt="1612342502(1)"><figcaption aria-hidden="true">1612342502(1)</figcaption></figure><p>增广拉格朗日乘子：</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612342580(1).png" alt="1612342580(1)"><figcaption aria-hidden="true">1612342580(1)</figcaption></figure><p>算法如下，假设时刻 <span class="math inline">\(t\)</span> 时节点<span class="math inline">\(i\)</span> wakes up，选取邻居节点 <span class="math inline">\(j \in \mathcal{N}_{i}\)</span>，定义 <span class="math inline">\(e = (i,j)\)</span>，</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612342728(1).png" alt="1612342728(1)"><figcaption aria-hidden="true">1612342728(1)</figcaption></figure><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612342765(1).png" alt="1612342765(1)"><figcaption aria-hidden="true">1612342765(1)</figcaption></figure><h1 id="experiments">Experiments</h1><h2 id="collaborative-linear-classification">Collaborative LinearClassification</h2><p>考虑100个节点，每个节点的目标是建立一个线性分类模型 in <span class="math inline">\(\mathbb{R}^{p}\)</span>。为了方便可视化，每个节点的真实参数位于2维子空间：将其参数看作是<span class="math inline">\(\mathbb{R}^{p}\)</span>空间中的向量，前两项从正态分布中随机产生，剩余项为0。两个节点 <span class="math inline">\(i\)</span> 和节点 <span class="math inline">\(j\)</span> 的相似度通过参数距离的高斯核定义，定义<span class="math inline">\(\phi_{ij}\)</span>为两个真实参数在单位圆上投影的夹角，<span class="math inline">\(W_{ij} =\exp(\cos \phi_{ij} - 1)/\sigma\)</span>，<span class="math inline">\(\sigma =0.1\)</span>。权重为负值的将被忽略。每个节点具有随机的训练样本，样本的标签为二元标签，由线性分类模型产生。以概率0.05随机使标签反转，以产生噪音数据。每个节点的损失函数为hinge损失：<span class="math inline">\(l(\theta;(x_{i}, y_{i})) = \max(0,1-y_{i}\theta^{T}x_{i})\)</span>。作者评估了模型在100个测试样本上的预测精度。</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1612343843(1).png" alt="1612343843(1)"><figcaption aria-hidden="true">1612343843(1)</figcaption></figure><h1 id="参考文献">参考文献</h1><ul><li>Vanhaesebrouck, P., Bellet, A. &amp; Tommasi, M.. (2017).Decentralized Collaborative Learning of Personalized Models overNetworks. Proceedings of the 20th International Conference on ArtificialIntelligence and Statistics, in PMLR 54:509-517</li></ul>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lower Bounds and Optimal Algorithms for Personalized Federated Learning</title>
      <link href="/2021/01/26/AL2SGD/"/>
      <url>/2021/01/26/AL2SGD/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="#introduction">Introduction</a></li><li><a href="#contributions">Contributions</a></li><li><a href="#lower-complexity-bounds">Lower complexity bounds</a><ul><li><a href="#lower-complexity-bounds-on-the-communication">Lowercomplexity bounds on the communication</a></li><li><a href="#lower-complexity-bounds-on-the-local-computation">Lowercomplexity bounds on the local computation</a></li></ul></li><li><a href="#优化算法">优化算法</a><ul><li><a href="#accelerated-proximal-gradient-descent-apgd-for-federated-learning">AcceleratedProximal Gradient Descent (APGD) for Federated Learning</a></li><li><a href="#beyond-proximal-oracle-inexact-apgd-iapgd">Beyond proximaloracle: Inexact APGD (IAPGD)</a></li><li><a href="#accelerated-l2sgd">Accelerated L2SGD+</a></li></ul></li><li><a href="#experiments">Experiments</a></li><li><a href="#参考文献">参考文献</a></li></ul><!-- /TOC --><h1 id="introduction">Introduction</h1><p>作者在前文考虑了一个新的优化问题： <span class="math display">\[\min_{\mathbf{x_{1},...,x_{n}} \in \mathbb{R}^{d}} \{ F(\mathbf{x}) :=f(\mathbf{x}) + \lambda \psi(\mathbf{x})\}\]</span> <span class="math display">\[f(\mathbf{x}):= \frac{1}{n}\sum_{i=1}^{n}f_{i}(\mathbf{x_{i}}), \quad\psi(\mathbf{x}):= \frac{1}{2n}\sum_{i=1}^{n}\|\mathbf{x_{i}} -\mathbf{\bar{x}}\|^{2}\]</span></p><p>Remark：该问题的最优解 <span class="math inline">\(\mathbf{x}^{*} =[\mathbf{x}_{1}^{*},..., \mathbf{x}_{n}^{*}] \in\mathbb{R}^{nd}\)</span> 可以被表示为 <span class="math inline">\(\mathbf{x}^{*}_{i} = \mathbf{\bar{x}}^{*} -\frac{1}{\lambda}\nabla f_{i}(\mathbf{x}_{i}^{*})\)</span>，其中 <span class="math inline">\(\mathbf{\bar{x}}^{*} = \frac{1}{n}\sum_{i=1}^{n}\mathbf{x}_{i}^{*}\)</span>，该形式与MAML相似。</p><h1 id="contributions">Contributions</h1><p>在这篇论文中，作者给出了求解上述优化问题的通信和局部计算复杂度（迭代次数）的最低界限，并且给出了几种能够达到最低界限的算法。</p><ul><li><p>lower bound on the communication complexity.作者证明对于任意一个满足一定假设条件的算法，会有一个L-smooth, <span class="math inline">\(\mu\)</span>-strongly convex 局部目标函数 <span class="math inline">\(f_{i}\)</span> 至少需要通信 <span class="math inline">\(O(\sqrt{\frac{\min\{L,\lambda\}}{\mu}}\log\frac{1}{\epsilon})\)</span> 轮才能得到最优解 <span class="math inline">\(\epsilon\)</span>邻域内的解。</p></li><li><p>lower complexity bound on the number of local oracle calls.作者证明对于局部近端梯度下降，至少需要迭代<span class="math inline">\(O(\sqrt{\frac{\min\{L,\lambda\}}{\mu}}\log\frac{1}{\epsilon})\)</span>次；对于局部梯度下降，至少需要进行 <span class="math inline">\(O(\sqrt{\frac{L}{\mu}}\log\frac{1}{\epsilon})\)</span>次迭代；若每个目标函数为 <span class="math inline">\(m\)</span>个有限和形式（<span class="math inline">\(\tilde{L}\)</span>-smooth)，至少需要 <span class="math inline">\(O((m +\sqrt{\frac{m\tilde{L}}{\mu}})\log\frac{1}{\epsilon})\)</span>次。</p></li><li><p>作者讨论了不同的用于求解上述优化问题的算法，这些算法在不同设定下可以达到最优通信复杂度和最优局部梯度复杂度。。首先是加速近端梯度下降算法(APGD)，作者考虑两种不同的应用方式，第一种是：函数<span class="math inline">\(f\)</span> 采用梯度下降，<span class="math inline">\(\lambda \psi\)</span>采用近端梯度下降，第二种是反过来。对于第一种情况，当 <span class="math inline">\(L \leq \lambda\)</span>时，我们可以实现最优通信复杂度和局部梯度复杂度 <span class="math inline">\(O(\sqrt{\frac{L}{\mu}}\log\frac{1}{\epsilon})\)</span>；对于第二种情况，当<span class="math inline">\(L \geq \lambda\)</span>时，我们可以得到最优通信复杂度和局部近端复杂度 <span class="math inline">\(O(\sqrt{\frac{\lambda}{\mu}}\log\frac{1}{\epsilon})\)</span>。受一篇论文启发，作者提到局部近端可以由局部加速梯度下降 (Local AGD) 近似(inexactly) 得到，当目标函数为有限和形式，还可以采用Katyusha算法近似得到。Local AGD 可以得到 <span class="math inline">\(O(\sqrt{\frac{\lambda}{\mu}}\log\frac{1}{\epsilon})\)</span>的通信复杂度，以及 <span class="math inline">\(\tilde{O}(\sqrt{\frac{L+\lambda}{\mu}})\)</span>的局部梯度复杂度，当 <span class="math inline">\(L \geq\lambda\)</span>（取决于对数因子）时，两者都能达到最优。同样，当局部采用 Katyusha时，我们可以得到通信复杂度 <span class="math inline">\(O(\sqrt{\frac{\lambda}{\mu}}\log\frac{1}{\epsilon})\)</span>和局部梯度复杂度 <span class="math inline">\(\tilde{O}(m\sqrt{\frac{\lambda}{\mu}} + \sqrt{m\frac{\tilde{L}}{\mu}})\)</span>，前者当 <span class="math inline">\(L\geq \Lambda\)</span> 时能达到最优，后者当 <span class="math inline">\(m\lambda \leq \tilde{L}\)</span>（取决于对数因子）时达到最优。</p></li><li><p>作者提出了加速的L2SGD+算法-AL2SGD+，该算法可以实现最优通信复杂 度<span class="math inline">\(O(\sqrt{\frac{\min\{\tilde{L},\lambda\}}{\mu}}\log\frac{1}{\epsilon})\)</span>，以及局部梯度复杂度<span class="math inline">\(O((m + \sqrt{\frac{m(\tilde{L} +\lambda)}{\mu}})\log\frac{1}{\epsilon})\)</span>，当 <span class="math inline">\(\lambda \leq \tilde{L}\)</span>时最优。但是，两者无法同时实现最优。</p><p><img src="/2021/01/26/AL2SGD/t1.jpg"></p></li></ul><h1 id="lower-complexity-bounds">Lower complexity bounds</h1><h2 id="lower-complexity-bounds-on-the-communication">Lower complexitybounds on the communication</h2><p><img src="/2021/01/26/AL2SGD/3.1.png"> <img src="/2021/01/26/AL2SGD/3.11.png"></p><h2 id="lower-complexity-bounds-on-the-local-computation">Lowercomplexity bounds on the local computation</h2><p><img src="/2021/01/26/AL2SGD/3.2.png"></p><h1 id="优化算法">优化算法</h1><h2 id="accelerated-proximal-gradient-descent-apgd-for-federated-learning">AcceleratedProximal Gradient Descent (APGD) for Federated Learning</h2><p>首先介绍非加速版本的近端梯度下降算法(PGD): <img src="/2021/01/26/AL2SGD/1.png"></p><p>根据另一篇论文，有两种不同的方式可以将梯度下降算法应用到上述优化问题上。最直接的方式是令<span class="math inline">\(h = f\)</span>，<span class="math inline">\(\phi =\lambda\psi\)</span>，那么可以得到如下更新步骤： <img src="/2021/01/26/AL2SGD/2.png"></p><p>另一种方式是令 <span class="math inline">\(h(\mathbf{x}) = \lambda\phi(\mathbf{x}) + \frac{\mu}{2n}\|\mathbf{x}\|^{2}\)</span>， <span class="math inline">\(\phi(\mathbf{x}) = f(\mathbf{x}) -\frac{\mu}{2n}\|\mathbf{x}\|^{2}\)</span>。由此得到的更新过程如下： <img src="/2021/01/26/AL2SGD/3.png"></p><p>同FedProx算法一致。</p><p>由于上述两种情况下，每次迭代都需要进行一轮通信，相应的通信复杂度次优。但是可以结合动量算法，程序(6)可以结合Nesterov'smomentum，能够得到最优通信复杂度，以及最优局部近端复杂度（当 <span class="math inline">\(\lambda \leqL)\)</span>，该算法定义为APGD1，具体如下：</p><p><img src="/2021/01/26/AL2SGD/a2.png"></p><p>将更新过程(5)和动量结合，可以得到最优通信复杂度以及最优局部近端复杂度（当<span class="math inline">\(\lambda \geqL）\)</span>。将该算法定义为APGD2，具体如下：</p><p><img src="/2021/01/26/AL2SGD/a3.png"></p><h2 id="beyond-proximal-oracle-inexact-apgd-iapgd">Beyond proximaloracle: Inexact APGD (IAPGD)</h2><p>在多数情况下，如果采用局部近端操作，每一步迭代时都需要得到子问题的精确解，这是不实际的。因此，作者提出了一个针对(6)的加速非精确的算法，每个节点只需要进行局部梯度运算（AGD, Katyusha)：</p><p><img src="/2021/01/26/AL2SGD/a1.png"></p><h2 id="accelerated-l2sgd">Accelerated L2SGD+</h2><p>作者给出L2SGD+算法的一个加速版本-AL2SGD+。作者指出AL2SGD+算法不过是L-Katyusha算法与非均匀抽样的结合。</p><p><img src="/2021/01/26/AL2SGD/a4.png"></p><h1 id="experiments">Experiments</h1><p>在第一个实验中，作者比较了当局部损失为有限和形式时，算法IAPGD+Katyusha、AL2SGD+以及L2SGD+的收敛速度。结果如下图：</p><p><img src="/2021/01/26/AL2SGD/5.jpg"></p><p>对于通信轮数，IAPGD+Katyusha和AL2SGD+都显著优于L2SGD+；对于局部计算次数，AL2SGD+表现最优，IAPGD+Katyusha不如L2SGD+。</p><p>第二个实验中，作者研究了数据异质性对算法的影响，结果如下图所示。可以看出，数据异质性不影响算法的收敛速度，各个算法的表现同第一个实验相似。</p><p><img src="/2021/01/26/AL2SGD/6.png"></p><p>在第三个实验中，作者比较了APGD算法的两种变形：APGD1和APGD2。作者不断改变参数<span class="math inline">\(\lambda\)</span>的取值，其余参数保持不变。在理论上，APGD2算法应该不受参数 <span class="math inline">\(\lambda\)</span> 影响，而APGD1 算法的收敛率会随着<span class="math inline">\(\lambda\)</span> 而增加 (<span class="math inline">\(\sqrt{\lambda}\)</span>)。 当 <span class="math inline">\(\lambda \leq L = 1\)</span>时，APGD1是最优选择；当<span class="math inline">\(\lambda &gt; L = 1\)</span> 时，APGD2应该是最优选择。实验结果如下图所示，结果与理论一致。</p><p><img src="/2021/01/26/AL2SGD/7.png"></p><h1 id="参考文献">参考文献</h1><ul><li>Filip Hanzely (KAUST) · Slavomír Hanzely (KAUST) · Samuel Horváth(King Abdullah University of Science and Technology)· Peter Richtarik(KAUST). Lower Bounds and Optimal Algorithms for Personalized FederatedLearning.arXiv e-prints.https://ui.adsabs.harvard.edu/abs/2020arXiv201002372H</li></ul>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Federated Learning of a Mixture of Global and Local Models</title>
      <link href="/2021/01/26/L2SGD/"/>
      <url>/2021/01/26/L2SGD/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="#introduction">Introduction</a><ul><li><a href="#11-federated-learning">1.1 Federated learning</a></li></ul></li><li><a href="#contributions">Contributions</a></li><li><a href="#新的优化问题">新的优化问题</a></li><li><a href="#l2gd-loopless-local-gd">L2GD: Loopless Local GD</a><ul><li><a href="#收敛理论">收敛理论</a></li><li><a href="#收敛率优化">收敛率优化</a></li></ul></li><li><a href="#loopless-local-sgd-with-variance-reduction">Loopless LocalSGD with Variance Reduction</a><ul><li><a href="#问题设置">问题设置</a></li><li><a href="#理论">理论</a></li></ul></li><li><a href="#experiments">Experiments</a></li><li><a href="#附录">附录</a><ul><li><a href="#experimental-setup-and-further-experiments">ExperimentalSetup and further experiments</a></li><li><a href="#其余算法">其余算法</a></li></ul></li><li><a href="#参考文献">参考文献</a></li></ul><!-- /TOC --><h1 id="introduction">Introduction</h1><h2 id="federated-learning">1.1 Federated learning</h2><p>联邦学习的目标函数： <span class="math display">\[  \min_{\mathbf{x} \in \mathbb{R}^{d}}\frac{1}{n}\sum_{i=1}^{n}f_{i}(\mathbf{x})  \]</span> 其中 <span class="math inline">\(n\)</span>表示参与训练的节点个数，<span class="math inline">\(\mathbf{x} \in\mathbb{R}^{d}\)</span>为全模型优化变量。 <span class="math inline">\(f_{i}(\mathbf{x})\)</span>为节点<span class="math inline">\(i\)</span>上的损失函数。</p><h1 id="contributions">Contributions</h1><ul><li>提出了新的FL优化形式，尝试学习全局模型和局部模型的混合。</li><li>给出了新的优化形式的理论性质。作者证明了最优局部模型以<span class="math inline">\(O(1/\lambda)\)</span>收敛到传统的全局模型；作者证明了在局部模型上得到的损失不高于全局模型上的损失(定理3.1)；作者指出局部模型的最优解等于所有局部模型最优解的平均值减去对应局部模型上损失函数的一阶梯度，这一点和MAML一致。</li><li>Loopless LGD：作者提出了一个随机梯度算法 — Loopless Local GradientDescent(L2GD)（算法1）来解决提出的优化问题。该算法不是一个标准的SGD，它可以看作是一个关于损失函数和惩罚项的不均匀抽样。当抽到损失函数部分时，每个节点执行一次随机梯度下降；当抽到惩罚项时，进行信息聚合。</li><li>收敛理论。假设函数 <span class="math inline">\(f_{i}\)</span> 为<span class="math inline">\(L-smooth\)</span>，并且为 <span class="math inline">\(\mu-strong \, convex\)</span>，可以得到抽样概率<span class="math inline">\(p^{*} = \frac{\lambda}{\lambda +L}\)</span>，固定期望局部更新次数为 <span class="math inline">\(1 +\frac{L}{\lambda}\)</span>，作者证明通信 (communication)复杂度为（通信次数上界）为 <span class="math inline">\(\frac{2\lambda}{\lambda +L}\frac{L}{\mu}\log\frac{1}{\epsilon}\)</span>。当 <span class="math inline">\(\lambda \to 0\)</span>时，通信次数非常小；当$$时，根据新优化问题得到的解收敛到全局模型最优解，并且L2GD算法的通信上界为 <span class="math inline">\(O(\frac{L}{\mu}\log\frac{1}{\epsilon})\)</span>。</li><li>推广。部分连接，局部SGD，variancereduction（variance来自三部分：非均匀抽样，部分连接，从节点样本随机抽样）。</li><li>可用于异质数据。</li><li>经验表现不错。</li></ul><h1 id="新的优化问题">新的优化问题</h1><p><span class="math display">\[\min_{\mathbf{x_{1},...,x_{n}} \in \mathbb{R}^{d}} \{ F(\mathbf{x}) :=f(\mathbf{x}) + \lambda \psi(\mathbf{x})\}\]</span> <span class="math display">\[f(\mathbf{x}):= \frac{1}{n}\sum_{i=1}^{n}f_{i}(\mathbf{x_{i}}), \quad\psi(\mathbf{x}):= \frac{1}{2n}\sum_{i=1}^{n}\|\mathbf{x_{i}} -\mathbf{\bar{x}}\|^{2}\]</span></p><ul><li>Local model (<span class="math inline">\(\lambda = 0\)</span>)</li><li>Mixed model (<span class="math inline">\(\lambda \in (0,\infty)\)</span>)</li><li>Global model (<span class="math inline">\(\lambda =\infty\)</span>)</li></ul><h1 id="l2gd-loopless-local-gd">L2GD: Loopless Local GD</h1><p>在这一部分中，作者给出一个算法求解上述优化问题，该算法可以看作是一个非均匀SGD，要么抽取<span class="math inline">\(\nabla f\)</span>，要么抽取 <span class="math inline">\(\nabla \psi\)</span> 估计 <span class="math inline">\(\nabla F\)</span>。令 <span class="math inline">\(0 &lt; p &lt; 1\)</span>，定义一个随机梯度如下：<span class="math display">\[G(\mathbf{x}):= \begin{cases} \frac{\nabla f(\mathbf{x})}{1-p}, &amp;\text {概率 $1-p$} \\ \frac{\lambda \nabla \psi(\mathbf{x})}{p}, &amp;\text{概率 $p$ } \end{cases}\]</span> 显然，<span class="math inline">\(G(\mathbf{x})\)</span>为<span class="math inline">\(\nabla F(\mathbf{x})\)</span>的无偏估计量。每步的更新为: <span class="math display">\[\mathbf{x}^{k+1} = \mathbf{x}^{k} - \alpha G(\mathbf{x}).\]</span></p><figure><img src="/2021/01/26/L2SGD/l2gd.png" alt="Algorithm 1"><figcaption aria-hidden="true">Algorithm 1</figcaption></figure><p><span class="math inline">\(\textbf{Lemma 4.2}\)</span> 经过 <span class="math inline">\(k\)</span> 步迭代后，期望的通信次数为 <span class="math inline">\(p(1-p)k\)</span>。</p><h2 id="收敛理论">收敛理论</h2><p>作者首先证明梯度估计量<span class="math inline">\(G(\mathbf{x})\)</span>的期望具有光滑性质，然后证明了算法L2GD的收敛性质。（<span class="math inline">\(\mathbf{x(\lambda)}\)</span>为最优解，定理4.4表明，L2GD算法只能收敛到最优解邻域。） <img src="/2021/01/26/L2SGD/4.3.png"></p><h2 id="收敛率优化">收敛率优化</h2><p>作者给出最优抽样概率 <span class="math inline">\(p^{*} =\frac{\lambda}{L + \lambda}\)</span>，步长 <span class="math inline">\(\alpha\)</span> 要满足 <span class="math inline">\(\frac{\alpha\lambda}{np} \leq\frac{1}{2}\)</span>. <img src="/2021/01/26/L2SGD/4.4.png"></p><h1 id="loopless-local-sgd-with-variance-reduction">Loopless Local SGDwith Variance Reduction</h1><p>L2GD算法仅线性收敛到最优解的邻域，无法收敛到最优解。假设每个子目标函数具有有限和形式，作者提出了一个算法L2SGD+，在每个节点上进行随机梯度下降，并且具有线性收敛速度。L2SGD是一个具有variancereduction 的局部SGD算法，关于SGD的variance reduction，见另一篇博客：SGDwith variance reduction.</p><h2 id="问题设置">问题设置</h2><p>假设 <span class="math inline">\(f_{i}\)</span> 具有有限和结构：<span class="math display">\[f_{i} = \frac{1}{m}\sum_{j=1}^{m}f_{i,j}(\mathbf{x}_{i})\]</span></p><p>那么目标函数变为： <span class="math display">\[F(\mathbf{x}) =\frac{1}{n}\sum_{i=1}^{n}(\frac{1}{m}\sum_{i=1}^{m}f_{i,j}(\mathbf{x}_{i}))+ \lambda\frac{1}{2n}\sum_{i=1}^{n}\|\mathbf{x}_{i} -\mathbf{\bar{x}}\|^{2}\]</span></p><p><img src="/2021/01/26/L2SGD/l2sgd+.png"></p><p>L2SGD算法仅在两次抽样不同时才会发生通信，经过 <span class="math inline">\(k\)</span> 次迭代后，需要进行 <span class="math inline">\(p(1-p)k\)</span>次聚合平均。但是，L2SGD算法还需要通信控制变量 <span class="math inline">\(\mathbf{J_{i}I,\Psi_{i}}\)</span>，因此通信次数变为原来的3倍。在附录中，作者给出了一个高效的L2SGD+，不需要通信控制变量。</p><h2 id="理论">理论</h2><p>作者给出了L2SGD算法的理论性质，并且给出最优抽样概率 <span class="math inline">\(p^{*}\)</span>。</p><p><img src="/2021/01/26/L2SGD/5.1.jpg"> <img src="/2021/01/26/L2SGD/5.2.png"> <img src="/2021/01/26/L2SGD/5.3.png"></p><h1 id="experiments">Experiments</h1><p>作者考虑Logistic回归问题，数据为LibSVM data(Chank &amp; Lin,2011)。数据首先进行normalized，以使得 <span class="math inline">\(f_{ij}\)</span>为1-smooth。步长根据定理5.2确定。每个数据集被划分为不同个数的节点，具体参数设置如下：<img src="/2021/01/26/L2SGD/table1.png"></p><p>作者考虑三种算法：L2SGD+, L2SGD(L2GD with local SGD), L2SGD2(L2GDwith local subsampling and control variates constructed for <span class="math inline">\(\Psi\)</span>)。根据理论分析，L2SGD+线性收敛到最优解，而L2SGD和L2SGD2收敛到最优解邻域。</p><p>作者考虑了两种数据分割方式。对于homogeneous data,首先将观测样本随机打乱，然后按照打乱后的数据划分到不同节点上；对于heterogeneousdata,首先根据观测样本的标签将样本排序，然后将排序后的数据依次划分到不同节点上(the worst-case heterogeneity)。</p><p><img src="/2021/01/26/L2SGD/figure3.png"></p><p>结果表明 - L2SGD+ (Full variance reduction)可以收敛到最优解，而L2SGD(without variance reduction)和 L2SGD2(with partial variancereduction) 只收敛到最优解邻域。 - 进行variancereduction是非常有必要的。它可以保证较快的全局收敛。 -数据异质性对算法收敛性没有影响。</p><h1 id="附录">附录</h1><h2 id="experimental-setup-and-further-experiments">Experimental Setupand further experiments</h2><ul><li>参数 <span class="math inline">\(p\)</span>如何影响算法L2SGD+的收敛速度</li><li>参数 <span class="math inline">\(\lambda\)</span>如何影响算法L2SGD+的收敛速度</li></ul><h2 id="其余算法">其余算法</h2><ul><li><p>Local GD with variance reduction</p><p>当每个节点采用梯度下降算法，且考虑variance reduction时，</p><p><img src="/2021/01/26/L2SGD/b1.png"> <img src="/2021/01/26/L2SGD/a3.png"></p></li><li><p>Efficient implementation of L2SGD+考虑到L2SGD+需要通信控制变量，增加了通信次数。作者给出了一个高效的版本，不需要通信控制变量，<span class="math inline">\(k\)</span>次迭代只需要通信 <span class="math inline">\(p(1-p)k\)</span>次。</p><p><img src="/2021/01/26/L2SGD/a4.png"></p></li><li><p>Local SGD with variance reduction – general method在这部分中，作者给出了一个使用性更广的版本。每个节点上目标函数可以包含一个非光滑正则项：</p><p><img src="/2021/01/26/L2SGD/b3.png"></p><p>另外，该版本算法允许从所有节点中任意抽样，允许节点结构任意（比如节点数据集大小，目标函数光滑程度，每个节点抽样方式任意）。</p><p><img src="/2021/01/26/L2SGD/a5.png"></p></li><li><p>Local stochastic algorithms</p><p>在这部分中，作者给出两个简单算法，不考虑variance reduction的LocalSGD(算法6)以及只考虑部分variance reduction的Local SGD (算法7)。</p><p><img src="/2021/01/26/L2SGD/a6.png"></p><p><img src="/2021/01/26/L2SGD/a7.png"></p></li></ul><h1 id="参考文献">参考文献</h1><ul><li>Hanzely, F. , &amp; Richtárik, Peter. (2020). Federated learning ofa mixture of global and local models.</li></ul>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FLreview</title>
      <link href="/2021/01/21/FLreview/"/>
      <url>/2021/01/21/FLreview/</url>
      
        <content type="html"><![CDATA[<h1 id="aaai21-personalized-cross-silo-federated-learning-on-non-iid-data">[AAAI21]Personalized Cross-Silo Federated Learning on Non-IID Data</h1><p>该算法的目标函数为： <img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613893223.png" alt="1613893223"></p><p>第二项<span class="math inline">\(A(\|\omega_{i} -\omega_{j}\|^{2})\)</span>的作用是使不同节点进行信息交流。该函数的定义如下：</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1614603445(1).png" alt="1614603445(1)"><figcaption aria-hidden="true">1614603445(1)</figcaption></figure><p>作者提出了一个求解上述目标函数的算法-FedAMP，具体如下：</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613893256(1).png" alt="1613893256(1)"><figcaption aria-hidden="true">1613893256(1)</figcaption></figure><p>注意到，函数<span class="math inline">\(A(\cdot)\)</span>中的变量为<span class="math inline">\(\|\omega_{i} -\omega_{j}\|^{2}\)</span>，由于是子模型参数距离二范数的平方，在式(3)进行求导时，会出现<span class="math inline">\((\omega_{i} -\omega_{j})\)</span>项，进而式(3)可以表示为模型参数 <span class="math inline">\(\omega_{1}^{k-1},...,\omega_{m}^{k-1}\)</span>的线性组合：<img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613893464(1).png" alt="1613893464(1)"></p><p>我们可以将 <span class="math inline">\(u_{i}\)</span> 看作是节点<span class="math inline">\(i\)</span>在云端子模型的参数，可以聚合各个节点的参数<span class="math inline">\(\omega_{1}^{k-1},...,\omega_{m}^{k-1}\)</span>信息。计算得到 <span class="math inline">\(u_{i}^{k}\)</span> 后，我们可以根据公式（4）在节点<span class="math inline">\(i\)</span> 上更新 <span class="math inline">\(\omega_{i}^{k}\)</span>:</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613893769(1).png" alt="1613893769(1)"><figcaption aria-hidden="true">1613893769(1)</figcaption></figure><p>借助于<span class="math inline">\(u_{i}\)</span>聚合其他节点的参数，节点<span class="math inline">\(i\)</span>可以获取其他节点的信息。在云端优化完<span class="math inline">\(A(W)\)</span>后，对于每个节点，再利用式(6)优化损失函数<span class="math inline">\(F_{i}(w)\)</span>。</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613893796(1).png" alt="1613893796(1)"><figcaption aria-hidden="true">1613893796(1)</figcaption></figure><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613893828(1).png" alt="1613893828(1)"><figcaption aria-hidden="true">1613893828(1)</figcaption></figure><p>在聚合其他节点参数时，式(5)中不同节点参数的权重为 <span class="math display">\[\xi_{i,j} = \alpha_{k}A'(\|\omega_{i}^{k-1} -\omega_{j}^{k-1}\|^{2}), \quad (i \ne j)\]</span> 根据定义1，在<span class="math inline">\([0,\infty)\)</span>上，<span class="math inline">\(A\)</span>是一个increasing and concave函数，函数A的导数<span class="math inline">\(A'\)</span>在<span class="math inline">\((0, \infty)\)</span>上为non-negative andnon-increasing 函数，所以<span class="math inline">\(A'(\|\omega_{i}^{k-1} -\omega_{j}^{k-1}\|^{2})\)</span>相当于一个相似度函数，如果两个节点的参数<span class="math inline">\(w_{i}^{k-1}\)</span>和<span class="math inline">\(w_{j}^{k-1}\)</span>的欧氏距离小，那么这两个节点的相似度要高，对应到<span class="math inline">\(u_{i}^{k}\)</span>和<span class="math inline">\(u_{j}^{k}\)</span>中，它们的权重更高，因而<span class="math inline">\(u_{i}^{k}\)</span>和<span class="math inline">\(u_{j}^{k}\)</span>更接近，进一步，<span class="math inline">\(w_{i}^{k}\)</span>和<span class="math inline">\(w_{j}^{k}\)</span>更接近。</p><h1 id="aaai21-tornadoaggregate-accurate-and-scalable-federated-learning-via-the-ring-based-architecture">[AAAI21]TornadoAggregate: Accurate and Scalable Federated Learning via theRing-Based Architecture</h1><p>在这篇文章中，作者提出一种可以提高精度和稳定性的聚合方式，并且讨论了当前已有的各种聚合方式。</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613894143.png" alt="1613894143"><figcaption aria-hidden="true">1613894143</figcaption></figure><p>作者指出STAR 这种全局聚合结构的稳定性差，相较而言，RING结构通过移除全局聚合，解决了STAR稳定性差的问题。但是，RING结构在FL中不切实际，假设共 <span class="math inline">\(|N|\)</span>个节点，RING需要进行的通信轮数是 STAR结构的 <span class="math inline">\(|N|\)</span> 倍数。除此之外，作者也总结讨论了其他已有聚合结构：STAR-stars, STAR-rings,RING-stars, RING-rings。</p><p>作者基于RING结构提出了两种新的聚合结构，通过减少RING结构带来的方差，提高了稳定性和精度。</p><h1 id="icml20-fedboost-communication-efficient-algorithms-for-federated-learning">[ICML20]FedBoost: Communication-Efficient Algorithms for Federated Learning</h1><p>作者借助集成的思想以减少FL中的通信成本。一些预先训练好的弱模型可以通过可获得的公共数据集训练。假设我们有<span class="math inline">\(q\)</span> 个已经训练好的弱模型 <span class="math inline">\(H =(h_{1},...,h_{q})\)</span>，本文的目标是学习组合权重 <span class="math inline">\(\alpha = \{ \alpha_{1}, ...,\alpha_{q}\}\)</span>，从而得到 <span class="math inline">\(\sum_{k=1}^{q} \alpha_{k}h_{k}\)</span>使得损失最小化。</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613895221(1).png" alt="1613895221(1)"><figcaption aria-hidden="true">1613895221(1)</figcaption></figure><h1 id="icml20-fetchsgd-communication-efficient-federated-learning-with-sketching">[ICML20]FetchSGD: Communication-Efficient Federated Learning with Sketching</h1><p>作者提出一个新的算法，算法思想为：在每一轮，每个节点基于自己的局部信息计算得到一个梯度，然后在进行聚合前，作者使用一种叫做CountSketch的数据结构对梯度进行压缩。中心端保留momentum和error accumulationCount Sketches，每轮更新的权重参数根据error accumulationsketch得到。</p><h1 id="icml20-federated-learning-with-only-positive-labels">[ICML20]Federated Learning with Only Positive Labels</h1><h1 id="icml20-from-local-sgd-to-local-fixed-point-methods-for-federated-learning">[ICML20]From Local SGD to Local Fixed-Point Methods for Federated Learning</h1><h1 id="nips20-lower-bounds-and-optimal-algorithms-for-personalized-federated-learning">[NIPS20]Lower Bounds and Optimal Algorithms for Personalized Federatedlearning</h1><p>L2SGD # [NIPS20] Federated Bayesian Optimization # [NIPS20] FederatedMulti-Task Learning MOCHA # [NIPS20] FedSplit: An algorithmic frameworkfor fast federated optimization作者首先讨论了两种已有算法FedSGD和FedProx算法，作者证明这两种算法都不具有可行的收敛理论保证，因为它们得到的稳定点都不是它们预先要求解的目标函数的解。因此，作者提出FedSplit算法，该算法得到的稳定点是优化问题的最优解。</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613897029.png" alt="1613897029"><figcaption aria-hidden="true">1613897029</figcaption></figure><h1 id="nips20-an-efficient-framework-for-clustered-federated-learning">[NIPS20]An Efficient Framework for Clustered Federated Learning</h1><p>作者提出一个迭代的聚类算法，论文假设所有的节点都能够被划分为若干类。由于每个节点所属类别未知，该算法可以交替估计每个节点所属的类别，并且通过梯度下降优化模型参数。论文中的算法可以解决数据分布的异质性问题。但是需要预先给定聚类个数<span class="math inline">\(k\)</span>。 <img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613897504(1).png" alt="1613897504(1)"></p><h1 id="nips20-group-knowledge-transfer-federated-learning-of-large-cnns-at-the-edge">[NIPS20]Group Knowledge Transfer: Federated Learning of Large CNNs at theEdge</h1><p>作者提出一种新的交替最小化算法，该算法在每个节点上先训练较小的CNN网络，然后通过信息迁移训练一个较大的中心端CNN网络。<img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613898317(1).jpg" alt="1613898317(1)"></p><p>上图展示了每个节点有一个特征提取器和分类器，可以在单个节点上进行模型训练。进行局部训练后，每个节点生成同样的张量，将其特征输出到中心端进行训练，然后借助于最小化预测标签和真实标签的KD损失函数训练参数。为了提升节点模型的表现，中心端会将其预测的标签发送给每个节点，然后每个节点可以基于其预测标签和中心端预测结果的损失函数训练子模型。</p><p><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613898899(1).png" alt="1613898899(1)"> # [NIPS20] Personalized Federated Learning withMoreau Envelopes为了解决异质性问题，作者考虑给每个节点的损失函数添加正则项： <span class="math display">\[f_{i}(\theta_{i}) + \frac{\lambda}{2}\|\theta_{i} - w\|^{2}，\]</span></p><p>优化问题表示为： <img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613899301(1).jpg" alt="1613899301(1)"></p><h1 id="nips20-tackling-the-objective-inconsistency-problem-in-heterogeneous-federated-optimization">[NIPS20]Tackling the Objective Inconsistency Problem in Heterogeneous FederatedOptimization</h1><p>大多数论文在分析算法的收敛性时，往往会假设每个节点上进行局部更新的次数相同，它们的工作表明算法能够达到全局目标函数的稳定点。事实上，论文指出当不同节点局部更新次数不一致时，算法收敛到的稳定点不是原始目标函数的最优解，而是另一个目标函数。</p><p>解决这个问题的最简单想法就是固定每个节点的局部更新次数，在进行新的一轮迭代前，要等所有节点进行迭代完才能开始。这种方法能够保证目标函数的一致性，但是会带来训练成本。一些算法比如FedProx,VRLSGD以及SCAFFOLD用于处理non-IID问题，可以减少目标函数的不一致问题，但是要么有较慢的收敛速度，要么需要额外的通信成本和内存。</p><p>本文作者提出FedNova算法，可以保证目标函数的一致性问题。</p><h1 id="nips20-throughput-optimal-topology-design-for-cross-silo-federated-learning">[NIPS20]Throughput-Optimal Topology Design for Cross-Silo FederatedLearning</h1><h1 id="nips20-federated-principal-component-analysis">[NIPS20]Federated Principal Component Analysis</h1><h1 id="nips20-ensemble-distillation-for-robust-model-fusion-in-federated-learning">[NIPS20]Ensemble Distillation for Robust Model Fusion in Federated Learning</h1><h1 id="nips20-differentially-private-federated-linear-bandits">[NIPS20]Differentially-Private Federated Linear Bandits</h1><h1 id="nips20-inverting-gradients---how-easy-is-it-to-break-privacy-in-federated-learning">[NIPS20]Inverting Gradients - How easy is it to break privacy in federatedlearning?</h1><h1 id="nips20-distributionally-robust-federated-averaging">[NIPS20]Distributionally Robust Federated Averaging</h1><h1 id="iclr20-fair-resource-allocation-in-federated-learning">[ICLR20]FAIR RESOURCE ALLOCATION IN FEDERATED LEARNING</h1><p>作者提出 q-FFL算法，目的是解决FL中的公平问题：不同节点上的精度均匀。通过最小化一个加权的损失函数，具有较高损失的节点具有较高的权重。</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613901146(1).png" alt="1613901146(1)"><figcaption aria-hidden="true">1613901146(1)</figcaption></figure><p>目标函数：</p><figure><img src="https://cdn.jsdelivr.net/gh/sugar-xue/BlogImages@main/Picbed1613901254(1).png" alt="1613901254(1)"><figcaption aria-hidden="true">1613901254(1)</figcaption></figure><p>具体算法略。 # [ICLR20] DIFFERENTIALLY PRIVATE META-LEARNING</p><h1 id="iclr20-dba-distributed-backdoor-attacks-against-federated-learning">[ICLR20]DBA: DISTRIBUTED BACKDOOR ATTACKS AGAINST FEDERATED LEARNING</h1><h1 id="iclr20-generative-models-for-effective-ml-on-private-decentralized-datasets">[ICLR20]GENERATIVE MODELS FOR EFFECTIVE ML ON PRIVATE, DECENTRALIZEDDATASETS</h1><h1 id="iclr20-attack-resistant-federated-learning-with-residual-based-reweighting">[ICLR20]ATTACK-RESISTANT FEDERATED LEARNING WITH RESIDUAL-BASED REWEIGHTING</h1>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FL </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
